// Multi-Head Attention
digraph {
	input [label="Input: Q, K, V
(batch_size, seq_len, embed_size)" shape=box]
	q_proj [label="Linear(Q)" shape=box]
	k_proj [label="Linear(K)" shape=box]
	v_proj [label="Linear(V)" shape=box]
	q_split [label="Rearrange(Q)
(batch_size, seq_len, num_heads, head_dim)" shape=box]
	k_split [label="Rearrange(K)
(batch_size, seq_len, num_heads, head_dim)" shape=box]
	v_split [label="Rearrange(V)
(batch_size, seq_len, num_heads, head_dim)" shape=box]
	attn_weights [label="Attention Weights
softmax(QK^T / sqrt(head_dim))" shape=box]
	head_outputs [label="Head Outputs
attention_weights * V" shape=box]
	concat [label="Concatenate Head Outputs
(batch_size, seq_len, embed_size)" shape=box]
	output [label="Output
Linear(concat)" shape=box]
	input -> q_proj [label=Q]
	input -> k_proj [label=K]
	input -> v_proj [label=V]
	q_proj -> q_split
	k_proj -> k_split
	v_proj -> v_split
	q_split -> attn_weights [label=Q]
	k_split -> attn_weights [label="K^T"]
	attn_weights -> head_outputs
	v_split -> head_outputs [label=V]
	head_outputs -> concat
	concat -> output
}
