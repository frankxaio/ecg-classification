Layer: encoder.0.0.block.0.weight
Parameters: tensor([0.9750, 1.0008, 1.0394, 0.9690, 1.0381, 0.9551, 1.0361, 0.9804, 1.0251,
        0.9770, 0.9904, 1.0317, 1.0246, 0.9874, 1.0160, 0.9927, 1.0636, 0.9876,
        0.9794, 1.0233, 1.0472, 1.0000, 1.0550, 1.0249, 0.9639, 1.0036, 1.0061,
        1.0274, 1.0092, 1.0298, 1.0008, 1.0026, 1.0025, 1.0162, 0.9898, 1.0281,
        0.9993, 1.0172, 1.0028, 0.9791, 1.0002, 0.9492, 0.9808, 1.0047, 1.0121,
        1.0756, 1.0484, 1.0530, 1.0308, 1.0548, 1.0228, 0.9818, 1.0365, 1.0565,
        1.0072, 0.9981, 1.0169, 1.0323, 0.9796, 1.0250, 0.9712, 0.9878, 1.0699,
        1.0638, 1.0120, 0.9914, 0.9969, 1.0180, 0.9557, 0.9869, 0.9812, 1.0278,
        0.9913, 0.9831, 0.9790, 0.9776, 1.0698, 0.9919, 0.9821, 1.0128, 1.0208,
        0.9713, 1.0205, 0.9782, 1.0168, 0.9990, 1.0669, 0.9685, 0.9903, 1.0564,
        1.0028, 0.9732, 0.9900, 1.0016, 0.9764, 1.0538, 0.9700, 1.0321, 0.9853,
        1.0275, 0.9730, 1.0576, 1.0065, 0.9865, 0.9718, 1.0318, 0.9698, 1.0009,
        0.9997, 0.9998, 1.0457, 1.0856, 1.0419, 1.0456, 1.0426, 1.0052, 0.9880,
        1.0245, 0.9877, 1.0324, 1.0372, 1.0039, 1.0107, 1.0121, 1.0386, 1.0081,
        1.0086, 1.0957, 1.0536, 1.0189, 1.0088, 1.0196, 0.9778, 1.0053, 0.9693,
        1.0646, 0.9503, 1.0302, 0.9749, 1.0263, 1.0327, 1.0324, 1.0163, 1.0140,
        1.0167, 1.0796, 1.0235, 1.0249, 0.9832, 0.9742, 1.0106, 0.9565, 0.9845,
        1.0191, 1.0266, 1.0431, 1.0238, 0.9800, 0.9822, 1.0213, 1.0231, 0.9399,
        1.0111, 0.9937, 1.0118, 1.0086, 0.9801, 1.1129, 1.0025, 1.0467, 1.0208,
        1.0143, 0.9412, 0.9968, 1.0069, 1.0380, 0.9438, 1.0153, 0.9957, 0.9649,
        0.9793, 1.0316, 1.0387, 1.0581, 0.9927, 1.0166, 0.9882, 1.0216, 1.0175,
        0.9699, 1.0435, 1.0296])

Layer: encoder.0.0.block.0.bias
Parameters: tensor([-0.0099,  0.0175,  0.0103,  0.0544,  0.0166,  0.0551, -0.0056, -0.0475,
         0.0165, -0.0376,  0.0286, -0.0341,  0.0089, -0.0023, -0.0366,  0.0168,
         0.0178,  0.0113, -0.0455, -0.0371,  0.0378, -0.0489,  0.0080,  0.0226,
        -0.0426,  0.0028,  0.0143, -0.0218, -0.0121,  0.0311,  0.0449, -0.0221,
        -0.0491, -0.0084,  0.0581, -0.0353,  0.0214,  0.0234,  0.0338,  0.0184,
        -0.0098,  0.0452,  0.0186, -0.0239, -0.0029, -0.0277, -0.0265, -0.0053,
        -0.0056, -0.0203,  0.0013,  0.0084, -0.0211, -0.0017,  0.0089, -0.0236,
        -0.0526,  0.0114,  0.0090,  0.0126,  0.0481, -0.0087, -0.0158,  0.0018,
         0.0072,  0.0218,  0.0349, -0.0650,  0.0131,  0.0209,  0.0152,  0.0220,
         0.0230,  0.0175, -0.0170,  0.0128,  0.0038, -0.0601,  0.0150,  0.0149,
        -0.0081,  0.0282, -0.0190, -0.0743,  0.0226,  0.0216, -0.0114,  0.0103,
         0.0239, -0.0071,  0.0069,  0.0270, -0.0171, -0.0114,  0.0192,  0.0134,
        -0.0758, -0.0113,  0.0405,  0.0059,  0.0075,  0.0124,  0.0117,  0.0107,
        -0.0002,  0.0083, -0.0284, -0.0610, -0.0523,  0.0102, -0.0296, -0.0267,
        -0.0023,  0.0212, -0.0020,  0.0172, -0.0306,  0.0098,  0.0205,  0.0220,
         0.0179,  0.0124,  0.0054, -0.0029,  0.0211,  0.0134, -0.0328,  0.0132,
        -0.0132,  0.0205, -0.0649, -0.0160,  0.0219,  0.0268,  0.0212,  0.0089,
         0.0598,  0.0410,  0.0189, -0.0208, -0.0115,  0.0057,  0.0106, -0.0285,
        -0.0001, -0.0121,  0.0220,  0.0150,  0.0228, -0.0639,  0.0042,  0.0202,
        -0.0070,  0.0355,  0.0124,  0.0082, -0.0410,  0.0208,  0.0175,  0.0074,
        -0.0190,  0.0273,  0.0243,  0.0354,  0.0238,  0.0323,  0.0510, -0.0106,
         0.0108, -0.0516, -0.0069, -0.0005,  0.0417,  0.0186, -0.0255,  0.0017,
        -0.0525, -0.0008,  0.0209, -0.0207, -0.0056,  0.0190,  0.0051,  0.0082,
         0.0186,  0.0309,  0.0127,  0.0068, -0.0250, -0.0340, -0.0517, -0.0038])

Layer: encoder.0.0.block.1.queries_projection._packed_params._packed_params
Parameters: (tensor([[-0.1168,  0.0417,  0.0751,  ...,  0.0150, -0.0184,  0.0684],
        [-0.0017, -0.0033, -0.0167,  ..., -0.0100, -0.0184, -0.0401],
        [-0.1152,  0.1252,  0.0250,  ..., -0.0150,  0.0150, -0.0768],
        ...,
        [ 0.0701, -0.0267, -0.0117,  ..., -0.0567, -0.0751,  0.0451],
        [ 0.0050, -0.0300,  0.0317,  ...,  0.0184, -0.0484,  0.0184],
        [ 0.0551, -0.0901, -0.0684,  ...,  0.0718, -0.0384,  0.0584]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0016688834875822067,
       zero_point=0), Parameter containing:
tensor([ 0.0613,  0.0520, -0.0378, -0.0085, -0.0466,  0.0948, -0.0120,  0.0250,
         0.0082,  0.0040, -0.0573, -0.0287,  0.0496, -0.0564, -0.0340,  0.0264,
        -0.0421,  0.0243, -0.0334, -0.0498,  0.0702,  0.0618,  0.0083,  0.0187,
         0.0402, -0.0576, -0.0033, -0.0152, -0.0290,  0.0737, -0.0037, -0.0544,
        -0.0712, -0.0034,  0.0477,  0.0072, -0.0269,  0.0864, -0.0595, -0.0414,
        -0.0122,  0.0440, -0.0066,  0.0985, -0.0628,  0.0584, -0.0099,  0.0021,
        -0.0018, -0.0112,  0.0195, -0.0335, -0.0618,  0.0047, -0.0649,  0.0007,
        -0.0478, -0.0016, -0.0282, -0.0555,  0.0281, -0.0389, -0.0721,  0.0244,
         0.0081, -0.0386,  0.0230,  0.0234,  0.0585, -0.0102, -0.0704,  0.0274,
         0.0430,  0.0684, -0.0194, -0.0304, -0.0014, -0.0090, -0.0123,  0.0029,
        -0.0516, -0.0244, -0.0539, -0.0393,  0.0458,  0.0296,  0.0838,  0.0362,
        -0.0228,  0.0722,  0.0193, -0.0116,  0.0273,  0.0665, -0.0429,  0.0192,
         0.0434, -0.0433, -0.0653, -0.0161, -0.0287,  0.0726, -0.0297,  0.0330,
         0.0728, -0.0363, -0.0496, -0.0413,  0.0305, -0.0054, -0.0188, -0.0005,
         0.0739, -0.0441, -0.0326,  0.0046,  0.0370, -0.0763,  0.0248,  0.0700,
         0.0088, -0.0066, -0.0450, -0.0673, -0.0548, -0.0791, -0.0429,  0.0483,
        -0.0714,  0.0453,  0.0316, -0.0406,  0.0506, -0.0301, -0.0129,  0.0222,
        -0.0189, -0.0641,  0.0417,  0.0214, -0.0140,  0.0905,  0.0700, -0.0629,
         0.0295,  0.0549, -0.0110,  0.0551,  0.0119,  0.0333,  0.0682,  0.0461,
         0.0361, -0.0567, -0.0915,  0.1000, -0.0550,  0.0219,  0.0589,  0.0267,
         0.0615, -0.0372,  0.0237, -0.0647, -0.0169,  0.0859, -0.0509, -0.0460,
         0.0509,  0.0057,  0.0174, -0.0441, -0.0263, -0.0093, -0.0304, -0.0279,
         0.0099, -0.0150, -0.0148,  0.0692,  0.0157, -0.0041, -0.0114,  0.0584,
         0.0185,  0.0327,  0.0666,  0.0179,  0.0349,  0.0456, -0.0387, -0.0060],
       requires_grad=True))

Layer: encoder.0.0.block.1.values_projection._packed_params._packed_params
Parameters: (tensor([[ 0.0127,  0.0361, -0.0191,  ..., -0.0594, -0.0148,  0.0551],
        [ 0.0509,  0.0891,  0.0679,  ..., -0.0636, -0.0085, -0.0170],
        [-0.0085,  0.0297,  0.0658,  ...,  0.0488,  0.0170, -0.0488],
        ...,
        [ 0.0870, -0.0530,  0.0488,  ..., -0.0700,  0.0700,  0.0424],
        [-0.0170,  0.0339, -0.0721,  ...,  0.0976, -0.0912, -0.0806],
        [ 0.0297,  0.0445,  0.0297,  ...,  0.0509,  0.0530, -0.0064]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0021209814585745335,
       zero_point=0), Parameter containing:
tensor([-0.0257,  0.0026, -0.0435,  0.0223, -0.0488, -0.0334,  0.0345,  0.0421,
         0.0040, -0.0674, -0.0015,  0.0579, -0.0344,  0.0039,  0.0616, -0.0659,
        -0.0444, -0.0041,  0.0649,  0.0031, -0.0309, -0.0728, -0.0393, -0.0472,
        -0.0327,  0.0390,  0.0276, -0.0639,  0.0510,  0.0243, -0.0119, -0.0343,
         0.0715, -0.0428, -0.0126, -0.0089, -0.0827,  0.0467, -0.0103, -0.0401,
         0.0450,  0.0255, -0.0485, -0.0295,  0.0004, -0.0046,  0.0484,  0.0540,
        -0.0216,  0.0450, -0.0511,  0.0280,  0.0688,  0.0449,  0.0497, -0.0461,
         0.0205,  0.0274, -0.0279, -0.0141,  0.0414,  0.0226,  0.0084, -0.0678,
         0.0301,  0.0176,  0.0356,  0.0140,  0.0035,  0.0728,  0.0572, -0.0657,
         0.0207, -0.0353,  0.0916,  0.0003, -0.0239,  0.0105,  0.0063,  0.0461,
        -0.0269,  0.0687,  0.0187, -0.0288, -0.0546, -0.0307,  0.0773, -0.0178,
         0.0510, -0.0175, -0.0123, -0.0416,  0.0041,  0.0002,  0.0434, -0.0142,
        -0.0032,  0.0029,  0.0193, -0.0612, -0.0391,  0.0413, -0.0212,  0.0285,
        -0.0198, -0.0591, -0.0037,  0.0074, -0.0529, -0.0055, -0.0693,  0.0015,
         0.0299,  0.0407,  0.0039,  0.0369, -0.0397,  0.0472, -0.0241,  0.0469,
        -0.0364, -0.0774,  0.0587, -0.0408,  0.0536,  0.0290,  0.0085, -0.0369,
         0.0030,  0.0776,  0.0723,  0.0286, -0.0495, -0.0403, -0.0276, -0.0105,
        -0.0224, -0.0004,  0.0405,  0.0192,  0.0149, -0.0744, -0.0262,  0.0219,
         0.0488, -0.0639, -0.0182,  0.0074, -0.0487, -0.0110, -0.0324, -0.0497,
        -0.0420,  0.0241, -0.0372, -0.0490,  0.0343,  0.0264, -0.0495,  0.0094,
        -0.0217, -0.0300, -0.0006,  0.0545, -0.0522,  0.0087, -0.0169,  0.0314,
         0.0527, -0.0178, -0.0333,  0.0146, -0.0110, -0.0500,  0.0478, -0.0079,
         0.0110,  0.0332,  0.0568,  0.0178,  0.0498,  0.0560,  0.0133, -0.0612,
        -0.0161, -0.0422, -0.0020, -0.0388, -0.0190,  0.0241, -0.0686,  0.0050],
       requires_grad=True))

Layer: encoder.0.0.block.1.keys_projection._packed_params._packed_params
Parameters: (tensor([[ 0.0068, -0.0579, -0.0392,  ..., -0.0903, -0.0153,  0.0017],
        [-0.0119,  0.0375,  0.0034,  ...,  0.0222,  0.1193, -0.0579],
        [ 0.0494,  0.0222,  0.0358,  ..., -0.0170, -0.0392,  0.0835],
        ...,
        [ 0.0102,  0.0699, -0.0409,  ..., -0.0665, -0.1022, -0.0596],
        [ 0.0187, -0.0511, -0.0409,  ..., -0.0375, -0.0682, -0.0665],
        [ 0.0341, -0.0187, -0.0136,  ...,  0.0886, -0.0187,  0.0273]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0017040540697053075,
       zero_point=0), Parameter containing:
tensor([-0.0829,  0.0307, -0.0355, -0.0944, -0.0518,  0.0797,  0.0002, -0.0050,
        -0.0257, -0.0756,  0.0025, -0.0179,  0.0706,  0.0502, -0.0378, -0.0303,
        -0.0269, -0.0156,  0.0483,  0.0507, -0.0074, -0.0317,  0.0589,  0.0021,
        -0.0346, -0.0512, -0.0206, -0.0473,  0.0150, -0.0662, -0.0578,  0.0612,
         0.0010, -0.0366, -0.0519, -0.0120,  0.0281,  0.1059,  0.0847, -0.0829,
        -0.0237,  0.0159, -0.0073,  0.0694, -0.0310,  0.0746,  0.0256,  0.0865,
        -0.0323, -0.0305,  0.0152, -0.0310,  0.0106,  0.0477, -0.0402, -0.0453,
         0.0597,  0.0740, -0.0345, -0.0625, -0.0654, -0.0275,  0.0091, -0.0757,
         0.0122, -0.0049, -0.0638,  0.0101,  0.0377, -0.0297,  0.0506, -0.0274,
         0.0268,  0.0262, -0.0179,  0.0963, -0.0532, -0.0054,  0.0135,  0.0326,
        -0.0268,  0.0611, -0.0050, -0.0565, -0.0753,  0.0026,  0.0048,  0.0177,
         0.0374, -0.0294, -0.0492, -0.0294, -0.0312,  0.0296,  0.0402, -0.0613,
        -0.0919,  0.0085, -0.0463,  0.0868,  0.0039, -0.0460,  0.0645, -0.0330,
         0.0491,  0.0405,  0.0674, -0.0581,  0.0685, -0.0701,  0.0115,  0.0356,
        -0.0435, -0.0274,  0.0200, -0.0027,  0.0106, -0.0168, -0.0017, -0.0829,
        -0.0076,  0.0415,  0.0162,  0.0299,  0.0211,  0.0235, -0.0605, -0.0601,
        -0.0396,  0.0511,  0.0086, -0.0052,  0.0398,  0.0374, -0.0314,  0.0911,
        -0.0308,  0.0155, -0.0483, -0.0840, -0.0076,  0.0105,  0.0609, -0.0067,
        -0.0415, -0.0361, -0.0137,  0.0406,  0.0459, -0.0146,  0.0756,  0.0221,
         0.0349,  0.0247, -0.0425, -0.0072, -0.0666,  0.0320, -0.0037,  0.0346,
         0.0161,  0.0506, -0.0877,  0.0483,  0.0824, -0.0312, -0.0619, -0.0393,
        -0.0275, -0.0417, -0.0209, -0.0246, -0.0407, -0.0268,  0.0581,  0.0317,
         0.0205,  0.0111,  0.0192, -0.0635,  0.0264,  0.0505, -0.0859, -0.0266,
         0.0739,  0.0324,  0.0588,  0.0778, -0.0187,  0.0558,  0.0281,  0.0332],
       requires_grad=True))

Layer: encoder.0.0.block.1.final_projection._packed_params._packed_params
Parameters: (tensor([[-0.0897,  0.0249,  0.0125,  ...,  0.1371, -0.1097,  0.0299],
        [ 0.0100, -0.0922, -0.1371,  ..., -0.0723,  0.0723, -0.0224],
        [ 0.0224, -0.0449, -0.0224,  ...,  0.0947, -0.0598, -0.0125],
        ...,
        [ 0.0673,  0.0374,  0.0324,  ..., -0.0548,  0.0773,  0.0922],
        [ 0.0199, -0.0548, -0.0025,  ..., -0.0623,  0.0399,  0.0673],
        [ 0.0598, -0.0199,  0.0199,  ...,  0.0274, -0.0100,  0.0175]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0024929861538112164,
       zero_point=0), Parameter containing:
tensor([ 4.3030e-02,  4.2485e-02,  5.0295e-02,  2.6345e-02,  2.9572e-02,
         5.8398e-02,  4.7936e-02, -5.6216e-02, -6.6108e-03, -2.5265e-02,
        -9.7642e-03,  3.7627e-02,  2.5566e-02,  1.4230e-02,  7.8935e-03,
        -3.2474e-02,  1.4033e-02, -6.8954e-02, -6.9097e-02,  3.4755e-02,
         7.8711e-02,  1.8010e-03, -7.3398e-02,  2.8414e-02,  5.5729e-03,
        -1.4818e-02, -3.5275e-02, -5.2306e-03,  1.2474e-02, -3.0924e-02,
        -1.0861e-02, -5.7460e-02, -4.7005e-02,  5.3832e-02,  4.4195e-02,
         5.9931e-02,  6.0091e-02, -1.2977e-02,  7.7474e-02,  4.2123e-02,
        -1.3094e-02,  3.3608e-02, -5.7710e-03, -5.0297e-02,  8.2471e-03,
         1.1802e-02,  9.8305e-03, -1.9483e-02, -1.0647e-03,  2.9471e-02,
        -2.6632e-02,  4.1429e-02, -9.1181e-03,  5.3476e-02,  1.6041e-02,
         2.3369e-02, -1.5499e-02, -1.0070e-02, -4.1414e-02, -6.1955e-02,
         4.8548e-02,  3.2012e-02, -1.6766e-02, -2.0780e-03,  5.5884e-02,
         1.7922e-02,  3.4534e-02,  2.2906e-02,  5.6289e-02, -6.8687e-03,
         1.0043e-02,  4.2559e-02, -5.1396e-02,  2.7990e-02,  4.6309e-02,
        -1.3638e-02,  2.1931e-03, -1.8942e-02,  1.9105e-02, -1.4487e-02,
         1.1370e-02, -1.2680e-02, -2.1937e-02, -5.1997e-02,  2.3270e-02,
        -2.4356e-02,  1.1572e-02,  9.9781e-03,  3.7717e-02,  3.2247e-02,
         2.0946e-02, -4.3110e-02, -1.0660e-02,  4.7037e-02,  2.7900e-02,
        -4.5158e-02, -7.6268e-02, -6.5789e-02, -2.5630e-02, -5.4969e-02,
        -5.7394e-02, -2.7497e-02,  6.1078e-02, -5.6180e-02,  3.4444e-02,
         1.1064e-02,  3.5664e-02, -1.4270e-02,  6.1648e-02, -2.1961e-02,
        -4.5332e-02,  3.6038e-02, -2.7467e-02,  2.3457e-02,  3.6675e-02,
        -4.5762e-02, -4.9344e-02, -1.1569e-02,  4.3133e-02, -1.7746e-02,
        -2.0865e-02,  4.4789e-02,  1.7102e-02,  2.5895e-02,  2.1340e-02,
        -4.6350e-02,  4.3408e-02, -6.2044e-02, -2.5755e-02, -1.6183e-02,
        -3.6506e-03, -6.7016e-03,  4.6970e-02, -4.7008e-02, -5.2151e-02,
         7.6065e-05,  2.3663e-02, -1.9345e-02, -3.3276e-02, -9.5980e-03,
         1.8248e-02, -1.1901e-03, -2.9343e-02,  3.8731e-02,  2.1080e-03,
         2.6622e-02,  2.4019e-02,  2.9884e-02,  3.9810e-02, -2.4162e-02,
        -1.9282e-02,  1.3395e-02, -2.9183e-02, -3.8201e-02,  1.6877e-02,
        -1.9893e-02,  3.4773e-03,  2.2126e-02,  4.1154e-02, -3.3532e-02,
        -4.9512e-02, -3.5711e-03, -4.8716e-02, -4.6204e-02, -3.8139e-02,
         5.6920e-02,  4.2506e-02,  2.9025e-03,  1.4765e-02,  2.2795e-02,
         5.8285e-02, -4.1102e-02,  6.3477e-02,  4.5321e-02, -1.0703e-02,
        -1.8899e-02,  8.9426e-03, -1.1994e-02,  4.4311e-02,  1.4638e-02,
         4.5524e-02, -2.7347e-02,  1.8170e-02,  3.7883e-03, -3.2852e-02,
         2.4933e-02,  1.4562e-02,  5.1783e-02, -5.3322e-03, -1.3875e-02,
         7.4793e-03,  1.6891e-02], requires_grad=True))

Layer: encoder.0.1.block.0.weight
Parameters: tensor([1.0418, 1.0060, 0.9843, 1.0244, 0.9766, 0.9731, 0.9900, 1.0045, 0.9934,
        0.9246, 0.9790, 1.0001, 1.0164, 1.0122, 1.0299, 1.0022, 0.9819, 0.9828,
        0.9876, 1.0061, 1.0116, 0.9758, 1.0600, 1.0011, 1.0177, 0.9773, 0.9597,
        1.0402, 1.0084, 1.0014, 0.9844, 1.0189, 0.9999, 1.0244, 0.9638, 1.0114,
        0.9992, 0.9415, 1.0154, 1.0409, 0.9924, 0.9905, 0.9760, 1.0082, 1.0073,
        1.0096, 1.0062, 1.0026, 1.0364, 1.0243, 1.0242, 0.9666, 1.0254, 1.0063,
        1.0002, 0.9557, 0.9972, 1.0193, 0.9928, 1.0067, 1.0291, 1.0142, 1.0217,
        1.0477, 1.0090, 0.9806, 0.9889, 1.0190, 0.9976, 0.9598, 0.9704, 1.0153,
        0.9871, 0.9514, 0.9977, 1.0173, 1.0370, 0.9797, 1.0120, 0.9704, 1.0046,
        0.9635, 1.0448, 1.0170, 0.9863, 0.9857, 1.0390, 0.9805, 1.0160, 1.0095,
        0.9687, 0.9715, 0.9976, 1.0055, 0.9779, 1.0118, 0.9559, 0.9797, 0.9794,
        1.0075, 0.9688, 0.9967, 1.0082, 0.9840, 0.9996, 1.0197, 0.9926, 0.9955,
        1.0229, 0.9760, 1.0045, 1.0288, 0.9705, 0.9852, 0.9655, 0.9944, 0.9620,
        1.0057, 0.9649, 1.0342, 1.0620, 0.9784, 1.0075, 0.9833, 1.0068, 0.9686,
        1.0129, 1.0176, 1.0270, 1.0250, 1.0131, 1.0113, 0.9810, 1.0118, 0.9920,
        1.0119, 1.0422, 0.9986, 1.0011, 0.9944, 1.0000, 0.9705, 0.9171, 1.0277,
        1.0099, 1.0078, 1.0219, 1.0379, 0.9346, 0.9725, 0.9968, 0.9953, 0.9346,
        0.9512, 1.0464, 0.9894, 1.0040, 0.9928, 1.0144, 1.0170, 1.0321, 0.9679,
        1.0077, 1.0281, 1.0248, 1.0251, 0.9380, 1.0445, 0.9918, 1.0437, 1.0214,
        0.9882, 1.0295, 0.9880, 1.0508, 1.0101, 0.9888, 0.9767, 0.9874, 0.9685,
        1.0250, 1.0143, 0.9962, 1.0165, 0.9456, 0.9749, 1.0488, 1.0022, 1.0098,
        0.9623, 1.0359, 0.9558])

Layer: encoder.0.1.block.0.bias
Parameters: tensor([ 0.0205, -0.0077, -0.0075, -0.0099,  0.0061,  0.0484,  0.0246, -0.0096,
        -0.0252, -0.0579,  0.0010, -0.0087, -0.0341, -0.0034,  0.0226, -0.0206,
         0.0332, -0.0106, -0.0256, -0.0182,  0.0377, -0.0070, -0.0336,  0.0022,
        -0.0037, -0.0141,  0.0237, -0.0114, -0.0150, -0.0226,  0.0205, -0.0101,
        -0.0109,  0.0186, -0.0110,  0.0039,  0.0059,  0.0316,  0.0525, -0.0080,
         0.0172,  0.0259, -0.0392, -0.0233, -0.0301, -0.0019,  0.0143,  0.0109,
        -0.0022, -0.0114,  0.0370,  0.0198,  0.0043,  0.0061,  0.0246, -0.0153,
        -0.0208,  0.0226,  0.0059,  0.0013,  0.0440, -0.0301,  0.0181, -0.0015,
        -0.0197, -0.0087,  0.0260,  0.0063,  0.0023,  0.0603,  0.0093,  0.0124,
         0.0101,  0.0285, -0.0021, -0.0150, -0.0005, -0.0056, -0.0203, -0.0255,
        -0.0393,  0.0072,  0.0196,  0.0170,  0.0136, -0.0124,  0.0059,  0.0412,
        -0.0156,  0.0155,  0.0103, -0.0026,  0.0015, -0.0004, -0.0462,  0.0190,
        -0.0288, -0.0055, -0.0130, -0.0194,  0.0107,  0.0117, -0.0022, -0.0116,
         0.0200, -0.0204, -0.0221, -0.0108, -0.0146,  0.0037,  0.0034, -0.0085,
        -0.0329,  0.0159, -0.0194, -0.0018, -0.0502, -0.0068,  0.0003,  0.0074,
         0.0035,  0.0130, -0.0103, -0.0241,  0.0200,  0.0086,  0.0152,  0.0023,
         0.0123, -0.0278,  0.0173,  0.0167,  0.0618,  0.0232,  0.0274,  0.0083,
         0.0339, -0.0020,  0.0419, -0.0569,  0.0228,  0.0303,  0.0323, -0.0174,
         0.0016,  0.0124,  0.0039,  0.0118,  0.0254, -0.0257,  0.0132,  0.0182,
         0.0128,  0.0383,  0.0093, -0.0090,  0.0110, -0.0200, -0.0369, -0.0105,
         0.0148,  0.0083, -0.0299, -0.0094,  0.0043, -0.0145,  0.0160,  0.0201,
        -0.0085, -0.0011,  0.0121,  0.0072, -0.0082,  0.0357,  0.0118,  0.0290,
         0.0075, -0.0462,  0.0007, -0.0310, -0.0229,  0.0222,  0.0081, -0.0074,
         0.0065,  0.0386, -0.0168, -0.0166, -0.0256, -0.0556,  0.0115, -0.0077])

Layer: encoder.0.1.block.1.0._packed_params._packed_params
Parameters: (tensor([[-0.0110,  0.0570,  0.0460,  ..., -0.0368,  0.0423,  0.0000],
        [-0.0276, -0.0386,  0.0460,  ...,  0.0589, -0.0092,  0.0037],
        [-0.0920,  0.0828,  0.0184,  ..., -0.0736,  0.0074,  0.0313],
        ...,
        [-0.1030, -0.0368,  0.0681,  ...,  0.0662,  0.0534, -0.0129],
        [-0.0681, -0.0386, -0.0258,  ..., -0.0626, -0.0184, -0.0552],
        [-0.0202, -0.0460, -0.0515,  ...,  0.0184, -0.0386,  0.0294]],
       size=(768, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0018401178531348705,
       zero_point=0), Parameter containing:
tensor([ 2.8576e-02,  3.5646e-02, -2.1681e-02, -7.6115e-03, -1.1041e-01,
        -4.6143e-02, -8.5512e-02,  2.8941e-02, -4.8355e-02, -9.8752e-02,
        -4.0317e-02, -3.1645e-02, -1.8798e-02, -2.0200e-03, -4.5121e-02,
        -1.8517e-02, -7.5882e-02, -6.9157e-02,  1.0584e-02,  3.0456e-02,
        -1.0159e-01, -8.3359e-02,  3.3073e-02,  2.7604e-02, -2.1450e-02,
        -8.5137e-03, -2.8966e-02,  2.9291e-03,  3.7450e-02, -7.3833e-02,
         2.8369e-03, -6.3342e-02,  1.9701e-02, -3.0132e-03,  4.4088e-02,
         9.4108e-03,  1.7615e-02, -2.0301e-02, -7.9639e-03, -8.2368e-02,
        -8.4262e-02, -3.8943e-02,  6.8632e-03, -4.6781e-02, -8.0821e-02,
        -7.8200e-02,  2.6409e-02, -8.2851e-02, -4.6338e-02,  4.7451e-02,
        -1.6151e-02,  9.6701e-03,  6.9805e-03, -5.1573e-02,  2.5118e-02,
        -4.5263e-02, -7.1824e-02, -1.4516e-02,  4.3401e-03, -2.0708e-02,
         3.4515e-03, -3.6866e-02, -2.9079e-02, -2.2738e-02,  2.0935e-02,
        -5.1360e-02,  2.1484e-02,  4.2914e-02, -6.0016e-02, -3.8929e-03,
        -1.1430e-02, -7.0979e-02, -8.5272e-02, -4.4194e-02, -2.2950e-02,
         3.6207e-02, -8.4771e-02, -8.1568e-02, -6.6456e-02,  3.0713e-02,
         2.3567e-02, -6.2138e-02, -5.2606e-02,  3.7140e-02, -3.3170e-02,
         1.5960e-03, -6.9625e-03,  4.9796e-02,  5.2445e-03, -2.2191e-02,
        -8.5521e-02,  2.1835e-02,  3.4565e-02, -8.9739e-02, -2.6118e-02,
        -5.7900e-02,  2.0751e-02, -6.6709e-02,  3.4126e-02, -9.7060e-02,
        -4.0326e-02,  1.7015e-02,  4.4967e-02, -6.6780e-02, -2.4731e-02,
         3.2827e-03, -3.4712e-02, -1.1285e-01, -8.2179e-03,  1.0460e-02,
        -1.1578e-02,  3.0283e-02,  4.4986e-02,  3.0235e-02,  1.4660e-02,
        -6.1953e-02, -6.4347e-03, -2.4810e-02, -4.2207e-02, -3.6993e-02,
         1.0303e-02,  2.9830e-03, -3.9422e-02, -4.3998e-02,  3.1702e-02,
        -1.1125e-01,  1.7984e-02, -5.2610e-02, -3.8646e-02,  3.3332e-02,
        -6.8126e-03, -1.7781e-02,  3.0548e-02, -5.7575e-02, -2.2147e-03,
        -7.3412e-03,  3.7909e-02, -3.2522e-02,  4.8039e-02, -8.4326e-03,
        -1.0272e-01,  2.2505e-03,  7.7928e-04,  2.5682e-02, -5.6887e-02,
        -3.6927e-04,  4.4816e-02,  3.1141e-02, -2.7010e-02,  3.0459e-02,
         3.2692e-02, -6.6765e-02, -4.4070e-02,  3.8336e-02, -6.7855e-02,
        -8.4317e-02,  7.5601e-03, -1.3513e-02, -5.9761e-02, -2.3465e-02,
         2.8316e-02, -7.4227e-02, -1.2582e-02, -7.3134e-02,  1.1849e-02,
        -4.4089e-02, -9.8948e-02, -9.5728e-02, -6.1366e-03, -5.8005e-02,
        -3.4524e-02, -6.1773e-02, -4.6899e-02, -4.0187e-02, -2.7625e-02,
        -7.4559e-02, -8.8751e-02, -2.4458e-02,  1.3259e-02, -3.4643e-02,
        -1.3037e-01,  3.5915e-04,  7.2787e-03, -5.6987e-02, -8.2461e-02,
         4.3484e-03, -3.4739e-02,  4.3310e-02,  9.0210e-03, -3.1335e-02,
        -1.1065e-02, -1.6834e-02, -4.4476e-02,  4.5689e-02,  2.4434e-02,
        -6.1378e-02,  1.4353e-02, -8.3882e-02,  4.3537e-02, -5.9273e-02,
         2.9468e-02,  1.4593e-02,  3.7102e-02,  1.0858e-02, -4.7035e-02,
        -3.6446e-02,  4.2722e-02, -7.0501e-03,  3.7635e-03, -1.1624e-02,
        -5.9994e-02,  4.2152e-02, -3.7097e-02, -8.8609e-02, -2.2446e-02,
        -9.3684e-02,  4.9692e-03, -8.9004e-02, -1.8680e-02, -6.0421e-02,
        -8.7551e-02, -4.7839e-02,  2.7244e-02, -1.3385e-02,  2.9961e-02,
         4.9831e-02, -1.1138e-03,  6.1723e-04, -4.6109e-02, -9.0791e-02,
         3.0730e-02, -4.9404e-02,  3.9628e-02, -3.2737e-02,  3.0636e-02,
        -7.3079e-02, -6.2298e-02, -9.1986e-03,  2.7480e-02, -1.9890e-02,
        -6.1859e-04,  2.5354e-02, -4.7499e-02, -2.3520e-02, -9.3529e-02,
        -8.6708e-02,  1.8163e-02, -4.3826e-02, -2.4066e-02, -9.6637e-02,
         1.2637e-02, -2.2576e-02,  5.8938e-03, -4.8455e-02,  3.0451e-02,
        -8.1407e-02, -6.0118e-02, -3.5575e-02, -9.8384e-02, -2.3951e-02,
        -7.7108e-02, -6.4250e-02, -7.5213e-03,  1.1748e-02,  1.8986e-02,
        -3.4778e-02,  1.8331e-02, -3.0727e-02, -4.5526e-02, -6.5161e-02,
         1.7855e-02,  3.4804e-02, -8.4943e-02,  2.3243e-02,  5.4103e-02,
         3.6205e-02,  1.1406e-02,  2.2162e-02, -7.2881e-02, -7.4152e-02,
        -3.1925e-02, -9.0746e-02, -3.8565e-02, -5.7426e-02, -7.6188e-02,
         2.8086e-02, -9.7412e-02,  3.7272e-03,  4.8954e-02, -7.2434e-02,
        -1.1116e-02, -9.9622e-03, -1.1805e-02, -9.2613e-03, -4.7240e-02,
        -2.7796e-02, -5.9192e-02, -2.4451e-02, -2.0901e-02, -1.2778e-02,
        -3.9083e-03, -4.9874e-02, -7.1137e-02, -5.6351e-02, -3.1165e-02,
        -4.2186e-02, -4.6068e-03, -1.1817e-02, -4.9281e-02, -6.9791e-02,
        -9.6591e-04, -8.8149e-02, -3.3815e-02, -2.8021e-02,  1.2273e-03,
         1.9680e-02, -5.0249e-02, -1.0920e-02,  4.2709e-03, -7.5373e-02,
        -4.6747e-02, -2.9216e-02,  1.0119e-02, -5.1227e-02, -4.2235e-02,
        -3.7598e-02, -8.0181e-02, -2.5183e-02, -3.8555e-02, -6.6021e-02,
         5.1470e-02,  1.8155e-02,  2.9482e-02,  1.1846e-02, -3.1726e-02,
         1.7432e-02,  4.0623e-04, -8.2317e-02, -7.9923e-02,  1.8748e-02,
         9.3802e-03, -4.5680e-02, -8.1868e-02,  2.1231e-03,  3.6627e-02,
         3.4844e-02,  9.7667e-03, -1.0300e-02, -5.0217e-02, -4.4100e-02,
        -4.7510e-02, -1.1787e-02,  7.2929e-03, -2.1135e-02, -7.1774e-02,
        -9.2465e-02,  5.6026e-02,  1.2857e-02,  2.7100e-02, -1.0837e-02,
        -2.9473e-02, -2.4010e-02, -7.7591e-02, -1.5100e-03,  3.3535e-02,
        -1.0118e-02,  5.5450e-03,  4.4439e-02, -4.3729e-02, -7.8164e-02,
         1.0413e-04,  2.3446e-03, -8.6630e-02, -4.7420e-02, -7.8145e-03,
        -2.7881e-02, -1.4092e-02, -3.9468e-02, -2.7923e-02, -5.4969e-02,
         3.0592e-03, -6.1093e-02, -6.2600e-02,  4.9152e-02, -2.7361e-03,
        -5.2255e-02,  1.2719e-02, -1.8437e-02, -5.7770e-02,  2.7047e-02,
        -1.0165e-02,  1.3385e-02,  1.6178e-02, -6.3082e-02, -6.0487e-02,
         1.0428e-02,  1.4331e-03,  2.2913e-02,  2.1504e-02,  2.3841e-02,
        -6.7877e-02, -2.2181e-02,  6.3858e-03, -2.5927e-02, -4.6762e-02,
        -7.2281e-02, -3.9759e-02,  3.5262e-03, -4.1979e-02, -3.0924e-02,
        -5.8092e-02,  2.4263e-02, -4.3772e-02, -4.6146e-02,  3.3793e-02,
         5.0974e-02, -7.0345e-02, -3.8437e-02, -7.4465e-02, -3.5070e-02,
         2.7230e-02, -5.4205e-02, -8.5455e-02, -9.3170e-02,  3.3347e-02,
         2.9595e-02,  1.7656e-02,  5.2364e-02,  6.5309e-03, -1.8502e-02,
        -8.2051e-02,  1.8523e-03, -9.1035e-02, -7.7876e-02, -1.3717e-02,
         4.3281e-02, -3.7736e-02, -8.0556e-02, -2.5231e-02, -5.8585e-03,
        -8.0547e-02,  3.8337e-02, -5.5016e-03, -7.8983e-03, -2.6838e-03,
        -5.3058e-02, -6.8646e-02,  3.0947e-02,  3.9694e-02,  3.6897e-02,
         9.8741e-03,  1.9766e-02, -2.8305e-02, -3.6005e-02,  3.3412e-02,
        -2.7469e-02, -1.1273e-02, -3.0923e-03, -4.1021e-02, -4.4926e-02,
        -8.1387e-02,  1.8730e-02, -1.3407e-03, -6.0983e-02,  1.5738e-02,
        -6.0344e-02, -6.2445e-02,  3.0084e-02, -8.8719e-03,  3.5955e-02,
        -1.2592e-01, -4.6183e-02, -4.6509e-02, -9.1187e-02, -5.1436e-03,
        -2.4593e-02,  3.0180e-02, -7.7550e-02, -4.2064e-02, -3.4435e-03,
        -8.2157e-02, -4.3419e-02, -6.5225e-02,  4.3859e-02,  8.6541e-03,
         2.2967e-02,  1.9824e-02,  5.3734e-02, -7.9578e-02, -8.2389e-02,
        -1.1033e-01, -8.8812e-03, -6.0960e-02,  4.0689e-02, -7.1278e-04,
        -7.6997e-02,  1.7178e-02,  2.4233e-02,  3.5384e-02, -6.2866e-03,
         1.5801e-02, -7.8547e-02, -7.7767e-03, -7.0164e-02,  5.5516e-04,
        -2.1389e-02, -3.6559e-02,  4.5882e-02, -4.1270e-02, -9.7651e-02,
        -7.0487e-02, -1.2476e-02, -6.6610e-02,  4.0748e-02,  1.9540e-02,
        -2.6021e-02, -4.7469e-02, -3.7311e-02,  2.1838e-02, -8.3636e-02,
        -8.3586e-02,  5.2497e-02, -2.6372e-02, -4.8483e-03, -2.9646e-02,
        -2.1809e-02, -3.5893e-02,  1.8548e-03,  2.0258e-02,  6.7794e-03,
         3.1344e-03, -9.2190e-03,  3.6318e-03, -3.5271e-02, -4.0672e-03,
        -3.9952e-02,  2.7765e-02, -3.9599e-02, -7.4168e-02,  3.9091e-02,
        -5.8241e-03, -5.3059e-02, -6.5232e-03,  1.9484e-02, -4.7782e-02,
        -1.8691e-02, -4.8748e-02, -7.0920e-02, -4.6507e-03,  4.5186e-02,
         6.3959e-03, -6.1864e-02, -3.0437e-02, -2.5604e-02, -3.1638e-02,
        -1.0322e-01, -3.0263e-02,  1.8887e-02, -4.2279e-02, -7.2524e-02,
        -3.8389e-02, -9.7812e-02, -6.4893e-02, -8.9913e-02, -9.3076e-03,
         1.8828e-02, -5.1100e-02, -6.4058e-02,  1.9162e-03, -4.5621e-02,
         4.5895e-03, -1.2928e-02, -1.2669e-02, -9.0366e-02, -6.3053e-02,
         4.1130e-02,  3.1922e-02, -4.9452e-02, -1.1416e-02, -4.2890e-03,
        -3.2206e-02,  4.2317e-02, -6.1551e-02,  1.3029e-02,  2.9924e-02,
        -6.7280e-03, -6.2075e-02, -6.8202e-02,  1.0007e-02,  9.3753e-03,
        -4.8098e-03, -1.6142e-03,  2.6012e-02,  3.1275e-02, -3.7403e-02,
        -8.5651e-02,  4.9185e-02, -4.2665e-02, -6.8693e-02, -5.6057e-02,
        -5.7819e-02, -6.1788e-02, -1.3532e-01, -9.7251e-02,  4.7874e-02,
         6.5796e-03, -3.5668e-02, -7.5173e-02,  6.1326e-03, -4.4352e-02,
        -5.5205e-02, -1.0164e-01, -2.3721e-02, -6.1071e-02, -4.6853e-02,
        -6.3701e-02, -3.9766e-02, -3.5984e-02, -6.7800e-02,  4.8323e-02,
        -2.3871e-02,  3.8584e-02, -2.7926e-02, -5.2520e-02, -5.4480e-02,
         2.2122e-02, -9.1035e-02, -3.5930e-02, -6.5614e-03, -6.9080e-02,
        -1.8595e-02, -6.7756e-02, -8.2313e-02,  8.7555e-03, -9.5003e-02,
        -3.8149e-02, -4.9564e-02, -6.8733e-02,  3.1650e-02, -1.9080e-03,
         2.3939e-02,  3.7344e-02, -1.4904e-02, -7.5802e-03, -1.0077e-01,
         3.5496e-02,  4.9943e-02, -7.6733e-02, -5.5644e-02, -1.5837e-02,
        -4.0627e-02, -4.1949e-02, -3.1358e-02, -6.7344e-02,  4.0531e-02,
         6.1725e-02, -7.1692e-02, -6.8562e-03, -1.5106e-02,  1.1012e-02,
         2.4231e-02, -2.7163e-02,  4.0830e-02,  2.9777e-02,  8.6370e-03,
        -6.9607e-02, -8.8367e-02, -6.8310e-02, -4.6440e-02, -7.0283e-02,
        -1.8657e-02, -7.8685e-02, -4.9149e-02, -1.9931e-02,  2.2682e-02,
        -6.5784e-02, -1.0998e-01,  5.4124e-02, -1.0539e-02, -8.5732e-02,
         4.5414e-02,  4.9675e-03,  4.0027e-02, -4.6103e-02, -4.7476e-02,
         2.2711e-02, -4.8734e-02, -4.3181e-02, -6.0986e-02,  1.6615e-02,
        -2.8470e-02, -2.1841e-02, -4.9295e-02, -9.3829e-02,  4.9390e-02,
        -4.4774e-02, -4.4283e-02, -7.8649e-02, -7.4387e-02, -6.4420e-02,
        -9.7909e-02, -7.5089e-02,  2.8610e-02, -4.8706e-02, -6.0562e-02,
        -6.5352e-02, -7.8396e-03, -2.0984e-02, -1.0320e-01,  4.4973e-02,
         1.9555e-02,  5.3392e-02,  1.2471e-02, -6.6944e-02, -1.0040e-01,
        -2.5091e-02, -7.7659e-02,  1.5069e-02,  2.2563e-03, -2.9553e-02,
        -4.5011e-02, -4.0844e-02, -7.5845e-02, -6.4950e-02, -8.0017e-02,
        -4.1011e-02, -4.4695e-02, -4.2910e-02,  1.8297e-02,  2.2085e-02,
         2.4000e-02, -6.8763e-02,  1.5753e-03,  3.2306e-03,  4.2417e-02,
        -6.8471e-02, -3.3355e-03, -3.7102e-02, -9.0222e-02,  7.1762e-03,
        -6.9669e-03, -1.9121e-02, -5.7810e-02, -6.8577e-02, -8.4490e-02,
         2.1749e-02, -1.5009e-02, -5.8682e-02, -4.8152e-02,  7.0415e-05,
         3.5267e-02, -7.5325e-02, -6.9407e-02, -5.3857e-03, -6.7596e-02,
         1.0795e-02,  2.5196e-02, -9.6857e-04, -8.2847e-02,  7.9605e-02,
        -3.7925e-04, -2.1324e-02,  4.7655e-02,  1.9610e-02,  1.9876e-02,
         1.6085e-02,  3.0361e-02, -2.6438e-02], requires_grad=True))

Layer: encoder.0.1.block.1.2._packed_params._packed_params
Parameters: (tensor([[-0.0074,  0.0000,  0.0706,  ...,  0.0211, -0.0136, -0.0161],
        [-0.0074,  0.0322,  0.0334,  ...,  0.0334,  0.0248, -0.0272],
        [ 0.0111, -0.0161,  0.0359,  ...,  0.0087,  0.0371,  0.0235],
        ...,
        [-0.0050,  0.0582,  0.0235,  ...,  0.0012, -0.0087,  0.0074],
        [ 0.0235,  0.0371,  0.0334,  ...,  0.0161, -0.0099, -0.0087],
        [ 0.0235,  0.0087,  0.0136,  ..., -0.0359,  0.0495,  0.0198]],
       size=(192, 768), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0012382707791402936,
       zero_point=0), Parameter containing:
tensor([ 0.0024,  0.0251, -0.0255,  0.0078, -0.0193,  0.0038, -0.0276, -0.0142,
        -0.0235,  0.0115, -0.0273, -0.0201, -0.0298,  0.0008,  0.0208, -0.0202,
         0.0248, -0.0296, -0.0328, -0.0019, -0.0098, -0.0141,  0.0322, -0.0220,
        -0.0238,  0.0118,  0.0186,  0.0203, -0.0058,  0.0178,  0.0470, -0.0299,
        -0.0184, -0.0053, -0.0096, -0.0415,  0.0145,  0.0033,  0.0186, -0.0163,
         0.0195,  0.0340,  0.0279,  0.0190,  0.0198,  0.0077,  0.0395, -0.0188,
         0.0245, -0.0531,  0.0096, -0.0221,  0.0046, -0.0160, -0.0297, -0.0243,
        -0.0208,  0.0385,  0.0097, -0.0319, -0.0233,  0.0061,  0.0254,  0.0026,
        -0.0176,  0.0153,  0.0103, -0.0139,  0.0020,  0.0225,  0.0329, -0.0032,
        -0.0073,  0.0102,  0.0340, -0.0233,  0.0356, -0.0077,  0.0093, -0.0342,
         0.0200,  0.0148, -0.0012, -0.0053, -0.0181,  0.0366,  0.0418, -0.0101,
        -0.0186,  0.0052, -0.0292,  0.0075, -0.0249, -0.0323,  0.0051,  0.0144,
        -0.0031, -0.0042,  0.0319, -0.0113,  0.0113, -0.0178, -0.0043, -0.0149,
        -0.0257, -0.0227, -0.0306, -0.0359,  0.0176,  0.0264, -0.0358, -0.0226,
        -0.0464, -0.0030,  0.0062, -0.0131, -0.0010,  0.0093, -0.0039, -0.0011,
         0.0197, -0.0195, -0.0019, -0.0050,  0.0347,  0.0013,  0.0440,  0.0105,
         0.0490, -0.0058,  0.0139, -0.0181,  0.0294, -0.0005, -0.0265,  0.0119,
        -0.0171,  0.0335, -0.0115, -0.0236,  0.0264,  0.0177, -0.0201, -0.0292,
        -0.0287,  0.0434,  0.0137,  0.0408, -0.0107, -0.0535, -0.0079, -0.0067,
        -0.0322, -0.0249,  0.0021, -0.0074, -0.0091,  0.0185,  0.0141, -0.0065,
        -0.0158, -0.0214,  0.0198,  0.0250, -0.0186, -0.0194, -0.0241,  0.0214,
        -0.0039, -0.0075, -0.0273,  0.0163,  0.0319, -0.0302, -0.0036,  0.0054,
        -0.0197, -0.0310, -0.0192,  0.0236, -0.0374, -0.0161,  0.0293,  0.0375,
         0.0031, -0.0199, -0.0269,  0.0150,  0.0137,  0.0070, -0.0161,  0.0398],
       requires_grad=True))

