{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:45:36.631009Z",
     "start_time": "2024-05-02T17:45:36.615498Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import itertools # 是 Python 的內建模組，提供了一組用於處理迭代器的函數和工具。\n",
    "                 # 它包含了各種用於高效處理迭代器的函數，可以幫助我們編寫更簡潔、高效的代碼。\n",
    "import sys # 是 Python 的內建模組，提供了與 Python 解釋器和運行環境相關的功能。\n",
    "# sys.path 是一個列表，包含了 Python 解釋器在導入模組時會搜尋的路徑。\n",
    "# 當你使用 import 語句導入模組時 Python 會依次在 sys.path 中的路徑下尋找對應的模組文件。\n",
    "sys.path.append(\"../ecg-classification/\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\Chen_Lab01\\\\Documents\\\\GitHub/ecg-classification\")\n",
    "# from IPython.display import Video\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\") #  是 Matplotlib 庫中用於設置繪圖樣式的函數。它使用了一種名為 \"ggplot\" 的預定義樣式\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "                        #  該樣式模仿了 R 語言的 ggplot2 繪圖包的外觀。\n",
    "# print(sys.path)\n",
    "import torch\n",
    "from ecg_tools.config import EcgConfig, Mode\n",
    "from ecg_tools.data_loader import DatasetConfig, get_data_loaders\n",
    "from ecg_tools.model import ECGformer\n",
    "from ecg_tools.train import ECGClassifierTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb91b9dbfa94e3",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29bb12472624e7d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:45:36.599968Z",
     "start_time": "2024-05-02T17:45:36.552689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xaio\\anaconda3\\envs\\pytorch-ecg\\lib\\site-packages\\torch\\_utils.py:382: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ECGformer(\n",
       "  (encoder): ModuleList(\n",
       "    (0-5): 6 x TransformerEncoderLayer(\n",
       "      (0): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): MultiHeadAttention(\n",
       "            (queries_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (values_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (keys_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (final_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): MLP(\n",
       "            (0): DynamicQuantizedLinear(in_features=192, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): DynamicQuantizedLinear(in_features=768, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): DynamicQuantizedLinear(in_features=192, out_features=6, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       "  (embedding): LinearEmbedding(\n",
       "    (0): DynamicQuantizedLinear(in_features=1, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "config = EcgConfig()    \n",
    "model_quantized = torch.load(\"..\\\\model_save\\\\model_quantized_98.pth\")\n",
    "model_quantized.eval()\n",
    "model_quantized.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc775d31a626cf5",
   "metadata": {},
   "source": [
    "量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe171c96df432930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:45:36.646540Z",
     "start_time": "2024-05-02T17:45:36.632009Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch.quantization\n",
    "# \n",
    "# # 使用 Eager Mode Quantization\n",
    "# # 將 torch.nn.Linear 的參數映射到 -127~127 之間\n",
    "\n",
    "# quantized_model = torch.quantization.quantize_dynamic(\n",
    "#     model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "# )\n",
    "# \n",
    "# torch.save(quantized_model, \"..\\\\model_save\\\\model_quantized_98.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48981fc857f746e3",
   "metadata": {},
   "source": [
    "準確度測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd264a5e30443e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:45:45.195964Z",
     "start_time": "2024-05-02T17:45:45.163466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGformer(\n",
      "  (encoder): ModuleList(\n",
      "    (0-5): 6 x TransformerEncoderLayer(\n",
      "      (0): ResidualAdd(\n",
      "        (block): Sequential(\n",
      "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MultiHeadAttention(\n",
      "            (queries_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (values_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (keys_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (final_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualAdd(\n",
      "        (block): Sequential(\n",
      "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): MLP(\n",
      "            (0): DynamicQuantizedLinear(in_features=192, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): DynamicQuantizedLinear(in_features=768, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (0): Reduce('b n e -> b e', 'mean')\n",
      "    (1): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (3): DynamicQuantizedLinear(in_features=192, out_features=6, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (embedding): LinearEmbedding(\n",
      "    (0): DynamicQuantizedLinear(in_features=1, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780d3550eb5bc030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:46:44.541812Z",
     "start_time": "2024-05-02T17:46:02.718086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.3524,   0.4145,  -3.0895,  -4.2983,  -9.4119,  -1.2548],\n",
      "        [  1.0958,  -0.1882,  -1.5530,  -4.7840,  11.1596,  -2.5099],\n",
      "        [  7.6049,   5.1967,  -7.6189,  -1.4542, -12.6208,  -0.5748],\n",
      "        ...,\n",
      "        [  7.7039,  -1.6093,  -8.5180,  -0.1873, -11.5546,   4.4579],\n",
      "        [  7.1878,  -2.8949,  -1.0929,  -1.0383,  -8.1328,  -3.3142],\n",
      "        [  4.4404,  -1.4253,  -3.3040,   1.3546,  -8.0465,   0.5579]],\n",
      "       grad_fn=<WarnNotImplemented>)\n",
      "tensor([0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 5, 0, 2, 0, 4, 0, 0, 0, 0, 5, 5,\n",
      "        0, 0, 2, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 0,\n",
      "        0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 3, 0, 0, 0, 2,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0, 5, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 1, 0, 0, 4, 0, 5, 1,\n",
      "        2, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        2, 0, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0, 5, 0, 0, 0, 2, 0,\n",
      "        2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2,\n",
      "        0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 4, 0, 0, 0, 0, 4, 5, 0, 0, 2, 0, 1, 0, 4, 0, 5, 0, 0, 0, 2, 5,\n",
      "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 4, 0, 4, 4, 0, 0, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 2, 0, 0, 0, 2, 0, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0,\n",
      "        0, 0, 0, 2, 5, 0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0,\n",
      "        1, 0, 0, 2, 0, 0, 2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 4,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0,\n",
      "        0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 2, 4, 0, 0, 0, 0, 5, 0, 0, 5,\n",
      "        0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 5, 0, 2, 0, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 2,\n",
      "        0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 5, 4, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 2, 0,\n",
      "        4, 1, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([512, 187, 1]) torch.Size([512])\n",
      "tensor([ True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True])\n",
      "accuracy: 0.966796875\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "loader = get_data_loaders(DatasetConfig())\n",
    "accuracy = 0\n",
    "for signal, label in loader[Mode.train]:\n",
    "    signal.to('cpu')\n",
    "    label.to('cpu')\n",
    "    signal = einops.rearrange(signal, \"b c e -> b e c\")\n",
    "    # print(signal)\n",
    "    p = model_quantized(signal)\n",
    "    print(p)\n",
    "    print(label)\n",
    "    print(signal.shape, label.shape)\n",
    "    print(p.argmax(1) == label)\n",
    "    accuracy += torch.sum(p.argmax(1) == label)\n",
    "    print(f\"accuracy: {accuracy / config.dataset.batch_size}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize the model",
   "id": "379edaba6f750520"
  },
  {
   "cell_type": "markdown",
   "id": "bc9c7997add87778",
   "metadata": {},
   "source": [
    "Neutron 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "198696373b0fcab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T17:59:03.157956Z",
     "start_time": "2024-05-02T17:59:01.159666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'traced_resnet_model.pth' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 187, 1)\n",
    "traced_script_module = torch.jit.trace(model_quantized, inputs)\n",
    "traced_script_module.save(\"traced_resnet_model.pth\")\n",
    "\n",
    "import netron\n",
    "modelData = 'traced_resnet_model.pth'\n",
    "netron.start(modelData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235629a16d18a7d3",
   "metadata": {},
   "source": [
    "Grapviz 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b52a2d77913ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# vis_graph = make_dot(model_quantized(inputs), params=dict(model_quantized.named_parameters()), show_attrs=True, show_saved=True)\n",
    "# vis_graph.view()  # 会在当前目录下保存一个“Digraph.gv.pdf”文件，并在默认浏览器中打开"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18593e383e1153c3",
   "metadata": {},
   "source": "## Parameter Extraction"
  },
  {
   "cell_type": "markdown",
   "id": "9da43806140530cf",
   "metadata": {},
   "source": [
    "### 提取全部的參數(忽略量化的資訊)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff539acd7bfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    'scale',\n",
    "    'zero_point',\n",
    "    '_packed_params.dtype'\n",
    "]\n",
    "\n",
    "with open('model_layers_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if not any(ignore_key in layer_name for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\") \n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d3a51dac9641d",
   "metadata": {},
   "source": [
    "### 提取六層 Encoder 參數"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c3a2eb2b1a473e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:15:32.994183Z",
     "start_time": "2024-05-02T18:15:32.836748Z"
    }
   },
   "source": [
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    '.scale',\n",
    "    '.zero_point',\n",
    "    '._packed_params.dtype'\n",
    "]\n",
    "\n",
    "# Extract encoder.0 to encoder.5\n",
    "for i in range(6):\n",
    "    with open(f'encoder_{i}_params.txt', 'w') as f:\n",
    "        for layer_name, param_tensor in model_state_dict.items():\n",
    "            if layer_name.startswith(f'encoder.{i}') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "                f.write(f\"Layer: {layer_name}\\n\") \n",
    "                f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "# Extract classifier\n",
    "with open('classifier_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('classifier') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\") \n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract embedding.cls_token\n",
    "with open('cls_token_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name == 'embedding.cls_token':\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract embedding\n",
    "with open('embedding_params.txt', 'w') as f: \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('embedding') and layer_name != 'embedding.cls_token' and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract positional_encoding\n",
    "with open('pos_encoding_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('positional_encoding') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\") \n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
