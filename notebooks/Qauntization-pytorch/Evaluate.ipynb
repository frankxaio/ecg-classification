{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "9f24395e3322cf24"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-05T16:09:25.463860Z",
     "start_time": "2024-05-05T16:09:25.447833Z"
    }
   },
   "source": [
    "import itertools # 是 Python 的內建模組，提供了一組用於處理迭代器的函數和工具。\n",
    "                 # 它包含了各種用於高效處理迭代器的函數，可以幫助我們編寫更簡潔、高效的代碼。\n",
    "import sys # 是 Python 的內建模組，提供了與 Python 解釋器和運行環境相關的功能。\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# sys.path 是一個列表，包含了 Python 解釋器在導入模組時會搜尋的路徑。\n",
    "# 當你使用 import 語句導入模組時 Python 會依次在 sys.path 中的路徑下尋找對應的模組文件。\n",
    "sys.path.append(\"../ecg-classification/\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\Chen_Lab01\\\\Documents\\\\GitHub/ecg-classification\")\n",
    "# from IPython.display import Video\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\") #  是 Matplotlib 庫中用於設置繪圖樣式的函數。它使用了一種名為 \"ggplot\" 的預定義樣式\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "                        #  該樣式模仿了 R 語言的 ggplot2 繪圖包的外觀。\n",
    "# print(sys.path)\n",
    "import torch\n",
    "from ecg_tools.config import EcgConfig, Mode\n",
    "from ecg_tools.data_loader import DatasetConfig, get_data_loaders\n",
    "from ecg_tools.model import ECGformer\n",
    "from ecg_tools.train import ECGClassifierTrainer\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "adbb91b9dbfa94e3",
   "metadata": {},
   "source": "## Load model"
  },
  {
   "cell_type": "code",
   "id": "29bb12472624e7d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:18.098018Z",
     "start_time": "2024-05-05T16:10:18.066803Z"
    }
   },
   "source": [
    "import torch\n",
    "config = EcgConfig()    \n",
    "model_quantized = torch.load(\"..\\\\..\\\\model_save\\\\model_quantized_514.pth\")\n",
    "model = torch.load(\"..\\\\..\\\\model_save\\\\model_epoch_514.pth\")\n",
    "model_quantized.eval()\n",
    "model_quantized.to('cpu')\n",
    "model.eval()\n",
    "model.to('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xaio\\anaconda3\\envs\\pytorch-ecg\\lib\\site-packages\\torch\\_utils.py:382: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ECGformer(\n",
       "  (encoder): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (0): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): MultiHeadAttention(\n",
       "            (queries_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (values_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (keys_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (final_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): Linear(in_features=192, out_features=6, bias=True)\n",
       "  )\n",
       "  (embedding): LinearEmbedding(\n",
       "    (0): Linear(in_features=1, out_features=192, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "fdc775d31a626cf5",
   "metadata": {},
   "source": "## 量化模型"
  },
  {
   "cell_type": "code",
   "id": "fe171c96df432930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:16.130936Z",
     "start_time": "2024-05-05T16:10:16.099419Z"
    }
   },
   "source": [
    "import torch.quantization\n",
    "\n",
    "# 使用 Eager Mode Quantization\n",
    "# 將 torch.nn.Linear 的參數映射到 -127~127 之間\n",
    "\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "torch.save(model_quantized, \"..\\\\..\\\\model_save\\\\model_quantized_514.pth\")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 準確度測試",
   "id": "a041d1c91993f194"
  },
  {
   "cell_type": "code",
   "id": "780d3550eb5bc030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:43.469485Z",
     "start_time": "2024-05-05T16:10:41.494027Z"
    }
   },
   "source": [
    "import einops\n",
    "loader = get_data_loaders(DatasetConfig())\n",
    "accuracy = 0\n",
    "for signal, label in loader[Mode.eval]:\n",
    "    signal.to('cpu')\n",
    "    label.to('cpu')\n",
    "    signal = einops.rearrange(signal, \"b c e -> b e c\")\n",
    "    # print(signal)\n",
    "    p = model_quantized(signal)\n",
    "    # print(p)\n",
    "    print(label)\n",
    "    # print(signal.shape, label.shape)\n",
    "    # print(p.argmax(1) == label)\n",
    "    accuracy += torch.sum(p.argmax(1) == label)\n",
    "    print(f\"accuracy: {accuracy / config.dataset.batch_size}\")\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 4, 5, 0, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0, 0,\n",
      "        0, 0, 0, 4, 4, 5, 0, 4, 0, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 4, 0, 0, 5, 5,\n",
      "        0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0,\n",
      "        0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 2, 0, 2, 3, 0, 5, 2, 0,\n",
      "        0, 4, 0, 0, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 5,\n",
      "        0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 5, 4, 0, 5, 0, 1, 5, 0, 0, 0, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 5, 0, 0, 4,\n",
      "        1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 4, 5, 2, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        5, 0, 0, 0, 0, 5, 0, 0, 0, 2, 2, 0, 5, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0,\n",
      "        2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 1, 0, 0, 4,\n",
      "        0, 0, 5, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4,\n",
      "        0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 2, 2, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 5, 1, 0, 4, 0, 0, 0, 0, 0, 5, 5, 0,\n",
      "        4, 5, 4, 0, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 5, 0, 0, 0, 0, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 4, 0, 5, 0, 4, 4, 4, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 4, 2, 0, 0, 5, 4, 0, 5, 0, 5, 0,\n",
      "        0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 5, 0, 0,\n",
      "        1, 0, 4, 5, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 5, 0, 2, 0, 0, 5, 4, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0, 0,\n",
      "        4, 4, 0, 5, 0, 0, 0, 0])\n",
      "accuracy: 0.91015625\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## View Prameter",
   "id": "a8b7f2cf319ea7bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model layer",
   "id": "a64d994b3dd451d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:44.873561Z",
     "start_time": "2024-05-05T16:10:44.858425Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_quantized)",
   "id": "c5ba9693145ab0eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGformer(\n",
      "  (encoder): ModuleList(\n",
      "    (0): TransformerEncoderLayer(\n",
      "      (0): ResidualAdd(\n",
      "        (block): Sequential(\n",
      "          (0): MultiHeadAttention(\n",
      "            (queries_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (values_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (keys_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (final_projection): DynamicQuantizedLinear(in_features=192, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (1): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (0): Reduce('b n e -> b e', 'mean')\n",
      "    (1): DynamicQuantizedLinear(in_features=192, out_features=6, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (embedding): LinearEmbedding(\n",
      "    (0): DynamicQuantizedLinear(in_features=1, out_features=192, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "字典形式的量化模型參數",
   "id": "a724a3db99f7bd99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:46.672534Z",
     "start_time": "2024-05-05T16:10:46.656512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 量化\n",
    "for param_name, param_tensor in model_quantized.state_dict().items():\n",
    "    print(f\"{param_name}\")"
   ],
   "id": "f3513f473313dc22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_encoding\n",
      "encoder.0.0.block.0.queries_projection.scale\n",
      "encoder.0.0.block.0.queries_projection.zero_point\n",
      "encoder.0.0.block.0.queries_projection._packed_params.dtype\n",
      "encoder.0.0.block.0.queries_projection._packed_params._packed_params\n",
      "encoder.0.0.block.0.values_projection.scale\n",
      "encoder.0.0.block.0.values_projection.zero_point\n",
      "encoder.0.0.block.0.values_projection._packed_params.dtype\n",
      "encoder.0.0.block.0.values_projection._packed_params._packed_params\n",
      "encoder.0.0.block.0.keys_projection.scale\n",
      "encoder.0.0.block.0.keys_projection.zero_point\n",
      "encoder.0.0.block.0.keys_projection._packed_params.dtype\n",
      "encoder.0.0.block.0.keys_projection._packed_params._packed_params\n",
      "encoder.0.0.block.0.final_projection.scale\n",
      "encoder.0.0.block.0.final_projection.zero_point\n",
      "encoder.0.0.block.0.final_projection._packed_params.dtype\n",
      "encoder.0.0.block.0.final_projection._packed_params._packed_params\n",
      "classifier.1.scale\n",
      "classifier.1.zero_point\n",
      "classifier.1._packed_params.dtype\n",
      "classifier.1._packed_params._packed_params\n",
      "embedding.cls_token\n",
      "embedding.0.scale\n",
      "embedding.0.zero_point\n",
      "embedding.0._packed_params.dtype\n",
      "embedding.0._packed_params._packed_params\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "字典形式的非量化模型參數",
   "id": "d308ce0f9be7ec25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:10:48.794035Z",
     "start_time": "2024-05-05T16:10:48.778515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 未量化\n",
    "for param_name, param_tensor in model.state_dict().items():\n",
    "    print(f\"{param_name}\")"
   ],
   "id": "f4dd095dd96a7ee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_encoding\n",
      "encoder.0.0.block.0.queries_projection.weight\n",
      "encoder.0.0.block.0.queries_projection.bias\n",
      "encoder.0.0.block.0.values_projection.weight\n",
      "encoder.0.0.block.0.values_projection.bias\n",
      "encoder.0.0.block.0.keys_projection.weight\n",
      "encoder.0.0.block.0.keys_projection.bias\n",
      "encoder.0.0.block.0.final_projection.weight\n",
      "encoder.0.0.block.0.final_projection.bias\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "embedding.cls_token\n",
      "embedding.0.weight\n",
      "embedding.0.bias\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Packed_params",
   "id": "4ab7fe9f2a642014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:12:09.862642Z",
     "start_time": "2024-05-05T16:12:09.846638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "weight_tensor_after = model_quantized.state_dict()['encoder.0.0.block.0.final_projection._packed_params._packed_params']\n",
    "\n",
    "# packed_params = model_quantized.encoder[0][0].block[0].queries_projection._packed_params._packed_params\n",
    "\n",
    "# Unpack the quantized weights and biases\n",
    "int8_weights, int8_bias = torch.ops.quantized.linear_unpack(packed_params)\n",
    "int8_weights_nd = np.array(int8_weights.int_repr())\n",
    "int8_bias_nd = int8_bias.detach().numpy()\n",
    "# # Dequantize the weights and biases\n",
    "# weights = int8_weights.dequantize()\n",
    "# bias = int8_bias.dequantize()\n",
    "\n",
    "print(int8_weights_nd)#　將量化後的權重轉換為整數表示並轉化為numpy# array\n",
    "print(int8_weights.q_scale()) #　獲取量化的scale\n",
    "print(int8_bias_nd)"
   ],
   "id": "d95afa5238bac0f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-42  -3 -34 ...  47 -26  45]\n",
      " [ -3  35  49 ... -25 -14  -5]\n",
      " [-46   0  65 ...  -3 -46  -7]\n",
      " ...\n",
      " [-42 -53 -29 ...  63  31 -18]\n",
      " [-29 -12  33 ... -13  -4 -59]\n",
      " [ 47 -44  -7 ... -15  -7  72]]\n",
      "0.002547278068959713\n",
      "[ 2.76264194e-02 -1.50640868e-02  2.36732177e-02 -4.16285247e-02\n",
      " -9.68751237e-02 -6.39410689e-03  7.23048225e-02  3.04073021e-02\n",
      "  8.90213698e-02  8.84827450e-02  3.40902731e-02 -2.42512487e-02\n",
      " -1.82843618e-02  4.40333150e-02 -1.12877481e-01  6.32806048e-02\n",
      " -1.18590131e-01  2.13804916e-02  9.12774652e-02  3.27855311e-02\n",
      " -3.75162507e-03  8.36397409e-02 -7.19515085e-02 -4.94827293e-02\n",
      " -5.01286052e-02  9.37522650e-02  3.84955630e-02 -5.67657426e-02\n",
      " -3.72093171e-02 -1.19285844e-01 -1.22359887e-01  1.18478209e-01\n",
      " -3.09927985e-02 -3.90720740e-02 -5.76000614e-03  4.45648730e-02\n",
      " -4.18479927e-02  5.85773773e-02 -3.81090641e-02 -1.30418077e-01\n",
      " -1.64908096e-01  8.50265659e-03 -2.93765217e-02 -3.66923995e-02\n",
      "  5.49796373e-02 -5.08473366e-02  9.68353152e-02 -5.63802421e-02\n",
      "  7.01328442e-02 -8.85146409e-02  1.04189932e-01  1.09626278e-01\n",
      "  6.18076418e-03  6.99393824e-02 -2.91182231e-02  5.77959232e-02\n",
      "  3.25087085e-03  3.34530044e-03  1.09590404e-01  1.00825541e-01\n",
      " -9.67672169e-02  1.16898403e-01  3.47109288e-02  2.42217779e-02\n",
      " -1.37236997e-01 -5.95789775e-02 -9.01284963e-02  4.08832356e-02\n",
      " -1.12342827e-01 -3.07124145e-02  6.59073368e-02 -2.82647405e-02\n",
      "  1.12075768e-01  6.06942829e-03  5.90594066e-03 -4.41136658e-02\n",
      "  6.12145402e-02  2.56058406e-02  5.26378155e-02 -7.77551159e-03\n",
      "  1.09011836e-01 -2.06598770e-02 -3.44994888e-02 -9.05224234e-02\n",
      " -4.43830192e-02 -1.03614196e-01  1.04818633e-02  1.03290305e-01\n",
      " -4.43791524e-02 -1.54936323e-02  5.49041331e-02  6.33311123e-02\n",
      " -4.39922512e-02 -6.53266236e-02 -1.30747095e-01  2.33524758e-02\n",
      " -1.80509668e-02  2.64757369e-02  4.99695092e-02  4.29809578e-02\n",
      " -6.88523520e-03 -1.29467830e-01  4.45265099e-02 -2.51133437e-03\n",
      " -1.80923492e-02  1.47070512e-02 -3.84587422e-02  1.71301197e-02\n",
      "  1.14575125e-01 -4.37682904e-02  8.40153545e-03  9.55372751e-02\n",
      " -4.15951461e-02 -1.89519823e-02  6.89818636e-02  2.18929872e-02\n",
      "  7.32886866e-02 -1.27885208e-01  9.63279791e-03  1.41751423e-01\n",
      "  1.15460284e-01  1.47668794e-02  7.17667043e-02 -1.18565366e-01\n",
      " -7.37563893e-02 -3.55101079e-02  1.47604614e-01 -1.32167891e-01\n",
      " -5.31169958e-02  9.61560234e-02  1.03492640e-01  4.91600260e-02\n",
      "  9.19121504e-03  1.85595434e-02  1.06106177e-01 -8.09863880e-02\n",
      "  3.30001637e-02 -7.19208550e-03 -2.98607834e-02  1.19686520e-04\n",
      " -6.44788099e-03  1.75253414e-02 -2.54108161e-02  1.37938990e-03\n",
      "  4.37884964e-02 -8.10883641e-02 -5.04069263e-03 -5.34810461e-02\n",
      "  1.48714155e-01 -4.74633761e-02 -4.92383018e-02  4.89311218e-02\n",
      "  7.23815858e-02 -5.24580218e-02 -8.75691324e-03  3.50144170e-02\n",
      "  7.78234378e-02 -6.88199326e-02  9.86877009e-02 -2.56379619e-02\n",
      "  4.55747470e-02  4.44428287e-02 -6.15271702e-02  5.15152104e-02\n",
      "  2.13596392e-02 -2.15402413e-02 -1.71790510e-01 -7.91909546e-02\n",
      "  1.38992881e-02  7.62942806e-02 -1.02236249e-01  2.26970837e-02\n",
      "  2.82744374e-02  1.24196962e-01  1.02276430e-02 -3.52637209e-02\n",
      " -8.67636222e-03  6.80543259e-02 -4.64643389e-02  8.04557949e-02\n",
      " -3.64699736e-02 -1.06286861e-01 -8.94929767e-02  1.08567864e-01\n",
      " -1.78398907e-01 -9.18807834e-02  1.41049456e-02 -1.05025887e-01\n",
      "  6.12349249e-02 -1.17154948e-01 -1.43648878e-01  7.77924955e-02]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:13:43.079848Z",
     "start_time": "2024-05-05T16:13:43.064794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param_name, param_tensor in model_quantized.state_dict().items():\n",
    "    if isinstance(param_tensor, torch.Tensor):\n",
    "        if not any(special_param in param_name for special_param in ['scale', 'zero_point', 'dtype', '_packed_params']):\n",
    "            print(f\"{param_name}\\t{param_tensor.size()}\")"
   ],
   "id": "93d323b07c1341c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_encoding\ttorch.Size([188, 192])\n",
      "embedding.cls_token\ttorch.Size([1, 192])\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "印出模型中所有的weights和bias",
   "id": "9ec3ae45807205c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:13:50.177693Z",
     "start_time": "2024-05-05T16:13:50.162178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model_quantized.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Weight: {param.data}\")\n",
    "    elif 'bias' in name:\n",
    "        print(f\"Layer: {name}\") \n",
    "        print(f\"Bias: {param.data}\")\n"
   ],
   "id": "42b88a0cb1bf2fa3",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:13:52.202141Z",
     "start_time": "2024-05-05T16:13:52.156062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for var_name in model_quantized.state_dict():\n",
    "    print(var_name, \"\\t\", model_quantized.state_dict()[var_name])"
   ],
   "id": "306fd264326966ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_encoding \t tensor([[-0.0750, -0.6766,  1.1748,  ..., -0.7591,  0.4770,  1.1972],\n",
      "        [ 0.4876, -0.0935, -0.0709,  ..., -1.6422, -0.6370,  0.2193],\n",
      "        [ 0.1016, -0.3014, -1.2248,  ...,  0.0405,  0.0135,  0.0560],\n",
      "        ...,\n",
      "        [-0.9791, -0.4300,  2.5149,  ..., -0.5010, -0.1276, -0.1874],\n",
      "        [ 0.7474, -0.0472, -0.2595,  ...,  0.3718,  0.6861,  0.8468],\n",
      "        [-0.9776,  1.3116, -0.2996,  ...,  0.0887,  0.0717,  0.1684]])\n",
      "encoder.0.0.block.0.queries_projection.scale \t tensor(1.)\n",
      "encoder.0.0.block.0.queries_projection.zero_point \t tensor(0)\n",
      "encoder.0.0.block.0.queries_projection._packed_params.dtype \t torch.qint8\n",
      "encoder.0.0.block.0.queries_projection._packed_params._packed_params \t (tensor([[-0.1070, -0.0076, -0.0866,  ...,  0.1197, -0.0662,  0.1146],\n",
      "        [-0.0076,  0.0892,  0.1248,  ..., -0.0637, -0.0357, -0.0127],\n",
      "        [-0.1172,  0.0000,  0.1656,  ..., -0.0076, -0.1172, -0.0178],\n",
      "        ...,\n",
      "        [-0.1070, -0.1350, -0.0739,  ...,  0.1605,  0.0790, -0.0459],\n",
      "        [-0.0739, -0.0306,  0.0841,  ..., -0.0331, -0.0102, -0.1503],\n",
      "        [ 0.1197, -0.1121, -0.0178,  ..., -0.0382, -0.0178,  0.1834]],\n",
      "       size=(192, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.002547278068959713,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 2.7626e-02, -1.5064e-02,  2.3673e-02, -4.1629e-02, -9.6875e-02,\n",
      "        -6.3941e-03,  7.2305e-02,  3.0407e-02,  8.9021e-02,  8.8483e-02,\n",
      "         3.4090e-02, -2.4251e-02, -1.8284e-02,  4.4033e-02, -1.1288e-01,\n",
      "         6.3281e-02, -1.1859e-01,  2.1380e-02,  9.1277e-02,  3.2786e-02,\n",
      "        -3.7516e-03,  8.3640e-02, -7.1952e-02, -4.9483e-02, -5.0129e-02,\n",
      "         9.3752e-02,  3.8496e-02, -5.6766e-02, -3.7209e-02, -1.1929e-01,\n",
      "        -1.2236e-01,  1.1848e-01, -3.0993e-02, -3.9072e-02, -5.7600e-03,\n",
      "         4.4565e-02, -4.1848e-02,  5.8577e-02, -3.8109e-02, -1.3042e-01,\n",
      "        -1.6491e-01,  8.5027e-03, -2.9377e-02, -3.6692e-02,  5.4980e-02,\n",
      "        -5.0847e-02,  9.6835e-02, -5.6380e-02,  7.0133e-02, -8.8515e-02,\n",
      "         1.0419e-01,  1.0963e-01,  6.1808e-03,  6.9939e-02, -2.9118e-02,\n",
      "         5.7796e-02,  3.2509e-03,  3.3453e-03,  1.0959e-01,  1.0083e-01,\n",
      "        -9.6767e-02,  1.1690e-01,  3.4711e-02,  2.4222e-02, -1.3724e-01,\n",
      "        -5.9579e-02, -9.0128e-02,  4.0883e-02, -1.1234e-01, -3.0712e-02,\n",
      "         6.5907e-02, -2.8265e-02,  1.1208e-01,  6.0694e-03,  5.9059e-03,\n",
      "        -4.4114e-02,  6.1215e-02,  2.5606e-02,  5.2638e-02, -7.7755e-03,\n",
      "         1.0901e-01, -2.0660e-02, -3.4499e-02, -9.0522e-02, -4.4383e-02,\n",
      "        -1.0361e-01,  1.0482e-02,  1.0329e-01, -4.4379e-02, -1.5494e-02,\n",
      "         5.4904e-02,  6.3331e-02, -4.3992e-02, -6.5327e-02, -1.3075e-01,\n",
      "         2.3352e-02, -1.8051e-02,  2.6476e-02,  4.9970e-02,  4.2981e-02,\n",
      "        -6.8852e-03, -1.2947e-01,  4.4527e-02, -2.5113e-03, -1.8092e-02,\n",
      "         1.4707e-02, -3.8459e-02,  1.7130e-02,  1.1458e-01, -4.3768e-02,\n",
      "         8.4015e-03,  9.5537e-02, -4.1595e-02, -1.8952e-02,  6.8982e-02,\n",
      "         2.1893e-02,  7.3289e-02, -1.2789e-01,  9.6328e-03,  1.4175e-01,\n",
      "         1.1546e-01,  1.4767e-02,  7.1767e-02, -1.1857e-01, -7.3756e-02,\n",
      "        -3.5510e-02,  1.4760e-01, -1.3217e-01, -5.3117e-02,  9.6156e-02,\n",
      "         1.0349e-01,  4.9160e-02,  9.1912e-03,  1.8560e-02,  1.0611e-01,\n",
      "        -8.0986e-02,  3.3000e-02, -7.1921e-03, -2.9861e-02,  1.1969e-04,\n",
      "        -6.4479e-03,  1.7525e-02, -2.5411e-02,  1.3794e-03,  4.3788e-02,\n",
      "        -8.1088e-02, -5.0407e-03, -5.3481e-02,  1.4871e-01, -4.7463e-02,\n",
      "        -4.9238e-02,  4.8931e-02,  7.2382e-02, -5.2458e-02, -8.7569e-03,\n",
      "         3.5014e-02,  7.7823e-02, -6.8820e-02,  9.8688e-02, -2.5638e-02,\n",
      "         4.5575e-02,  4.4443e-02, -6.1527e-02,  5.1515e-02,  2.1360e-02,\n",
      "        -2.1540e-02, -1.7179e-01, -7.9191e-02,  1.3899e-02,  7.6294e-02,\n",
      "        -1.0224e-01,  2.2697e-02,  2.8274e-02,  1.2420e-01,  1.0228e-02,\n",
      "        -3.5264e-02, -8.6764e-03,  6.8054e-02, -4.6464e-02,  8.0456e-02,\n",
      "        -3.6470e-02, -1.0629e-01, -8.9493e-02,  1.0857e-01, -1.7840e-01,\n",
      "        -9.1881e-02,  1.4105e-02, -1.0503e-01,  6.1235e-02, -1.1715e-01,\n",
      "        -1.4365e-01,  7.7792e-02], requires_grad=True))\n",
      "encoder.0.0.block.0.values_projection.scale \t tensor(1.)\n",
      "encoder.0.0.block.0.values_projection.zero_point \t tensor(0)\n",
      "encoder.0.0.block.0.values_projection._packed_params.dtype \t torch.qint8\n",
      "encoder.0.0.block.0.values_projection._packed_params._packed_params \t (tensor([[ 0.0000,  0.0847,  0.7111,  ..., -0.0508,  0.0000, -0.0339],\n",
      "        [ 0.1524, -0.0847,  0.2878,  ...,  0.0339,  0.3894,  0.2540],\n",
      "        [ 0.0508,  0.1354, -0.1185,  ..., -0.0847,  0.5249, -0.5249],\n",
      "        ...,\n",
      "        [-0.4063, -0.0847,  0.0169,  ...,  0.0339, -1.2359, -0.1693],\n",
      "        [-0.0508, -0.1016, -0.4063,  ...,  0.1016,  0.4910,  0.1016],\n",
      "        [ 0.3048,  0.0677,  0.1354,  ...,  0.1016,  0.7280,  0.0169]],\n",
      "       size=(192, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0169307179749012,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([-0.0136, -0.0370, -0.0164,  0.0314,  0.0837, -0.0363,  0.0061, -0.0603,\n",
      "        -0.0306, -0.0405,  0.0129, -0.0222,  0.0737,  0.0301, -0.0237, -0.0295,\n",
      "         0.0348,  0.0173, -0.0691, -0.0170,  0.0109,  0.0395, -0.0758, -0.0414,\n",
      "        -0.1161, -0.0228,  0.0108, -0.0256, -0.0368,  0.0238,  0.0396, -0.0111,\n",
      "        -0.1006,  0.0630, -0.0232, -0.0051,  0.0257, -0.0237, -0.1323, -0.0646,\n",
      "        -0.0203, -0.0770, -0.1207, -0.0219, -0.0135,  0.0280, -0.0143,  0.0406,\n",
      "        -0.0759,  0.0342,  0.0091, -0.0183,  0.0162, -0.0099, -0.0351, -0.0128,\n",
      "         0.0117, -0.0430, -0.0137,  0.0044,  0.0428,  0.0157,  0.0712, -0.0495,\n",
      "        -0.0534,  0.0704,  0.0505,  0.0385, -0.0328, -0.0737, -0.0825,  0.0212,\n",
      "        -0.0281,  0.0070,  0.0278, -0.0177, -0.0622, -0.0153, -0.0413,  0.0629,\n",
      "        -0.0842, -0.0571,  0.0429, -0.0226, -0.0632,  0.0448,  0.0052,  0.0643,\n",
      "        -0.0818, -0.0481,  0.0502, -0.0028,  0.0759,  0.0510, -0.1074,  0.0401,\n",
      "         0.0333, -0.0169, -0.0199, -0.0230, -0.0007, -0.0464, -0.0242, -0.0633,\n",
      "        -0.0365,  0.0502, -0.0016,  0.0306, -0.0457, -0.0553, -0.0706, -0.0069,\n",
      "        -0.0527, -0.0258,  0.0461,  0.0028, -0.0797,  0.0266,  0.0139,  0.0061,\n",
      "        -0.0932,  0.0410, -0.0121, -0.0447,  0.0729, -0.0115,  0.0266, -0.0206,\n",
      "        -0.0520, -0.0040,  0.0182, -0.0145, -0.0134, -0.0069, -0.0006,  0.0506,\n",
      "         0.0211, -0.0183, -0.0578, -0.0017, -0.0463,  0.0140,  0.0285,  0.0229,\n",
      "        -0.0385,  0.0117,  0.0042, -0.0331, -0.0745, -0.1022, -0.0147, -0.0485,\n",
      "        -0.0776,  0.0126, -0.0553,  0.0239,  0.0372, -0.0267, -0.0598, -0.0783,\n",
      "         0.0248,  0.0429, -0.0915, -0.0717, -0.0306, -0.0566, -0.0646, -0.0417,\n",
      "        -0.0850, -0.0311, -0.0466, -0.0580, -0.1017,  0.0757,  0.0832, -0.0734,\n",
      "         0.0664,  0.0559,  0.0157,  0.0259,  0.0107,  0.0480,  0.0168,  0.0090,\n",
      "         0.0649, -0.0759,  0.0273,  0.0069,  0.0734,  0.0360, -0.0631, -0.0144],\n",
      "       requires_grad=True))\n",
      "encoder.0.0.block.0.keys_projection.scale \t tensor(1.)\n",
      "encoder.0.0.block.0.keys_projection.zero_point \t tensor(0)\n",
      "encoder.0.0.block.0.keys_projection._packed_params.dtype \t torch.qint8\n",
      "encoder.0.0.block.0.keys_projection._packed_params._packed_params \t (tensor([[-0.1389,  0.1119,  0.1698,  ...,  0.0772,  0.0154, -0.0039],\n",
      "        [-0.0887, -0.0540, -0.0540,  ..., -0.0309,  0.0039, -0.1543],\n",
      "        [-0.0154, -0.0887, -0.0695,  ...,  0.1119, -0.0579, -0.2199],\n",
      "        ...,\n",
      "        [-0.0656, -0.0154, -0.0887,  ..., -0.0154,  0.1505,  0.1003],\n",
      "        [ 0.0347,  0.0502, -0.0424,  ..., -0.1003,  0.1389,  0.0232],\n",
      "        [ 0.0849, -0.0309,  0.0579,  ..., -0.1003,  0.0077,  0.1042]],\n",
      "       size=(192, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0038585274014621973,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([-0.0338, -0.0299, -0.2403, -0.2712,  0.3279, -0.1962, -0.1162, -0.1977,\n",
      "        -0.0505, -0.3909, -0.3219,  0.1944,  0.3427,  0.0137,  0.1636, -0.4012,\n",
      "         0.5875, -0.3210,  0.2253, -0.5103, -0.0504, -0.2399, -0.0345,  0.4046,\n",
      "        -0.1007, -0.0011,  0.2751, -0.2529,  0.1896,  0.2561,  0.5476, -0.0034,\n",
      "         0.1251, -0.2119, -0.0147, -0.1436,  0.3690, -0.1784, -0.0417, -0.0111,\n",
      "         0.5017, -0.1996, -0.2008,  0.1309,  0.0838, -0.4653, -0.0129, -0.1079,\n",
      "        -0.2561,  0.7458, -0.4800,  0.0768, -0.0250,  0.3080, -0.0055,  0.1052,\n",
      "         0.1044,  0.0137,  0.1235, -0.0122,  0.5175, -0.1033,  0.1758, -0.3050,\n",
      "         0.3532, -0.0491,  0.5522, -0.2275,  0.2604,  0.4824, -0.0939,  0.1393,\n",
      "         0.0347,  0.2390, -0.2840,  0.1172,  0.4432,  0.4911, -0.1457,  0.2937,\n",
      "         0.1406, -0.3850, -0.2748, -0.0674,  0.0541,  0.5212, -0.1500, -0.2392,\n",
      "        -0.1443,  0.0853,  0.0131, -0.1374,  0.1004,  0.0859,  0.0335, -0.1314,\n",
      "         0.1954, -0.1439, -0.0168,  0.2147,  0.1956,  0.1714, -0.1052, -0.3504,\n",
      "         0.4961,  0.1574,  0.2624, -0.4941, -0.0732, -0.2522,  0.0820, -0.1477,\n",
      "        -0.1341,  0.1101, -0.2783, -0.4239, -0.0048,  0.3377,  0.1631, -0.1978,\n",
      "        -0.3302, -0.3170,  0.0539, -0.1866, -0.2025,  0.2453, -0.3672,  0.1618,\n",
      "         0.1908, -0.0692,  0.0800,  0.3335,  0.1144, -0.1777,  0.3884, -0.1324,\n",
      "        -0.0410, -0.0389, -0.2095, -0.0406, -0.1156, -0.0587,  0.0756,  0.3420,\n",
      "        -0.0867, -0.2571, -0.4141, -0.1759, -0.4500, -0.0618, -0.5061, -0.0497,\n",
      "        -0.0767,  0.2064, -0.5550, -0.0731,  0.0475,  0.2542, -0.2867, -0.1607,\n",
      "        -0.4669, -0.1614, -0.2113, -0.1003,  0.1484,  0.0644,  0.3751,  0.2083,\n",
      "        -0.2752, -0.1328,  0.2518, -0.1429,  0.0550, -0.5600, -0.0464, -0.4579,\n",
      "        -0.1650, -0.3408, -0.1946, -0.0688, -0.0808,  0.4492,  0.3291, -0.2030,\n",
      "        -0.1537, -0.2906,  0.3276,  0.1461, -0.1286, -0.0972, -0.1019,  0.1204],\n",
      "       requires_grad=True))\n",
      "encoder.0.0.block.0.final_projection.scale \t tensor(1.)\n",
      "encoder.0.0.block.0.final_projection.zero_point \t tensor(0)\n",
      "encoder.0.0.block.0.final_projection._packed_params.dtype \t torch.qint8\n",
      "encoder.0.0.block.0.final_projection._packed_params._packed_params \t (tensor([[ 0.0702, -0.0153,  0.0691,  ..., -0.0328, -0.0198,  0.0662],\n",
      "        [ 0.0470, -0.0091, -0.0142,  ...,  0.0113,  0.0458,  0.0611],\n",
      "        [-0.0719, -0.0419, -0.0555,  ..., -0.0294,  0.0113,  0.0509],\n",
      "        ...,\n",
      "        [-0.0006, -0.0204,  0.0328,  ..., -0.0515,  0.0175,  0.0221],\n",
      "        [ 0.0023, -0.0147, -0.0447,  ..., -0.0051,  0.0634, -0.0091],\n",
      "        [-0.0408,  0.0340,  0.0311,  ..., -0.0136, -0.0589,  0.0226]],\n",
      "       size=(192, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0005660285241901875,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 3.6463e-02,  6.9682e-03,  4.2184e-02, -5.5638e-02, -6.8558e-03,\n",
      "         4.0863e-02, -3.6490e-02, -1.0714e-02,  5.8838e-02,  5.8433e-02,\n",
      "         4.3417e-02, -6.7871e-02,  1.2782e-02,  9.2343e-03,  4.3812e-02,\n",
      "        -1.9392e-03,  4.7862e-03, -7.0384e-02, -2.3515e-02,  3.3095e-02,\n",
      "         6.3870e-03, -2.4123e-02,  4.5468e-02,  4.3689e-02, -7.0452e-02,\n",
      "         1.2725e-02, -6.9898e-02, -3.5268e-02,  4.2376e-02, -5.1578e-02,\n",
      "        -4.8736e-02, -5.2146e-02, -6.2057e-02,  2.1077e-02,  4.4945e-02,\n",
      "        -5.2737e-02,  4.8716e-02,  4.1371e-02,  5.5212e-02,  5.0144e-02,\n",
      "        -5.4984e-02, -4.7596e-02, -1.7049e-02, -6.4559e-02,  3.7286e-02,\n",
      "         6.1845e-02,  2.9091e-02, -3.6376e-02,  2.9303e-02,  7.3845e-03,\n",
      "        -4.2364e-02,  1.4102e-02,  6.2476e-02, -6.1668e-02,  8.2024e-03,\n",
      "        -1.7822e-03,  1.3009e-02, -4.3330e-02, -3.2343e-03,  5.7426e-02,\n",
      "         2.1693e-02,  2.4566e-02,  1.7119e-02,  4.7828e-02, -3.2808e-02,\n",
      "        -4.2591e-02, -9.1087e-03, -2.9556e-02,  5.1340e-03, -9.5772e-03,\n",
      "         3.0132e-03,  3.9242e-02, -1.3927e-02,  6.7378e-02, -3.7392e-02,\n",
      "         2.5287e-02,  6.6416e-02,  5.3058e-02,  3.2295e-02, -4.8612e-02,\n",
      "         5.3657e-02,  2.3116e-02,  9.5137e-03,  6.2255e-03,  4.5999e-02,\n",
      "        -4.5522e-02,  6.2364e-02, -5.0652e-02,  2.2793e-02, -1.6056e-02,\n",
      "         2.8296e-02, -6.0407e-02, -1.2004e-02, -5.5109e-02, -1.1976e-02,\n",
      "        -3.1656e-03, -4.4026e-02, -2.9589e-02, -3.1882e-02,  1.7391e-02,\n",
      "        -6.7864e-02, -6.1896e-02,  3.7795e-02, -4.1420e-02, -3.9316e-02,\n",
      "        -6.4065e-02,  2.4475e-02, -4.7375e-02, -6.1575e-02, -5.4451e-02,\n",
      "        -4.9660e-02,  5.8485e-02, -3.1284e-02, -7.1152e-02,  7.4446e-03,\n",
      "        -2.2801e-02,  4.2704e-02,  1.4243e-02, -3.6576e-02,  3.1812e-02,\n",
      "         2.6885e-02, -5.7374e-04,  2.1002e-02,  6.9486e-02, -7.8652e-03,\n",
      "         5.8274e-02,  5.8263e-02, -6.1216e-02,  4.7795e-02, -1.4892e-02,\n",
      "        -4.1501e-02,  7.0301e-02,  4.6302e-02,  1.7182e-02, -2.7032e-02,\n",
      "         7.1311e-02, -1.4048e-02,  5.9207e-02,  1.0952e-03,  1.1512e-03,\n",
      "         3.0881e-02,  3.0758e-02,  5.6846e-02,  2.5651e-02,  4.5363e-02,\n",
      "        -3.1948e-02,  5.5145e-02,  1.0187e-02, -1.0160e-02, -5.7272e-02,\n",
      "        -8.9596e-03,  2.3616e-02, -2.8807e-02, -6.3283e-02, -4.9199e-02,\n",
      "        -4.0476e-02,  3.7816e-03,  5.5227e-02,  1.5462e-02, -1.5065e-02,\n",
      "         3.6788e-03,  4.7050e-02,  2.8274e-02, -1.1374e-02, -8.6287e-03,\n",
      "         3.7978e-02, -3.1322e-02,  1.6265e-02, -4.2698e-02, -7.0353e-03,\n",
      "         2.3925e-02, -5.1027e-03, -3.6607e-02, -5.1835e-02,  4.8918e-02,\n",
      "         7.0248e-02, -5.9191e-02,  2.4003e-02, -2.6007e-02, -2.4925e-02,\n",
      "        -5.0469e-02,  4.2679e-03, -6.9358e-02, -2.8051e-02,  2.2356e-03,\n",
      "         3.9505e-02,  5.3868e-02, -5.5134e-05,  5.6268e-04, -7.0041e-02,\n",
      "        -3.6217e-02,  4.3089e-02], requires_grad=True))\n",
      "classifier.1.scale \t tensor(1.)\n",
      "classifier.1.zero_point \t tensor(0)\n",
      "classifier.1._packed_params.dtype \t torch.qint8\n",
      "classifier.1._packed_params._packed_params \t (tensor([[ 0.0793,  0.0264,  0.1058,  ..., -0.1851,  0.1851, -0.0529],\n",
      "        [ 0.4495,  1.5336, -0.7932,  ..., -0.3437,  0.0529,  0.2115],\n",
      "        [-1.3485, -0.7668,  0.1058,  ...,  0.2909,  0.3173, -0.1851],\n",
      "        [-0.4231, -0.0529,  0.1851,  ..., -0.1058,  1.6393, -0.0793],\n",
      "        [ 0.1851, -0.5817, -0.1058,  ...,  1.4807,  0.2380, -0.3437],\n",
      "        [ 1.2427, -0.0529,  0.2380,  ...,  0.0000, -1.1105,  0.0264]],\n",
      "       size=(6, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.026441076770424843,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([-0.0908, -0.0645, -0.0345, -0.0601, -0.0912,  0.0351],\n",
      "       requires_grad=True))\n",
      "embedding.cls_token \t tensor([[-1.0392,  0.4478,  0.3949, -0.5078,  0.5773, -0.5205, -0.9324, -1.3846,\n",
      "         -1.1536,  0.4468,  0.0119,  0.2285, -0.3844,  0.4385,  0.4410,  0.0231,\n",
      "         -0.9561, -0.0279, -0.2806, -0.8993,  0.9000, -0.3888, -0.0452,  1.3966,\n",
      "          0.4333, -0.3760,  1.8336, -0.9976,  0.0526, -0.2613,  0.7596,  1.9604,\n",
      "          1.6255, -0.2494,  0.4295,  1.7336,  0.2127,  0.2037, -0.7481, -0.4152,\n",
      "         -1.8649,  1.9232, -0.6015,  0.9886, -0.9682, -1.1556,  0.6619,  0.4800,\n",
      "         -1.1815,  1.3855,  0.4690,  2.3255,  0.9610,  1.4623, -0.6400,  1.1323,\n",
      "         -0.0767, -0.7745, -0.0548, -0.6235, -0.9601, -1.3235,  1.4542, -0.3855,\n",
      "          0.5459, -0.3337,  1.3173,  0.0489,  0.8489,  0.0829,  0.3222, -0.1766,\n",
      "          0.2132,  0.5505,  0.0621, -0.6120, -0.4539,  0.6683, -1.5497, -1.5172,\n",
      "         -0.6152,  0.4697, -1.2358,  0.9305, -1.4251, -0.7043,  0.1887,  1.9007,\n",
      "         -0.4762, -0.2645, -1.6258, -0.2321, -0.8551, -0.2164,  0.5391, -1.3734,\n",
      "         -0.6718, -1.4954,  0.2999, -0.8838, -0.2478, -0.6595, -0.8796,  0.9258,\n",
      "          0.5396,  1.0267, -0.7498, -0.0817,  0.8011,  1.4669,  1.5495, -0.9861,\n",
      "         -0.3230,  0.4990,  0.0042,  0.6090, -0.8713, -0.7474, -1.9799,  1.7080,\n",
      "         -1.0921,  0.4602,  0.8398,  1.8204,  1.1799,  0.2426,  0.0425, -0.5789,\n",
      "         -1.6509, -0.4097, -0.2258,  0.6393,  0.5106,  0.7618,  1.7091, -0.6918,\n",
      "          1.4394,  0.8629,  0.8463,  0.3330, -1.0421, -0.6669,  0.9732, -1.0559,\n",
      "         -0.8422, -1.0499, -0.4549,  0.0364, -1.3033,  0.1922,  0.1137,  1.4107,\n",
      "         -0.5399,  0.0368,  1.2587,  0.4901, -2.0767, -0.6139,  0.9215, -0.7152,\n",
      "          1.1396, -0.4490,  0.5023, -0.2047,  0.5230, -1.3906,  0.2609,  0.3410,\n",
      "         -1.0873,  0.4648, -2.4497, -0.9842,  0.1189, -0.6264, -0.0155,  0.0966,\n",
      "          0.3641,  2.2811, -0.1395, -0.2543,  0.9818, -0.1716, -0.4116, -0.2382,\n",
      "         -1.2944, -1.4214, -1.7697,  0.4948, -1.6490,  0.2716, -1.0785,  1.0358]])\n",
      "embedding.0.scale \t tensor(1.)\n",
      "embedding.0.zero_point \t tensor(0)\n",
      "embedding.0._packed_params.dtype \t torch.qint8\n",
      "embedding.0._packed_params._packed_params \t (tensor([[-0.2089],\n",
      "        [-0.2437],\n",
      "        [-1.4620],\n",
      "        [-1.0617],\n",
      "        [ 0.1915],\n",
      "        [ 1.0443],\n",
      "        [-1.3576],\n",
      "        [-1.8971],\n",
      "        [ 1.8275],\n",
      "        [ 0.6440],\n",
      "        [ 1.3402],\n",
      "        [ 0.3133],\n",
      "        [ 0.3655],\n",
      "        [ 0.5918],\n",
      "        [ 0.6440],\n",
      "        [-0.8876],\n",
      "        [-0.2263],\n",
      "        [ 0.8354],\n",
      "        [ 0.7658],\n",
      "        [ 0.0000],\n",
      "        [-0.8354],\n",
      "        [ 0.1218],\n",
      "        [-1.5838],\n",
      "        [ 0.1218],\n",
      "        [-0.1915],\n",
      "        [-1.7753],\n",
      "        [-0.5918],\n",
      "        [-0.6614],\n",
      "        [ 0.4873],\n",
      "        [-0.5918],\n",
      "        [ 0.8006],\n",
      "        [ 0.2437],\n",
      "        [-0.0174],\n",
      "        [-0.4351],\n",
      "        [ 0.3829],\n",
      "        [ 0.0696],\n",
      "        [-1.1139],\n",
      "        [ 0.6092],\n",
      "        [-0.5744],\n",
      "        [-0.9225],\n",
      "        [ 1.1835],\n",
      "        [ 0.4699],\n",
      "        [-1.1313],\n",
      "        [-0.0522],\n",
      "        [ 0.2959],\n",
      "        [-0.4177],\n",
      "        [ 0.6266],\n",
      "        [ 0.5221],\n",
      "        [ 1.4446],\n",
      "        [ 0.4351],\n",
      "        [ 0.7310],\n",
      "        [ 1.2880],\n",
      "        [-0.9573],\n",
      "        [-0.7658],\n",
      "        [-0.5396],\n",
      "        [-1.3054],\n",
      "        [-2.1408],\n",
      "        [-0.0522],\n",
      "        [-0.1915],\n",
      "        [-1.8101],\n",
      "        [ 0.3307],\n",
      "        [-1.4968],\n",
      "        [-0.9051],\n",
      "        [-1.1487],\n",
      "        [-0.1218],\n",
      "        [-0.5744],\n",
      "        [ 0.4699],\n",
      "        [-1.0617],\n",
      "        [-0.1392],\n",
      "        [ 0.2263],\n",
      "        [ 0.1740],\n",
      "        [ 0.1392],\n",
      "        [ 0.6788],\n",
      "        [ 0.4177],\n",
      "        [-0.0696],\n",
      "        [-0.3655],\n",
      "        [-0.1218],\n",
      "        [-0.6440],\n",
      "        [-1.3054],\n",
      "        [-0.6614],\n",
      "        [-1.8101],\n",
      "        [-1.8449],\n",
      "        [-0.3133],\n",
      "        [-0.4699],\n",
      "        [-0.0870],\n",
      "        [-1.3054],\n",
      "        [ 0.9051],\n",
      "        [ 1.3402],\n",
      "        [-1.1487],\n",
      "        [-0.9747],\n",
      "        [ 0.4003],\n",
      "        [ 1.3924],\n",
      "        [ 0.1740],\n",
      "        [ 0.0000],\n",
      "        [ 0.8180],\n",
      "        [-0.1740],\n",
      "        [-0.7832],\n",
      "        [-1.0269],\n",
      "        [-0.4351],\n",
      "        [-0.2959],\n",
      "        [-1.5490],\n",
      "        [ 1.2357],\n",
      "        [-0.4873],\n",
      "        [ 1.0095],\n",
      "        [-1.0095],\n",
      "        [-1.3402],\n",
      "        [-0.9225],\n",
      "        [-0.3307],\n",
      "        [ 0.0174],\n",
      "        [ 0.9051],\n",
      "        [-1.1487],\n",
      "        [ 0.2785],\n",
      "        [ 0.0348],\n",
      "        [ 0.1392],\n",
      "        [ 0.1044],\n",
      "        [ 0.6440],\n",
      "        [ 0.7832],\n",
      "        [-1.5316],\n",
      "        [-0.6614],\n",
      "        [ 0.6440],\n",
      "        [ 0.7310],\n",
      "        [-0.1392],\n",
      "        [ 0.7832],\n",
      "        [ 1.4794],\n",
      "        [ 1.1661],\n",
      "        [ 0.0000],\n",
      "        [ 0.7658],\n",
      "        [ 0.9225],\n",
      "        [-1.8971],\n",
      "        [ 0.1566],\n",
      "        [-0.3655],\n",
      "        [-1.0269],\n",
      "        [ 0.9399],\n",
      "        [-0.1566],\n",
      "        [-0.3133],\n",
      "        [-1.3054],\n",
      "        [-0.5047],\n",
      "        [-0.8006],\n",
      "        [-1.1661],\n",
      "        [ 0.2437],\n",
      "        [ 0.7484],\n",
      "        [ 1.3576],\n",
      "        [-1.9145],\n",
      "        [-0.4525],\n",
      "        [ 1.2183],\n",
      "        [ 1.5142],\n",
      "        [-0.8180],\n",
      "        [ 0.5047],\n",
      "        [-0.4525],\n",
      "        [ 0.3133],\n",
      "        [-0.3133],\n",
      "        [ 1.4446],\n",
      "        [-0.6614],\n",
      "        [-0.4699],\n",
      "        [ 0.3655],\n",
      "        [ 1.5490],\n",
      "        [-0.8180],\n",
      "        [-1.9145],\n",
      "        [-2.2104],\n",
      "        [ 0.8702],\n",
      "        [-0.7832],\n",
      "        [-0.2089],\n",
      "        [-1.6187],\n",
      "        [-1.9145],\n",
      "        [ 0.2785],\n",
      "        [ 0.4873],\n",
      "        [-1.1139],\n",
      "        [ 1.3402],\n",
      "        [ 0.0870],\n",
      "        [-1.2880],\n",
      "        [-1.5838],\n",
      "        [ 1.1313],\n",
      "        [ 0.9399],\n",
      "        [-0.6962],\n",
      "        [ 0.4351],\n",
      "        [-1.0095],\n",
      "        [ 0.2089],\n",
      "        [ 1.2880],\n",
      "        [-0.1740],\n",
      "        [-0.4525],\n",
      "        [-0.7136],\n",
      "        [-0.2263],\n",
      "        [-0.2263],\n",
      "        [ 1.5664],\n",
      "        [-0.5570],\n",
      "        [-0.2437],\n",
      "        [ 0.4525],\n",
      "        [-0.0696],\n",
      "        [ 0.0348],\n",
      "        [ 1.6361],\n",
      "        [ 1.2183],\n",
      "        [-2.1060]], size=(192, 1), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.017404863610863686,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([ 9.5536e-02, -1.0727e+00,  5.8812e-01, -3.9546e-02,  1.3756e-02,\n",
      "         5.9362e-01, -6.2250e-01,  9.8148e-01, -8.0376e-01, -1.8897e-01,\n",
      "        -4.0729e-02, -2.2532e-01, -1.5984e-01,  5.6774e-02, -1.0762e-01,\n",
      "        -8.1319e-01, -1.1275e-01, -4.0195e-02, -7.3130e-02,  3.8972e-01,\n",
      "         9.4981e-01,  5.2888e-01,  5.8508e-01, -9.7902e-01,  7.4345e-01,\n",
      "         7.5657e-01,  5.8885e-01, -9.1685e-01, -7.4818e-01,  1.1881e-01,\n",
      "        -1.4039e-01, -1.0180e+00,  4.1872e-01, -9.7810e-01, -7.7721e-01,\n",
      "         5.2066e-01, -9.1321e-04,  5.2805e-02,  8.1385e-01, -7.1587e-01,\n",
      "         4.9512e-01,  6.1203e-01,  8.7039e-01,  2.4755e-01, -6.1571e-01,\n",
      "        -5.1773e-01, -5.4723e-01,  9.8491e-02,  6.2332e-01, -1.1499e-01,\n",
      "         1.8395e-01, -5.1716e-01, -3.1531e-01, -9.9510e-01,  4.1526e-01,\n",
      "         4.3585e-01,  8.3539e-01, -8.6724e-02, -1.8466e-01,  5.7375e-01,\n",
      "        -1.6059e-01, -2.3226e-01, -7.1897e-01,  1.1081e-01,  5.9546e-01,\n",
      "        -7.5344e-01, -5.8723e-01,  1.0386e-01,  3.4548e-01, -1.1773e-01,\n",
      "         6.0330e-01, -3.1550e-01,  7.3744e-01, -5.4565e-02, -9.7826e-01,\n",
      "        -6.0325e-01,  8.6487e-01,  8.5798e-01,  7.3017e-01,  1.0386e-01,\n",
      "         8.7937e-01,  7.8343e-01,  3.6314e-01, -8.4739e-01,  2.5425e-01,\n",
      "         6.0339e-01, -3.2451e-02, -2.2542e-01,  1.5824e-01,  2.4252e-02,\n",
      "        -4.5569e-01,  1.8123e-01,  4.0868e-03, -8.0433e-01,  7.5093e-01,\n",
      "        -2.2198e-01, -4.4155e-01,  9.3132e-02, -8.7112e-01,  7.5760e-01,\n",
      "         1.6823e-02, -2.9010e-01, -3.3730e-01, -6.9415e-02, -5.5050e-01,\n",
      "        -3.3380e-02,  8.5493e-01, -1.0770e+00, -1.0587e+00, -5.7916e-02,\n",
      "         1.2432e-01, -1.8672e-02, -1.0547e+00,  2.3330e-01,  5.5242e-01,\n",
      "         4.2456e-01,  4.3585e-01,  3.0367e-01, -1.0999e-02,  1.3536e-01,\n",
      "         6.2067e-01, -3.7309e-01,  1.4714e-01, -2.3211e-02, -9.8911e-01,\n",
      "        -7.0932e-01, -4.0212e-01, -6.9569e-01,  8.4581e-01,  6.3529e-01,\n",
      "         3.4402e-01,  9.0409e-01,  5.6235e-01, -9.5738e-01, -8.3578e-01,\n",
      "        -6.5032e-01,  6.0987e-01,  2.9304e-01,  2.0052e-01,  3.3648e-01,\n",
      "        -7.5626e-01, -9.3033e-01,  9.7328e-01, -9.8632e-01,  2.0473e-01,\n",
      "         3.4855e-02,  8.4628e-01, -4.9560e-01,  7.0637e-01,  5.7489e-01,\n",
      "        -8.2384e-01,  5.3497e-01,  3.6383e-01,  5.2809e-01,  4.5225e-01,\n",
      "         5.5932e-02, -1.0328e+00,  9.9937e-01,  1.0089e+00,  1.5087e-01,\n",
      "        -3.0037e-01, -1.0065e-01,  9.1754e-01, -2.3176e-02,  2.2813e-01,\n",
      "        -3.2739e-01,  3.1990e-01,  4.5903e-01,  3.2239e-01,  5.8788e-01,\n",
      "         1.6642e-01,  4.4683e-01,  2.1334e-01, -6.2713e-01, -1.0235e+00,\n",
      "         3.8718e-01, -6.2732e-01,  1.3203e-01, -5.6599e-02,  2.4670e-01,\n",
      "         3.3595e-01, -2.0549e-01, -1.3790e-03, -6.2944e-01, -9.1420e-01,\n",
      "         1.9859e-01,  1.2893e-01,  1.2384e-01, -4.9032e-01, -3.4285e-01,\n",
      "        -7.6718e-01,  1.1383e+00], requires_grad=True))\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "id": "18593e383e1153c3",
   "metadata": {},
   "source": "## Parameter Extraction"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:13:54.456748Z",
     "start_time": "2024-05-05T16:13:54.424648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    'scale',\n",
    "    'zero_point',\n",
    "    '_packed_params.dtype'\n",
    "]\n",
    "\n",
    "with open('model_layers_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if not any(ignore_key in layer_name for ignore_key in ignore_keys):\n",
    "            if '_packed_params._packed_params' in layer_name:\n",
    "                # Dynamically get the corresponding layer\n",
    "                layer_parts = layer_name.split('.')\n",
    "                layer = model_quantized\n",
    "                for part in layer_parts[:-1]:\n",
    "                    layer = getattr(layer, part)\n",
    "                \n",
    "                packed_params = getattr(layer, '_packed_params')\n",
    "                \n",
    "                # Unpack the quantized weights and biases\n",
    "                int8_weights, int8_bias = torch.ops.quantized.linear_unpack(packed_params)\n",
    "                int8_weights_nd = np.array(int8_weights.int_repr())\n",
    "                int8_bias_nd = int8_bias.detach().numpy()\n",
    "                \n",
    "                f.write(f\"Layer: {layer_name}\\n\")\n",
    "                f.write(f\"Quantized Weights:\\n{int8_weights_nd}\\n\")\n",
    "                f.write(f\"Quantization Scale: {int8_weights.q_scale()}\\n\")\n",
    "                f.write(f\"Quantized Bias:\\n{int8_bias_nd}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            else:\n",
    "                # Convert param_tensor to ndarray\n",
    "                param_ndarray = param_tensor.detach().numpy()\n",
    "                \n",
    "                f.write(f\"Layer: {layer_name}\\n\") \n",
    "                f.write(f\"Parameters:\\n{param_ndarray}\\n\")\n",
    "                f.write(\"\\n\")\n"
   ],
   "id": "dcb42f8ab80da6cf",
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "1b8d3a51dac9641d",
   "metadata": {},
   "source": "### 提取六層 Encoder, Classifier, Embedding 參數"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 32-bit 浮點數",
   "id": "20e7df3fed31e5a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:13:57.278911Z",
     "start_time": "2024-05-05T16:13:57.058786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    '.scale',\n",
    "    '.zero_point',\n",
    "    '._packed_params.dtype'\n",
    "]\n",
    "\n",
    "def extract_packed_params(layer_name, param_tensor, folder_path):\n",
    "    if '_packed_params._packed_params' in layer_name:\n",
    "        layer_parts = layer_name.split('.')\n",
    "        layer = model_quantized\n",
    "        for part in layer_parts[:-1]:\n",
    "            layer = getattr(layer, part)\n",
    "        \n",
    "        packed_params = getattr(layer, '_packed_params')\n",
    "        \n",
    "        int8_weights, int8_bias = torch.ops.quantized.linear_unpack(packed_params)\n",
    "        int8_weights_nd = np.array(int8_weights.int_repr())\n",
    "        int8_bias_nd = int8_bias.detach().numpy()\n",
    "        \n",
    "        # Save quantized weights\n",
    "        weights_file = os.path.join(folder_path, 'quantized_weights.txt')\n",
    "        with open(weights_file, 'w') as f:\n",
    "            for weight in int8_weights_nd.flatten():\n",
    "                f.write(f\"{weight}\\n\")\n",
    "        \n",
    "        # Save quantized biases\n",
    "        bias_file = os.path.join(folder_path, 'quantized_bias.txt')\n",
    "        with open(bias_file, 'w') as f:\n",
    "            np.savetxt(f, int8_bias_nd, fmt='%.8f')\n",
    "        \n",
    "        # Save quantization scale\n",
    "        scale_file = os.path.join(folder_path, 'quantization_scale.txt')\n",
    "        with open(scale_file, 'w') as f:\n",
    "            f.write(str(int8_weights.q_scale()))\n",
    "    else:\n",
    "        param_ndarray = param_tensor.detach().numpy()\n",
    "        \n",
    "        # Save regular parameters\n",
    "        param_file = os.path.join(folder_path, 'parameters.txt')\n",
    "        with open(param_file, 'w') as f:\n",
    "            np.savetxt(f, param_ndarray.flatten(), fmt='%.8f')\n",
    "\n",
    "# Create the \"32float\" folder in the current directory\n",
    "float32_folder = '32float'\n",
    "os.makedirs(float32_folder, exist_ok=True)\n",
    "\n",
    "# Extract encoder.0 to encoder.5\n",
    "for i in range(1):\n",
    "    folder_name = f'encoder_{i}_params'\n",
    "    folder_path = os.path.join(float32_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith(f'encoder.{i}') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            layer_folder = os.path.join(folder_path, layer_name.replace('.', '_'))\n",
    "            os.makedirs(layer_folder, exist_ok=True)\n",
    "            \n",
    "            if '_packed_params._packed_params' in layer_name:\n",
    "                extract_packed_params(layer_name, param_tensor, layer_folder)\n",
    "            else:\n",
    "                param_ndarray = param_tensor.detach().numpy()\n",
    "                param_file = os.path.join(layer_folder, 'parameters.txt')\n",
    "                with open(param_file, 'w') as f:\n",
    "                    np.savetxt(f, param_ndarray.flatten(), fmt='%.8f')\n",
    "\n",
    "# Extract remaining layers\n",
    "layers_to_extract = ['classifier', 'embedding', 'positional_encoding']\n",
    "for layer in layers_to_extract:\n",
    "    folder_name = f'{layer}_params'\n",
    "    folder_path = os.path.join(float32_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith(layer) and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            layer_folder = os.path.join(folder_path, layer_name.replace('.', '_'))\n",
    "            os.makedirs(layer_folder, exist_ok=True)\n",
    "            \n",
    "            extract_packed_params(layer_name, param_tensor, layer_folder)\n"
   ],
   "id": "ee1229d64b4c3fa1",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 16-bit IEEE 754 binary format\n",
    "\n",
    "- 整數轉成8位元的二進制\n",
    "- 浮點數轉成16位元的IEEE 754二進制"
   ],
   "id": "d72a43aa9b0c05c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T16:14:01.396024Z",
     "start_time": "2024-05-05T16:14:00.721623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import struct\n",
    "\n",
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    '.scale',\n",
    "    '.zero_point',\n",
    "    '._packed_params.dtype'\n",
    "]\n",
    "\n",
    "def float_to_bin_16bit(num):\n",
    "    # Convert float to 16-bit IEEE 754 binary format\n",
    "    binary = struct.pack('>e', num)\n",
    "    return ''.join('{:08b}'.format(b) for b in binary)\n",
    "\n",
    "def int_to_bin_8bit(num):\n",
    "    # Convert integer to 8-bit signed binary format\n",
    "    return '{:08b}'.format(num & 0xff)\n",
    "\n",
    "def extract_packed_params(layer_name, param_tensor, folder_path):\n",
    "    if '_packed_params._packed_params' in layer_name:\n",
    "        layer_parts = layer_name.split('.')\n",
    "        layer = model_quantized\n",
    "        for part in layer_parts[:-1]:\n",
    "            layer = getattr(layer, part)\n",
    "        \n",
    "        packed_params = getattr(layer, '_packed_params')\n",
    "        \n",
    "        int8_weights, int8_bias = torch.ops.quantized.linear_unpack(packed_params)\n",
    "        int8_weights_nd = np.array(int8_weights.int_repr())\n",
    "        int8_bias_nd = int8_bias.detach().numpy()\n",
    "        \n",
    "        # Save quantized weights as binary in text format\n",
    "        weights_file = os.path.join(folder_path, 'quantized_weights.txt')\n",
    "        with open(weights_file, 'w') as f:\n",
    "            for weight in int8_weights_nd.flatten():\n",
    "                f.write(int_to_bin_8bit(weight) + '\\n')\n",
    "        \n",
    "        # Save quantized biases as binary in text format\n",
    "        bias_file = os.path.join(folder_path, 'quantized_bias.txt')\n",
    "        with open(bias_file, 'w') as f:\n",
    "            for bias in int8_bias_nd.flatten():\n",
    "                f.write(float_to_bin_16bit(bias) + '\\n')\n",
    "        \n",
    "        # Save quantization scale as binary in text format\n",
    "        scale_file = os.path.join(folder_path, 'quantization_scale.txt')\n",
    "        with open(scale_file, 'w') as f:\n",
    "            f.write(float_to_bin_16bit(int8_weights.q_scale()))\n",
    "    else:\n",
    "        param_ndarray = param_tensor.detach().numpy()\n",
    "        \n",
    "        # Save regular parameters as binary in text format\n",
    "        param_file = os.path.join(folder_path, 'parameters.txt')\n",
    "        with open(param_file, 'w') as f:\n",
    "            for param in param_ndarray.flatten():\n",
    "                if isinstance(param, np.integer):\n",
    "                    f.write(int_to_bin_8bit(param) + '\\n')\n",
    "                else:\n",
    "                    f.write(float_to_bin_16bit(param) + '\\n')\n",
    "\n",
    "# Extract encoder.0 to encoder.5 \n",
    "for i in range(1):\n",
    "    folder_name = f'binary/encoder_{i}_params'\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith(f'encoder.{i}') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            layer_folder = os.path.join(folder_name, layer_name.replace('.', '_'))\n",
    "            os.makedirs(layer_folder, exist_ok=True)\n",
    "            \n",
    "            if '_packed_params._packed_params' in layer_name:\n",
    "                extract_packed_params(layer_name, param_tensor, layer_folder)\n",
    "            else:\n",
    "                param_ndarray = param_tensor.detach().numpy()\n",
    "                param_file = os.path.join(layer_folder, 'parameters.txt')\n",
    "                with open(param_file, 'w') as f:\n",
    "                    for param in param_ndarray.flatten():\n",
    "                        if isinstance(param, np.integer):\n",
    "                            f.write(int_to_bin_8bit(param) + '\\n')\n",
    "                        else:\n",
    "                            f.write(float_to_bin_16bit(param) + '\\n')\n",
    "\n",
    "# Extract remaining layers\n",
    "layers_to_extract = ['classifier', 'embedding', 'positional_encoding']\n",
    "for layer in layers_to_extract:\n",
    "    folder_name = f'binary/{layer}_params'\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith(layer) and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            layer_folder = os.path.join(folder_name, layer_name.replace('.', '_'))\n",
    "            os.makedirs(layer_folder, exist_ok=True)\n",
    "            \n",
    "            extract_packed_params(layer_name, param_tensor, layer_folder)\n"
   ],
   "id": "ad9f3ef3fd02811a",
   "outputs": [],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
