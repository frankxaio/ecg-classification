Layer: encoder.4.0.block.0.weight
Parameters: tensor([1.0638, 1.0900, 1.0632, 1.0523, 1.0345, 1.0584, 1.1711, 1.0900, 1.0929,
        1.0388, 1.0739, 1.0645, 1.1292, 1.0302, 1.0804, 1.0459, 1.0506, 1.0580,
        1.0772, 1.0868, 1.0476, 1.0388, 1.0627, 1.1022, 1.0526, 1.0761, 1.0509,
        1.0698, 1.0465, 1.0165, 1.0643, 1.0420, 1.0936, 1.0807, 1.0737, 1.0721,
        1.0657, 1.0433, 1.1175, 1.0729, 1.1148, 1.0733, 1.0650, 1.1116, 1.0535,
        1.0558, 1.0894, 1.0698, 1.0856, 1.0981, 1.1126, 1.0848, 1.1226, 1.0476,
        1.0584, 1.0810, 1.0570, 1.0946, 1.0703, 1.1243, 1.0933, 1.0815, 1.0935,
        1.0443, 1.0913, 1.0623, 1.0801, 1.0687, 1.1020, 1.0818, 1.0493, 1.0772,
        1.0247, 1.0790, 1.0959, 1.0866, 1.0842, 1.0525, 1.0348, 1.0587, 1.0980,
        1.0704, 1.0870, 1.0229, 1.0635, 1.0514, 1.1175, 1.1091, 1.0512, 1.1043,
        1.0645, 1.0539, 1.0839, 1.0627, 1.0805, 1.1096, 1.0489, 1.0336, 1.0841,
        1.0873, 1.0860, 1.1055, 1.0654, 1.0862, 0.9907, 1.1054, 1.0718, 1.0442,
        1.0447, 1.1030, 1.0714, 1.0698, 1.0567, 1.0150, 1.0586, 1.0929, 1.0627,
        1.0240, 1.0025, 1.0877, 1.0795, 1.0358, 1.0918, 1.1030, 1.0876, 1.0521,
        1.0518, 1.0729, 1.1203, 1.0556, 1.1076, 1.0885, 1.0346, 1.0846, 1.0358,
        1.0822, 1.1065, 1.0706, 1.0744, 1.0541, 1.0603, 1.0676, 1.0301, 1.0764,
        1.0823, 1.1184, 1.0908, 1.0279, 1.0856, 1.0532, 1.0906, 1.0517, 1.0927,
        1.0738, 1.1094, 1.0904, 1.0742, 1.0900, 1.0831, 1.0111, 1.0649, 1.1051,
        1.0290, 1.1085, 1.0452, 1.0810, 1.0873, 1.0647, 1.0183, 1.0940, 1.0649,
        1.0491, 1.0893, 1.0781, 1.0968, 1.1113, 1.0955, 1.1329, 1.0838, 0.9928,
        1.0456, 1.0852, 1.0841, 1.0612, 1.0525, 1.0696, 1.0469, 1.0601, 1.0289,
        1.0276, 1.0675, 1.0702])

Layer: encoder.4.0.block.0.bias
Parameters: tensor([ 0.0025, -0.0152,  0.0046,  0.0125, -0.0015,  0.0121,  0.0283, -0.0158,
         0.0164,  0.0263,  0.0274, -0.0307, -0.0117,  0.0182,  0.0039,  0.0200,
         0.0053, -0.0218,  0.0104, -0.0067,  0.0150, -0.0097,  0.0143,  0.0314,
        -0.0007, -0.0148,  0.0081,  0.0148, -0.0125,  0.0101,  0.0104, -0.0148,
         0.0163, -0.0266,  0.0091, -0.0031,  0.0106,  0.0089, -0.0107,  0.0475,
        -0.0235,  0.0269,  0.0096, -0.0053,  0.0292, -0.0071, -0.0025,  0.0017,
        -0.0283, -0.0025, -0.0066, -0.0110,  0.0058, -0.0022,  0.0201,  0.0045,
        -0.0054, -0.0313, -0.0120,  0.0080,  0.0276,  0.0128, -0.0242, -0.0236,
        -0.0137, -0.0013,  0.0067,  0.0024,  0.0070, -0.0086,  0.0324,  0.0346,
         0.0277,  0.0130, -0.0298,  0.0353, -0.0138, -0.0330,  0.0064,  0.0239,
        -0.0037,  0.0066, -0.0197, -0.0247,  0.0072,  0.0247, -0.0259, -0.0261,
        -0.0164, -0.0276,  0.0174, -0.0101,  0.0107,  0.0164, -0.0110, -0.0117,
        -0.0224, -0.0163,  0.0094, -0.0267, -0.0085,  0.0215,  0.0015,  0.0090,
        -0.0002,  0.0163, -0.0230, -0.0074, -0.0210,  0.0095, -0.0136,  0.0038,
         0.0205,  0.0355, -0.0136,  0.0118, -0.0268, -0.0109,  0.0298,  0.0109,
        -0.0132,  0.0100,  0.0162,  0.0112,  0.0021, -0.0150, -0.0495,  0.0154,
        -0.0328,  0.0272, -0.0167, -0.0022,  0.0394,  0.0217,  0.0035,  0.0161,
         0.0180,  0.0041,  0.0038, -0.0017,  0.0023,  0.0054, -0.0026,  0.0165,
         0.0287, -0.0183, -0.0040, -0.0425,  0.0114,  0.0170,  0.0181, -0.0314,
         0.0303,  0.0187, -0.0290,  0.0218, -0.0155, -0.0539, -0.0005,  0.0468,
        -0.0350,  0.0081, -0.0224,  0.0235,  0.0143,  0.0298,  0.0201, -0.0353,
        -0.0196, -0.0348, -0.0185, -0.0124, -0.0164, -0.0171, -0.0029, -0.0193,
         0.0061,  0.0183, -0.0085, -0.0054,  0.0183, -0.0386,  0.0345, -0.0417,
         0.0327,  0.0290, -0.0041,  0.0229, -0.0410, -0.0133,  0.0100,  0.0139])

Layer: encoder.4.0.block.1.queries_projection._packed_params._packed_params
Parameters: (tensor([[-0.0258, -0.0223, -0.0120,  ...,  0.0567, -0.0602,  0.0756],
        [-0.0636, -0.0223, -0.0413,  ..., -0.0378,  0.0602,  0.0155],
        [ 0.0241, -0.0309,  0.0378,  ..., -0.0017, -0.0636,  0.0017],
        ...,
        [-0.1341,  0.0894, -0.0911,  ..., -0.0292,  0.0464, -0.1135],
        [-0.0309, -0.0309,  0.0481,  ..., -0.0602, -0.1032,  0.0034],
        [ 0.0653, -0.1083, -0.0860,  ..., -0.0894,  0.0585,  0.0172]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0017192050581797957,
       zero_point=0), Parameter containing:
tensor([ 0.0085,  0.0092, -0.0396, -0.0063,  0.0281, -0.0036,  0.0323, -0.0990,
         0.0187, -0.0211,  0.0680, -0.0064, -0.0211,  0.0340, -0.0569,  0.0181,
         0.0176, -0.0539,  0.0185,  0.0508,  0.0196,  0.0137,  0.0181,  0.0594,
        -0.0042,  0.0049, -0.0661,  0.0049, -0.0078,  0.0640,  0.0274, -0.0091,
        -0.0706, -0.0087, -0.0392, -0.0374, -0.0177,  0.0441,  0.0080, -0.0437,
        -0.0271,  0.0129,  0.0684, -0.0127,  0.0569,  0.0456, -0.0177, -0.0010,
        -0.0429, -0.0090, -0.0047, -0.0487,  0.0426,  0.0374,  0.0375, -0.0101,
         0.0063,  0.0618,  0.0546,  0.0385,  0.0693,  0.0082,  0.0567, -0.0197,
         0.0104, -0.0011, -0.0052, -0.0690,  0.0603, -0.0854,  0.0409, -0.0667,
        -0.0396, -0.0572, -0.0090,  0.0229,  0.0051, -0.0180, -0.0222, -0.0316,
        -0.0496,  0.0484, -0.0672, -0.0002,  0.0479,  0.0394, -0.0242,  0.0300,
         0.0180, -0.0123,  0.0378,  0.0362, -0.0375, -0.0208, -0.0578, -0.0413,
         0.0275,  0.0223, -0.0223, -0.0018,  0.0031, -0.0555,  0.0172, -0.0840,
        -0.0387,  0.0616, -0.0461,  0.0025, -0.0764,  0.0410,  0.0519,  0.0071,
         0.0673, -0.0582,  0.0280,  0.1032, -0.0269,  0.0555, -0.0426,  0.0143,
        -0.0240,  0.1304,  0.0872, -0.0440,  0.0371,  0.1125, -0.0184, -0.0687,
        -0.0144, -0.0787, -0.0543, -0.0146,  0.0086, -0.1326, -0.0531,  0.0690,
        -0.0124,  0.1505, -0.0902, -0.0771, -0.0068, -0.0314, -0.0606, -0.0524,
         0.0710,  0.0781,  0.0447,  0.0008, -0.0325,  0.0495,  0.0264,  0.0814,
         0.0611, -0.0461,  0.0302,  0.0251, -0.0282,  0.0260, -0.0608, -0.0475,
         0.0171, -0.0080, -0.0208, -0.0260, -0.0168,  0.0765,  0.0197,  0.0211,
         0.0372, -0.0959, -0.0631,  0.0448,  0.0623,  0.0287,  0.0450,  0.0315,
         0.0336, -0.0685,  0.0634, -0.0034, -0.0718,  0.0380,  0.0075, -0.0760,
        -0.0020,  0.0143, -0.0317, -0.0266, -0.0432,  0.0066, -0.0974, -0.0178],
       requires_grad=True))

Layer: encoder.4.0.block.1.values_projection._packed_params._packed_params
Parameters: (tensor([[-0.0247, -0.0449,  0.0314,  ...,  0.0650,  0.0000, -0.0493],
        [ 0.0763, -0.0807, -0.0987,  ..., -0.0381, -0.0538,  0.0807],
        [-0.0112,  0.0045, -0.0112,  ..., -0.0157, -0.0112, -0.0224],
        ...,
        [ 0.0359,  0.0292,  0.0067,  ...,  0.1076,  0.0359,  0.0852],
        [ 0.0045,  0.0942, -0.1099,  ...,  0.0650, -0.1413,  0.0583],
        [ 0.0135,  0.0224, -0.0673,  ..., -0.0314, -0.0292, -0.0224]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.002242662012577057,
       zero_point=0), Parameter containing:
tensor([-4.8011e-02, -5.7966e-04, -3.0337e-02, -4.8949e-02, -1.0374e-02,
         4.9731e-02,  2.1908e-02,  3.0104e-02,  1.7515e-03,  6.3380e-02,
        -1.0148e-02, -2.4967e-02,  3.6602e-02,  1.1918e-02,  2.8438e-03,
        -3.5834e-03, -5.2405e-02,  9.9229e-03,  4.9465e-02,  6.9462e-02,
        -3.6450e-02,  1.5328e-02, -1.4831e-02, -5.7250e-02,  1.9970e-02,
        -6.1588e-02, -3.9940e-02,  1.0706e-03, -4.6214e-02,  2.3395e-02,
        -4.7483e-02, -6.0955e-02, -5.7062e-02,  1.2593e-02, -1.8932e-03,
         1.3098e-02, -2.3507e-02, -6.7928e-02, -3.9987e-02, -4.4460e-05,
        -3.7199e-02, -2.3861e-02,  4.8201e-02, -8.8446e-03, -5.9407e-02,
        -8.3707e-03,  2.6306e-02,  2.5476e-02,  1.3296e-02, -1.4447e-04,
        -5.5265e-02,  4.1990e-02,  3.5565e-02,  4.4077e-02, -5.6877e-02,
        -1.7514e-02,  4.1700e-02, -1.2039e-02, -1.5877e-02, -4.2384e-02,
        -3.8398e-02, -3.6178e-02, -3.0639e-02, -3.3090e-02,  5.7623e-02,
        -4.9679e-02, -3.5252e-02, -2.5294e-03,  5.1246e-02, -4.0382e-03,
        -3.7326e-02, -7.1386e-02,  3.7522e-02,  9.0169e-03, -6.2248e-02,
         1.6676e-02,  2.4347e-02, -4.4345e-02,  2.4759e-02, -4.5298e-02,
        -2.5563e-02, -4.7392e-02,  7.2156e-02, -4.2536e-02, -6.3024e-02,
        -5.3872e-02,  3.8378e-02, -1.3743e-03, -7.8411e-03, -1.1280e-02,
         2.2352e-02, -2.5866e-02, -4.9475e-02, -5.3390e-03, -6.1177e-02,
        -2.7095e-02,  3.4059e-02, -3.3110e-02, -1.0852e-02,  5.9587e-02,
         5.7998e-02,  4.7020e-02,  3.4747e-02,  2.2949e-03, -4.0624e-02,
        -6.6506e-02,  7.5745e-02,  5.8271e-02,  8.3864e-02, -4.7994e-02,
         2.5960e-02,  1.3084e-03,  7.5474e-02, -5.0564e-02, -2.6862e-02,
        -5.6518e-02, -3.2867e-02, -3.3478e-02,  6.7387e-02,  9.7678e-03,
        -5.0131e-02,  2.0473e-02,  2.0286e-03, -1.5400e-03,  1.1513e-02,
         4.0986e-02, -4.4965e-02, -1.8727e-02, -5.9600e-02,  2.5915e-02,
        -6.3420e-02, -5.3580e-02,  3.0462e-02, -4.5679e-02,  1.8510e-02,
         6.4449e-02, -2.0885e-03, -4.9504e-02,  3.3658e-02, -2.3439e-04,
         6.2878e-03,  1.4228e-02, -6.1248e-02,  3.0127e-02,  5.2069e-02,
        -7.2060e-02, -5.6753e-02, -1.7111e-02, -2.4345e-02, -3.9131e-02,
         5.8179e-02, -9.1518e-03,  4.6909e-02, -1.8624e-03, -3.9532e-02,
         1.8140e-02,  4.7332e-02,  3.7356e-02,  2.6141e-03,  2.5948e-02,
        -2.5516e-02, -8.7879e-03, -6.5528e-02, -5.9725e-03,  3.0522e-02,
         3.0969e-02, -5.1195e-02, -2.4461e-02, -1.6825e-02, -2.0799e-02,
        -6.4294e-02,  1.7903e-02,  2.7853e-02, -3.0784e-02,  3.3337e-02,
         6.2380e-02, -3.0738e-03, -3.6056e-03, -5.0158e-02, -3.9210e-02,
         4.3848e-02,  7.4806e-02, -6.5757e-02, -1.5930e-02,  3.5785e-02,
        -8.1346e-03,  3.9718e-02, -5.8220e-03, -2.2549e-02, -5.8619e-03,
         1.6352e-02,  6.2813e-02], requires_grad=True))

Layer: encoder.4.0.block.1.keys_projection._packed_params._packed_params
Parameters: (tensor([[-0.0172, -0.0329,  0.0925,  ..., -0.0549, -0.1410,  0.0501],
        [ 0.0439,  0.1661,  0.0392,  ..., -0.0016,  0.0141, -0.0172],
        [-0.0031, -0.0580,  0.0251,  ..., -0.0188, -0.0298, -0.0219],
        ...,
        [ 0.0345, -0.0596,  0.0016,  ...,  0.0439,  0.0094, -0.0596],
        [-0.0752, -0.0157, -0.0172,  ..., -0.0407,  0.0831, -0.0549],
        [-0.0533,  0.0533,  0.0407,  ..., -0.0345, -0.0266,  0.1034]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0015671472065150738,
       zero_point=0), Parameter containing:
tensor([-1.0895e-02,  6.3180e-02, -1.8824e-02,  4.2413e-02, -7.8060e-02,
        -3.2297e-02,  5.0512e-02,  4.9495e-03,  7.0407e-02,  4.5429e-02,
        -4.9630e-02, -1.4955e-02,  4.6166e-02,  6.3973e-02, -4.8292e-03,
        -6.4452e-02, -1.0680e-02, -5.6293e-02, -5.1834e-02,  6.1032e-02,
         9.9128e-05, -3.3448e-02, -1.2517e-02, -6.8648e-02, -2.8074e-02,
         1.0510e-02,  2.7373e-02, -4.6975e-02, -1.2488e-02, -1.2333e-02,
         4.8308e-02,  5.2956e-02,  5.7795e-02,  1.4634e-02, -6.1049e-02,
         7.3451e-02,  5.6378e-03, -7.1948e-02,  4.8294e-02,  6.8591e-02,
        -4.9159e-03, -2.3847e-02, -6.2545e-02, -6.4045e-02, -7.3728e-02,
         4.8882e-02,  5.0522e-02,  3.7811e-02, -2.9981e-03, -6.6946e-03,
         1.4618e-02, -1.9070e-02,  3.0041e-02, -2.2323e-02, -4.2609e-02,
        -7.1109e-02, -4.4767e-02, -5.6789e-02,  3.2727e-02,  1.7662e-04,
        -5.8862e-02, -2.3872e-03, -5.5267e-02, -6.6243e-02,  6.8357e-02,
        -5.5105e-02,  5.2067e-02, -2.6038e-02,  8.4788e-03, -5.2105e-02,
        -2.2646e-02, -4.2898e-02,  1.2597e-02,  1.2665e-02, -5.2620e-03,
        -1.7778e-02,  3.3080e-02,  1.6150e-02, -5.9820e-02,  4.0392e-02,
        -1.0021e-02, -5.5670e-02, -1.3502e-02, -1.7644e-02, -1.1280e-02,
        -1.6667e-02, -1.3686e-03, -7.1891e-02, -5.5492e-02, -6.4565e-02,
        -1.9459e-03,  3.1164e-02,  2.0624e-02,  1.7707e-02, -2.0263e-03,
        -6.8946e-02, -4.9709e-03, -3.7231e-02,  4.6505e-02, -6.2440e-02,
         1.1385e-02, -7.1312e-02, -7.1286e-02, -4.4293e-02, -6.2311e-02,
         4.6200e-03,  2.2487e-02, -2.7934e-02,  3.9569e-02,  2.4856e-02,
        -7.2979e-03,  2.7133e-02,  6.0515e-02,  5.6164e-02,  5.8726e-02,
        -5.3629e-02,  6.9452e-02, -3.3255e-02, -4.1277e-02,  5.3302e-02,
        -1.8683e-02, -1.6347e-02, -1.8198e-02,  5.1387e-02, -6.1411e-02,
        -5.5332e-03,  4.3173e-02, -7.1052e-02, -5.1737e-02,  1.9461e-02,
         6.9978e-03,  1.1267e-02, -4.1184e-02,  4.4253e-02,  4.8978e-02,
         3.3327e-02, -4.8285e-02, -1.6034e-02,  6.6164e-03, -1.7011e-02,
         5.0277e-02, -8.0391e-03,  1.1841e-02,  1.5540e-02, -2.4747e-02,
         5.0144e-02, -2.6321e-02, -4.7094e-02,  7.4690e-02,  2.9800e-02,
         3.0880e-02,  1.5931e-02,  5.1248e-02, -3.3680e-02, -3.4930e-02,
        -4.2327e-02,  3.8513e-02, -1.5218e-03, -1.1628e-02,  5.8372e-02,
        -5.7681e-02, -3.9470e-02, -2.9058e-02,  2.9030e-02,  1.1627e-04,
        -1.6428e-02, -4.8160e-03,  3.8349e-02,  5.3687e-02, -2.6655e-03,
         1.8334e-02, -7.7491e-02,  1.1893e-02, -1.8671e-02,  2.6421e-02,
         7.6476e-02, -1.4163e-02,  2.6484e-02,  1.3270e-02,  2.0723e-03,
         2.3009e-02,  6.0288e-03, -5.2416e-02,  6.9460e-02,  2.7248e-02,
         7.5377e-02, -4.5069e-03,  7.1861e-02,  7.4475e-02,  4.9075e-02,
         2.0328e-02, -5.2914e-02], requires_grad=True))

Layer: encoder.4.0.block.1.final_projection._packed_params._packed_params
Parameters: (tensor([[ 0.1461,  0.0411,  0.0548,  ..., -0.1324,  0.1119,  0.0160],
        [ 0.1416, -0.0776,  0.0685,  ...,  0.0822, -0.1073,  0.0616],
        [-0.0502,  0.1393, -0.0046,  ...,  0.0479, -0.1872, -0.1781],
        ...,
        [-0.0731,  0.0753, -0.1256,  ..., -0.0890,  0.1142,  0.0616],
        [-0.0502,  0.0434, -0.0479,  ...,  0.0822, -0.1484, -0.1370],
        [ 0.0845,  0.0000, -0.0388,  ...,  0.0571,  0.0959,  0.1530]],
       size=(192, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0022832865361124277,
       zero_point=0), Parameter containing:
tensor([-1.5919e-02, -5.3035e-02,  6.2691e-02,  6.5314e-02, -3.6672e-02,
         6.1238e-02,  5.3430e-02,  5.5790e-03,  4.0288e-02,  5.9723e-02,
        -2.0820e-02,  4.1051e-02, -4.3547e-02, -8.0800e-03, -6.7717e-02,
        -3.6644e-02,  3.0902e-02, -4.1565e-02,  5.1769e-02,  1.4633e-02,
         8.4142e-02, -3.5333e-02,  1.2511e-02, -2.5276e-02, -1.1012e-02,
        -1.4448e-02, -7.5029e-03,  2.7096e-02, -6.1842e-02,  1.8886e-02,
        -4.0963e-02,  4.4535e-02,  4.1757e-02, -2.4691e-02, -3.6748e-02,
        -8.6405e-02,  1.6089e-02,  4.1019e-02, -5.1069e-02,  7.6108e-02,
         3.3944e-02,  3.8781e-02, -2.5156e-02,  2.2545e-02, -3.5051e-02,
         2.3562e-02, -1.3691e-02,  6.6332e-03,  3.1747e-02,  3.5275e-02,
         5.7280e-03,  8.5732e-04, -1.6917e-03, -1.6674e-03,  3.5992e-02,
        -4.3428e-02,  3.0393e-02, -5.8704e-02,  1.0400e-02,  6.1094e-03,
         7.0711e-02,  3.0088e-02,  1.9951e-02, -8.6785e-02, -1.0105e-02,
         4.1660e-02, -2.6266e-02,  4.4509e-02,  3.3581e-02,  7.3850e-02,
        -5.8818e-02, -3.5848e-02,  1.0716e-02,  1.5680e-02,  4.3402e-02,
         4.2596e-02, -5.8214e-02, -3.2845e-02, -6.2304e-02, -4.7846e-02,
        -4.6890e-02,  1.0747e-02, -2.3848e-02,  3.6780e-02,  3.1003e-02,
         9.6878e-02, -7.3008e-04, -1.8087e-02,  9.0084e-02, -7.2326e-02,
        -6.0185e-03, -3.1969e-02,  7.0707e-03,  5.5190e-02,  8.2620e-03,
        -9.0914e-02,  3.2264e-02, -5.0940e-02, -2.3014e-02,  4.6276e-02,
         2.3046e-02, -1.7860e-02, -4.9597e-02,  3.9318e-02,  4.0888e-02,
        -3.4710e-02,  6.5137e-02, -4.6865e-02, -3.5179e-02, -1.2095e-02,
        -6.8766e-02, -7.6698e-02, -2.6189e-02, -2.8482e-02, -2.4007e-02,
         5.2600e-02, -7.0855e-02,  5.6326e-02,  5.4250e-02, -1.0432e-02,
         2.6315e-02,  4.5576e-02, -3.1834e-02, -4.0264e-02, -2.1831e-02,
        -3.1567e-02,  2.2332e-02, -5.2979e-02, -2.5792e-02, -5.9969e-02,
        -8.0305e-02, -6.5776e-02, -3.5268e-02, -2.3680e-02,  8.4593e-03,
        -6.1291e-02, -4.6596e-02, -1.3383e-02, -2.5937e-02,  7.9925e-02,
        -7.0023e-02, -2.6153e-02,  5.2773e-02,  4.2739e-02, -1.6476e-02,
        -8.0404e-02, -5.6962e-02, -8.6923e-02, -5.1331e-02, -4.2846e-02,
         6.3720e-02, -7.0276e-02,  4.0364e-02,  6.9865e-03,  3.6035e-02,
         2.4611e-02, -6.8759e-02, -7.1753e-02,  4.2266e-02, -2.0350e-02,
         3.0384e-02, -3.0187e-02,  3.9661e-02, -2.3756e-03, -3.0569e-02,
         6.5463e-02, -1.3613e-02, -1.0444e-01, -6.0485e-03,  2.4944e-02,
        -4.8350e-02, -2.0102e-02, -1.0401e-04, -2.1513e-02, -6.9843e-02,
         3.8748e-02, -8.5604e-02, -3.3416e-02, -8.3617e-02,  4.4005e-02,
        -4.1236e-02, -3.1184e-02, -6.6378e-02, -4.5333e-02, -2.9144e-02,
        -5.0811e-02,  4.2519e-02,  6.2706e-02, -7.6003e-02,  7.2219e-02,
        -5.2235e-02, -6.1404e-02], requires_grad=True))

Layer: encoder.4.1.block.0.weight
Parameters: tensor([0.8385, 0.8729, 0.8614, 0.9557, 0.9089, 0.9396, 0.9707, 0.9610, 0.8626,
        0.8980, 0.8756, 0.9733, 0.8909, 0.9172, 0.8736, 0.9056, 0.8776, 0.9417,
        0.9588, 0.9246, 0.9377, 0.8978, 0.8972, 0.8855, 0.8216, 0.8997, 0.9275,
        0.8598, 0.8622, 0.8710, 0.9307, 0.8626, 0.9285, 0.8541, 0.8815, 0.9460,
        0.9331, 0.8715, 0.8788, 0.8776, 0.8782, 0.8623, 0.8724, 0.9348, 0.9126,
        0.8783, 0.8718, 0.8721, 1.0108, 0.8399, 0.8359, 0.9153, 0.8770, 0.9188,
        0.8759, 0.8592, 0.8911, 0.8944, 0.8594, 0.9404, 0.9097, 0.9237, 0.9029,
        0.9585, 0.9252, 0.9094, 0.9308, 0.9252, 0.9353, 0.9370, 0.9915, 0.9212,
        0.8549, 0.9098, 0.9347, 0.8771, 0.8864, 0.8992, 0.9496, 0.9144, 0.8847,
        0.9492, 0.9383, 0.8932, 0.9183, 0.9333, 0.9471, 0.9240, 0.8692, 0.8388,
        0.9197, 0.8932, 0.8780, 0.8864, 0.9304, 0.8962, 0.8437, 0.8946, 0.9136,
        0.8573, 0.9171, 0.8501, 0.9585, 0.8601, 0.9281, 0.9313, 0.9301, 0.9406,
        0.9368, 0.9016, 0.9110, 0.9369, 0.9205, 0.9038, 0.9001, 0.8786, 0.9471,
        0.9333, 0.9534, 0.9131, 0.8604, 0.9343, 0.8587, 0.9129, 0.8458, 0.9173,
        0.8971, 0.8816, 0.9070, 0.8510, 0.9100, 0.9398, 0.9074, 0.8765, 0.9260,
        0.8522, 0.8750, 0.8942, 0.9066, 0.8622, 0.8860, 0.8762, 0.9268, 0.8550,
        0.9161, 0.9467, 0.9027, 0.9041, 0.9509, 0.9260, 0.8790, 0.8511, 0.8736,
        0.9153, 0.8671, 0.8527, 0.9455, 0.8596, 0.8448, 0.9190, 0.9242, 0.8798,
        0.9401, 0.8828, 0.8780, 0.8835, 0.9271, 0.9660, 0.9342, 0.9509, 0.9452,
        0.9290, 0.9359, 0.8991, 0.8639, 0.8667, 0.9374, 0.9321, 0.8572, 0.9280,
        0.9599, 0.9640, 0.9253, 0.8569, 0.9147, 0.9371, 0.9393, 0.8833, 0.9399,
        0.8802, 0.8939, 0.8750])

Layer: encoder.4.1.block.0.bias
Parameters: tensor([ 0.0807, -0.0234, -0.0325, -0.0062, -0.0243,  0.0284, -0.0043,  0.0654,
        -0.0232,  0.0229, -0.0478,  0.0081, -0.0369, -0.0519, -0.0039, -0.0131,
        -0.0307, -0.0584,  0.0418,  0.0549, -0.0339,  0.0116, -0.0144, -0.0388,
         0.0113, -0.0276, -0.0366, -0.0021,  0.0181,  0.0022, -0.0350,  0.0040,
        -0.0044,  0.0394, -0.0175,  0.0222,  0.0026, -0.0273,  0.0370, -0.0144,
         0.0048, -0.0335, -0.0179,  0.0184, -0.0301,  0.0088,  0.0386, -0.0112,
         0.0385,  0.0080,  0.0232, -0.0008,  0.0174, -0.0393, -0.0208, -0.0079,
         0.0407, -0.0420, -0.0413, -0.0227, -0.0356, -0.0010, -0.0087,  0.0058,
         0.0498, -0.0033, -0.0274,  0.0190,  0.0084, -0.0378, -0.0522, -0.0427,
        -0.0280, -0.0230,  0.0264, -0.0439, -0.0116,  0.0088, -0.0210,  0.0270,
        -0.0090, -0.0282,  0.0128,  0.0359, -0.0238, -0.0303,  0.0096,  0.0085,
        -0.0030,  0.0396, -0.0335,  0.0319,  0.0178,  0.0436, -0.0205,  0.0330,
         0.0577, -0.0139, -0.0467, -0.0256, -0.0259, -0.0048, -0.0350, -0.0020,
         0.0403,  0.0376,  0.0160,  0.0209,  0.0228,  0.0648,  0.0359, -0.0138,
        -0.0022, -0.0552, -0.0127,  0.0054,  0.0187,  0.0340, -0.0443,  0.0375,
        -0.0437,  0.0013, -0.0228,  0.0199, -0.0192, -0.0387,  0.0107, -0.0092,
         0.0106, -0.0133,  0.0120, -0.0340, -0.0258, -0.0424,  0.0133, -0.0023,
        -0.0360,  0.0329, -0.0255, -0.0048, -0.0396,  0.0054,  0.0171, -0.0356,
        -0.0440,  0.0184,  0.0517,  0.0408, -0.0132,  0.0081, -0.0655, -0.0013,
        -0.0409, -0.0433,  0.0026,  0.0060,  0.0031, -0.0388,  0.0090, -0.0461,
         0.0380,  0.0024, -0.0332, -0.0176, -0.0263, -0.0145, -0.0332,  0.0185,
        -0.0048,  0.0418, -0.0362,  0.0054, -0.0210, -0.0085,  0.0601,  0.0263,
         0.0133, -0.0051, -0.0084,  0.0340, -0.0205,  0.0466,  0.0080,  0.0484,
        -0.0058, -0.0311, -0.0158, -0.0391,  0.0375,  0.0560, -0.0085, -0.0150])

Layer: encoder.4.1.block.1.0._packed_params._packed_params
Parameters: (tensor([[ 0.0123, -0.0055, -0.0219,  ...,  0.0096,  0.0507, -0.0096],
        [-0.0137,  0.0493, -0.0740,  ...,  0.0438, -0.0164, -0.0603],
        [-0.0562, -0.0288,  0.0315,  ...,  0.0027, -0.0192, -0.0356],
        ...,
        [-0.0329, -0.0082,  0.0014,  ..., -0.0288, -0.0206, -0.0617],
        [ 0.0027,  0.0164,  0.0096,  ..., -0.0480, -0.0288, -0.0658],
        [-0.0781, -0.0027, -0.0027,  ...,  0.0356, -0.0671,  0.0685]],
       size=(768, 192), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0013701356947422028,
       zero_point=0), Parameter containing:
tensor([ 5.9283e-03, -7.6263e-02,  7.6230e-03, -2.5546e-02, -1.4180e-03,
        -3.8100e-02,  5.9794e-03,  1.9749e-02, -3.0851e-02,  3.3257e-03,
        -5.3829e-03, -6.1530e-02,  1.0541e-02, -8.0617e-02,  2.2182e-02,
        -4.6406e-02, -3.1358e-02,  1.5187e-02, -6.7081e-02,  7.3424e-03,
        -5.9086e-02,  1.6962e-02, -4.2203e-02, -5.7394e-02, -8.5536e-02,
         8.2324e-03,  1.7470e-02, -1.0911e-04, -1.0162e-02, -4.3864e-02,
         2.0036e-03, -6.5606e-02, -3.6355e-02,  8.8280e-03,  2.6890e-02,
        -2.2328e-02, -1.0044e-01, -3.1594e-02, -9.8318e-02, -2.6969e-02,
        -3.0436e-02, -8.1517e-02, -2.3958e-02, -5.2485e-02,  5.8960e-03,
        -9.7464e-02,  1.0344e-02, -4.7023e-02, -1.2209e-02, -1.7607e-02,
        -4.0378e-02,  5.9255e-03,  2.0205e-02, -6.7333e-03, -2.8638e-03,
        -7.6838e-02, -6.8991e-02,  2.9285e-03, -3.5251e-02, -5.2925e-02,
        -8.4744e-02, -6.1017e-02,  1.9469e-02, -3.8539e-02,  9.1911e-03,
         5.9330e-03, -1.1411e-02, -4.1730e-02, -7.7774e-02,  1.3910e-03,
        -1.0504e-01, -8.8088e-02, -4.8445e-02, -1.1491e-01, -6.6753e-02,
        -9.8080e-02, -1.0976e-01, -8.0398e-02, -8.0631e-02, -6.1477e-02,
        -6.9906e-02, -6.2359e-04, -7.2160e-02, -1.6936e-02, -4.1368e-02,
         3.3375e-02,  5.5508e-03, -1.4550e-02, -2.7933e-02, -1.5097e-03,
        -5.8410e-02, -9.2768e-02, -4.0278e-02,  2.3524e-02,  7.0424e-03,
        -1.5458e-02, -8.7848e-02,  6.3445e-03, -7.4892e-02, -6.0130e-02,
         4.3760e-02, -1.6118e-03, -6.7975e-02, -2.4170e-02, -9.4648e-03,
        -6.6331e-02, -7.2707e-02, -3.7388e-02,  1.4013e-02,  2.6490e-02,
         4.1121e-03, -4.2711e-02, -5.2511e-02,  8.7939e-03, -4.6624e-02,
        -8.5318e-02, -2.9740e-03,  1.8782e-02, -7.7350e-02, -1.8091e-02,
        -3.6270e-02, -5.7535e-02, -2.7202e-02, -5.7586e-02,  1.7391e-02,
         1.3774e-02,  3.4208e-02, -1.4145e-02, -1.7288e-02, -3.0912e-02,
         2.1739e-02, -8.3228e-02,  2.6760e-03, -1.8404e-02, -1.0363e-03,
        -1.9665e-02, -2.0569e-02, -5.6672e-02,  3.1975e-02,  2.1403e-02,
        -9.7199e-02, -5.7248e-02,  2.6143e-02, -6.5446e-02, -4.9618e-02,
         4.4070e-02, -5.0671e-02, -6.2031e-02, -5.8897e-02,  2.9958e-02,
         3.1380e-02, -9.4416e-02, -6.0827e-03,  3.1590e-02, -5.6856e-02,
        -9.7435e-02, -1.8695e-02, -4.6817e-03,  1.7288e-02,  1.8753e-02,
        -5.3807e-03, -3.1851e-02, -7.0818e-02, -6.1314e-02, -4.8082e-02,
         4.4050e-03, -3.3280e-02,  1.2370e-02, -4.4692e-02,  4.1314e-03,
        -2.4631e-02, -2.4769e-02, -1.0933e-01,  3.6022e-02, -1.3539e-02,
         1.9828e-02, -8.4821e-02, -5.3274e-02, -4.6174e-02, -4.9750e-02,
        -4.9337e-02, -4.7188e-02, -5.1426e-02,  7.8221e-03, -2.0532e-02,
        -3.5128e-03,  1.2057e-02, -2.7691e-02,  1.7865e-02, -1.5146e-03,
         2.2433e-02, -9.1100e-02,  1.2246e-02,  3.0230e-02,  2.2457e-03,
        -3.8582e-02,  3.2134e-02, -1.0369e-01, -7.0708e-02, -5.5700e-03,
        -9.8836e-02, -8.3797e-02, -2.6666e-02, -6.6059e-02, -8.1511e-02,
        -3.0031e-02, -1.7330e-02, -1.1283e-01, -6.8887e-02, -6.8145e-02,
        -1.7866e-02, -9.5589e-02, -9.6811e-02, -9.4041e-02, -4.1251e-02,
        -9.6980e-02, -2.4950e-02, -9.9772e-02, -2.6645e-02, -7.4392e-02,
         7.4878e-03, -6.8282e-02,  1.2673e-02, -2.1025e-02, -6.6168e-02,
        -9.1036e-02, -7.0887e-02, -1.5157e-02,  5.1705e-03, -3.6150e-02,
        -2.4950e-02, -8.8856e-02,  8.4670e-03, -4.3265e-02, -8.6488e-02,
         2.3719e-02, -9.1754e-02,  5.7884e-03, -1.6800e-02,  1.5435e-02,
        -7.9444e-02, -7.2321e-02, -1.2671e-02,  2.9205e-02,  1.8932e-02,
        -3.7559e-02, -1.7584e-02,  8.8594e-04, -2.7016e-03, -1.9094e-02,
        -4.7287e-02,  2.9358e-02, -1.7833e-02, -1.0649e-03, -2.2165e-02,
        -6.2967e-02, -1.6179e-02, -6.8927e-02, -1.1954e-02, -5.9513e-02,
        -7.1871e-02, -6.5097e-02, -1.8029e-02, -3.7327e-03, -7.3750e-02,
        -1.0143e-02, -9.2270e-02, -8.0312e-02, -4.1155e-02, -4.0370e-02,
         1.0189e-02,  1.7982e-02,  1.1024e-02, -5.2531e-02,  6.4183e-03,
        -1.0404e-02,  1.2592e-02, -7.3922e-02, -3.5292e-02, -7.1487e-02,
        -3.8851e-02, -2.6994e-03, -9.3060e-02,  2.2503e-02,  1.0675e-02,
        -3.8161e-02, -3.7928e-03,  1.9259e-02, -9.3371e-02, -3.7610e-02,
         2.3730e-02, -5.2844e-02, -4.7204e-02, -5.9031e-02,  2.3028e-02,
         1.7253e-02,  1.2088e-02, -4.2676e-02, -5.6987e-02, -4.3782e-02,
        -9.4581e-02, -6.3570e-02, -8.2317e-02, -3.8757e-02, -7.4511e-02,
        -8.4827e-02, -9.9511e-02, -5.4494e-02, -9.1144e-02, -4.6056e-02,
        -5.8651e-02, -8.6591e-03, -1.5978e-02,  1.2825e-02, -4.5897e-02,
        -2.6543e-02, -3.8533e-02, -1.0317e-01,  3.8587e-03,  1.3927e-02,
        -9.6195e-02,  2.7525e-03,  1.8611e-02, -5.9915e-02, -7.6725e-02,
        -3.2872e-02, -8.4358e-02, -3.1767e-02, -1.5878e-02, -9.4168e-02,
         3.4407e-04, -3.5816e-02, -7.0708e-02, -6.5007e-02, -9.2710e-02,
         2.1389e-02, -1.4068e-02, -3.5207e-02, -8.4330e-02, -8.9934e-02,
         2.1728e-03, -8.9939e-02, -1.3933e-02,  4.2125e-04, -1.2097e-02,
        -7.2461e-02, -6.4872e-02,  3.0688e-02,  5.7413e-03, -8.4497e-02,
        -7.4515e-02, -9.4635e-03, -6.4947e-02,  7.3993e-03, -2.3873e-02,
        -9.0003e-02,  2.8305e-02, -1.0518e-01, -9.3847e-02, -2.8033e-02,
        -2.7245e-02, -7.2262e-02,  1.4790e-02, -9.0215e-02, -3.0856e-02,
         1.4033e-02,  4.1112e-02, -3.2966e-02,  1.8126e-02, -6.8341e-02,
        -8.0056e-03, -4.9894e-02, -1.6712e-03,  2.4116e-02, -3.6600e-02,
        -6.0905e-02, -1.1800e-01, -4.5238e-02, -3.6913e-02, -5.1338e-02,
         2.9368e-02, -6.0366e-02,  1.2541e-02, -2.9498e-02, -6.1825e-03,
         6.3483e-04, -6.4825e-02, -8.5272e-02,  1.2152e-02,  2.1771e-02,
        -1.9930e-02, -1.9102e-02, -8.2426e-03,  1.2199e-02, -3.4708e-02,
         2.4042e-02, -6.9987e-02, -1.0069e-02, -5.9013e-02, -3.8488e-02,
        -7.3505e-02,  1.4056e-02, -1.7114e-02, -1.6265e-02, -3.2868e-02,
         2.1971e-02,  2.7929e-02, -6.8524e-02, -9.6882e-02, -9.2641e-02,
         7.3746e-03, -8.4991e-02,  6.5533e-04, -2.5810e-02, -3.5264e-02,
         9.2928e-03,  2.9091e-03, -2.9388e-02, -6.4140e-02,  2.5339e-02,
        -6.8475e-02, -7.5150e-02, -6.2811e-02, -1.0230e-02, -3.6128e-02,
        -5.2560e-02, -8.6828e-02, -6.2875e-02, -5.2734e-02, -5.3111e-02,
         2.3702e-02, -1.3022e-03, -3.5522e-02,  2.9803e-02,  2.7291e-03,
        -4.0458e-02, -9.0759e-02, -1.0116e-02, -3.3206e-02, -4.0259e-02,
        -1.0116e-02, -3.1774e-02,  1.0121e-02,  2.2708e-02, -6.5602e-02,
        -3.7625e-02, -1.0404e-01,  8.1030e-03,  3.6004e-02, -8.6032e-02,
        -7.1032e-02, -6.2373e-02, -5.6406e-02,  1.1899e-02, -3.4560e-02,
         8.0458e-03, -8.7768e-02, -6.7496e-02, -4.8509e-02,  1.6495e-02,
        -2.8919e-02, -8.4653e-03,  2.4843e-02, -1.0669e-01,  2.0702e-02,
        -3.8343e-02, -4.9689e-02,  2.3289e-03, -8.4555e-02, -7.3414e-02,
        -3.6200e-02, -2.9743e-02, -3.9726e-02,  6.7178e-03, -5.9332e-02,
        -6.2196e-02, -9.0183e-02, -8.4253e-02, -6.6069e-03,  3.0811e-02,
         2.6415e-02,  2.7345e-02,  6.1846e-03,  1.9950e-02, -7.3696e-02,
        -4.9806e-02, -6.9620e-02, -3.3029e-02, -2.9896e-02,  2.2923e-02,
        -6.2340e-02, -6.8387e-02,  2.8303e-02, -6.2487e-02, -2.3818e-03,
        -6.3737e-02,  1.5163e-02, -6.6810e-02,  3.0828e-02,  7.1262e-03,
        -3.8654e-02,  2.5211e-02, -7.2221e-02, -7.4758e-02, -3.6787e-02,
        -4.5481e-02, -1.5001e-02, -7.8471e-02,  3.5744e-03,  2.5067e-02,
        -9.8390e-02, -6.2930e-02, -8.3106e-03,  7.1775e-03, -2.1932e-02,
         1.9272e-02, -8.6708e-02, -1.3848e-02, -1.7821e-02, -2.0627e-02,
        -2.7963e-02, -2.5542e-02,  1.4125e-03, -3.3937e-02, -6.5076e-02,
        -2.1079e-02, -4.3083e-02, -4.8611e-02, -5.4046e-02, -7.7959e-03,
        -8.5239e-02, -4.3522e-02, -8.0764e-02, -9.6838e-02, -4.9773e-02,
        -1.7562e-02, -4.8222e-02, -1.1585e-02, -5.7397e-03, -9.0427e-02,
         8.2807e-03, -1.3722e-02,  2.3991e-02, -5.9268e-02, -4.0964e-02,
        -9.4298e-02, -9.3542e-02, -3.2900e-02,  2.2641e-03, -8.0868e-02,
         1.3159e-02,  1.9598e-02, -9.2014e-03, -2.0284e-02, -3.3705e-02,
        -4.0358e-02,  1.2645e-02, -7.0626e-02, -9.7005e-02, -7.6351e-02,
        -5.7155e-02, -2.6777e-02, -1.4637e-03, -7.2865e-02, -3.6084e-02,
        -8.9764e-02,  3.4748e-03,  2.2887e-02, -6.0434e-02, -3.2527e-03,
        -1.3261e-02, -7.2077e-02, -1.0377e-01, -7.8646e-02, -7.0744e-02,
         2.8411e-03,  1.7460e-02, -1.3391e-02, -2.7954e-02, -6.1522e-02,
        -3.5179e-02,  6.6121e-03, -1.2621e-02, -3.8751e-02, -6.1115e-02,
        -7.8686e-02,  5.1379e-03, -1.0126e-02, -5.2801e-02, -6.9202e-02,
         2.1487e-02,  8.1026e-03, -1.0118e-02, -8.9952e-03, -4.6288e-02,
         1.9066e-02,  2.2886e-02, -7.0530e-02, -6.8495e-02, -9.4693e-02,
         1.7523e-02, -5.4683e-03, -2.0616e-02, -3.6564e-02, -5.3499e-02,
        -7.7889e-02,  1.6808e-02, -3.7823e-02, -5.9270e-02,  2.0330e-02,
        -7.3746e-02, -3.9638e-02, -6.8944e-02, -1.2875e-02, -4.2731e-03,
        -2.9531e-02, -2.9305e-03, -5.3942e-02, -8.9243e-04, -8.5041e-02,
        -1.4467e-02, -3.0631e-02, -6.7832e-02, -1.6736e-02,  2.0105e-02,
        -7.8215e-04, -4.2794e-02, -5.2724e-02, -4.0637e-02, -8.5175e-02,
         1.6653e-02, -7.4964e-03, -9.4389e-03, -6.4213e-02,  1.1975e-02,
        -6.3527e-02,  1.2592e-02, -7.8611e-02,  1.6907e-02, -3.3881e-02,
        -6.3813e-02,  1.0997e-02,  7.8993e-03, -1.0325e-01, -1.0605e-01,
        -5.6901e-02,  9.5511e-03, -8.8506e-03,  1.5537e-02, -5.6861e-02,
        -7.0053e-02, -2.5571e-02, -1.6563e-03, -3.7488e-02, -1.7555e-02,
        -7.7019e-02, -2.0825e-02, -1.0082e-01, -4.7115e-02, -3.3478e-02,
        -3.6238e-02, -9.6538e-02, -3.3713e-02,  9.0900e-03, -1.0476e-01,
        -6.5003e-03,  3.5205e-02,  6.8724e-03, -4.5064e-03, -2.0967e-02,
        -8.4263e-02, -5.0193e-02, -1.0756e-01, -2.6459e-02, -6.8015e-02,
        -4.4976e-02, -4.5251e-02, -2.5928e-02, -4.8616e-03, -5.2000e-02,
        -4.7593e-02, -2.8106e-02,  2.6782e-02, -6.1393e-02, -5.9589e-02,
        -7.3059e-02, -1.0096e-01, -3.0381e-02, -7.5148e-02, -6.4836e-02,
        -4.7744e-02, -5.3063e-02, -7.8869e-02, -3.8349e-02, -5.8375e-02,
        -4.6103e-02, -2.9820e-02, -1.7967e-02,  8.1730e-03, -8.7416e-02,
        -4.5638e-02,  2.4327e-02,  7.9205e-03,  2.7178e-02,  1.4676e-02,
        -6.3593e-02, -5.6491e-04, -8.1712e-02, -6.9300e-03,  1.2577e-02,
        -6.1516e-02, -1.4638e-02, -1.0198e-01, -7.5524e-03, -3.7102e-02,
         1.7004e-02, -2.5362e-02, -3.8859e-02, -5.6853e-02, -5.0830e-02,
        -3.9419e-02, -7.8377e-02, -9.8076e-03, -4.2423e-02, -6.9248e-02,
        -6.5302e-02, -7.1933e-02,  2.5426e-02, -1.6649e-02, -1.0216e-01,
        -6.1570e-02, -4.9148e-02, -4.4837e-02, -3.5629e-02,  2.2725e-02,
        -4.6060e-02, -7.7105e-02,  2.2409e-02, -6.9672e-02, -6.3325e-02,
        -3.4540e-02, -5.3388e-02, -8.8525e-02, -8.4924e-02, -3.8903e-02,
        -1.2946e-02,  3.2330e-02,  3.2452e-02, -8.8830e-02,  1.0759e-03,
        -3.8236e-03, -9.7457e-02, -3.6999e-02, -1.0790e-01, -7.3766e-02,
        -4.1789e-02,  1.8265e-02, -7.3338e-02, -4.9835e-02,  4.8786e-03,
        -7.9645e-03, -5.4261e-02,  4.5548e-04, -9.0008e-02, -2.7855e-02,
         3.2485e-02, -5.0318e-02, -1.0287e-02], requires_grad=True))

Layer: encoder.4.1.block.1.2._packed_params._packed_params
Parameters: (tensor([[-0.0096,  0.0376, -0.0029,  ...,  0.0067,  0.0096, -0.0087],
        [ 0.0144, -0.0116,  0.0356,  ..., -0.0096,  0.0096,  0.0096],
        [-0.0125,  0.0212,  0.0356,  ...,  0.0279, -0.0289,  0.0472],
        ...,
        [-0.0356, -0.0125, -0.0039,  ...,  0.0231, -0.0279,  0.0029],
        [ 0.0298,  0.0173, -0.0279,  ...,  0.0298,  0.0096, -0.0327],
        [-0.0279, -0.0270, -0.0260,  ...,  0.0366, -0.0587,  0.0241]],
       size=(192, 768), dtype=torch.qint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.0009628683910705149,
       zero_point=0), Parameter containing:
tensor([-1.1114e-02,  4.4044e-02, -6.8559e-03,  3.2829e-02, -2.8763e-02,
        -1.0809e-02, -1.6793e-02, -1.5005e-05,  4.9486e-03,  4.2160e-03,
         3.1879e-02, -1.5699e-02, -5.1480e-03, -1.0420e-02, -5.3506e-03,
         3.3755e-02, -1.1466e-03,  2.8462e-02, -9.0816e-03, -3.8818e-03,
         2.6433e-02,  5.4014e-04,  1.2206e-02,  2.2696e-02, -5.4873e-02,
        -3.0140e-03,  4.6939e-03, -5.8922e-04, -1.1779e-02, -1.2534e-02,
         8.4912e-03, -3.2522e-02,  2.7469e-02,  9.8847e-03, -1.0277e-02,
        -2.4678e-02, -6.0033e-03,  2.4877e-02,  7.8528e-03,  1.7827e-02,
         3.4093e-02,  1.0010e-02, -7.6997e-03, -3.2211e-02,  1.0359e-02,
        -1.1746e-02, -3.1118e-02, -2.9392e-02, -4.4928e-02,  1.5190e-02,
        -3.5161e-02, -1.0174e-02,  3.2068e-03, -2.1357e-03, -1.2839e-02,
         1.6324e-02, -2.7349e-02,  2.4000e-02, -1.8802e-02, -2.3931e-02,
         6.2544e-03,  3.6548e-03,  1.9159e-02,  4.9814e-04, -1.5408e-02,
        -2.1665e-02, -3.1555e-02,  1.0654e-02,  3.0881e-02,  4.7831e-02,
        -1.5636e-03, -3.9303e-03, -1.1442e-03, -1.7787e-02, -5.0670e-02,
         3.1011e-02, -4.3246e-02, -3.3107e-02,  3.1526e-02, -1.7126e-02,
         4.3600e-02,  9.2230e-04, -1.7284e-02, -3.0212e-02,  1.4462e-02,
         3.6810e-02, -5.9524e-02, -4.6589e-02,  1.5605e-02, -1.2762e-02,
        -1.2596e-02, -3.1607e-02, -2.2193e-02,  2.8565e-03,  3.1358e-02,
        -1.1288e-02, -6.4377e-03, -1.3729e-02,  2.3797e-02, -3.6342e-02,
        -3.3878e-02, -1.8079e-04,  1.8737e-02,  3.9885e-02, -3.6884e-02,
        -2.0722e-02, -1.2636e-02, -4.0199e-02, -3.7782e-02,  9.6052e-03,
        -3.2802e-02, -1.7876e-02,  1.4767e-02, -1.3826e-02,  1.3412e-02,
         3.9606e-03,  9.4661e-03, -1.4373e-02,  2.1388e-02, -3.1818e-02,
        -1.6600e-02,  2.3035e-02,  1.7363e-02, -5.7977e-03, -1.2182e-02,
         7.8174e-03, -3.9234e-02, -4.0916e-02, -1.2181e-02, -1.8883e-02,
        -1.3769e-02,  1.0117e-02, -1.9311e-02, -1.1695e-02, -1.2035e-02,
        -2.5254e-02,  3.6546e-02,  7.2212e-03,  1.4268e-02,  1.8659e-02,
        -3.8119e-02, -4.4812e-02,  2.0951e-02,  3.6302e-02,  1.6313e-02,
        -1.1175e-02, -3.4187e-02, -4.6747e-02, -2.6137e-02,  5.2322e-03,
         3.4701e-02, -1.8425e-02, -1.1336e-02,  1.9138e-02, -1.8441e-02,
        -9.7480e-03,  2.2057e-02,  2.4840e-02, -9.9632e-03, -1.2612e-02,
        -5.9567e-02,  1.8888e-02,  9.0677e-03, -2.9870e-03,  1.7685e-02,
         4.1237e-02,  9.8927e-03, -7.2057e-02,  1.2730e-03, -1.9818e-02,
        -4.2360e-02,  6.2983e-03, -1.2706e-02, -1.2052e-03, -8.9860e-02,
        -5.9519e-02, -9.9133e-03, -1.8237e-02, -3.5209e-02,  7.4250e-03,
         1.5901e-02, -2.0540e-02,  1.1005e-03, -3.7816e-02,  1.4934e-02,
         1.3069e-02, -3.3887e-02, -3.6516e-03, -2.0785e-02,  1.2890e-02,
         2.9887e-02,  1.2980e-02], requires_grad=True))

