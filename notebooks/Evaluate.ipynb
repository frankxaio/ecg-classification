{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T04:32:47.850064Z",
     "start_time": "2024-05-02T04:32:42.266101Z"
    }
   },
   "source": [
    "import itertools # 是 Python 的內建模組，提供了一組用於處理迭代器的函數和工具。\n",
    "                 # 它包含了各種用於高效處理迭代器的函數，可以幫助我們編寫更簡潔、高效的代碼。\n",
    "import sys # 是 Python 的內建模組，提供了與 Python 解釋器和運行環境相關的功能。\n",
    "# sys.path 是一個列表，包含了 Python 解釋器在導入模組時會搜尋的路徑。\n",
    "# 當你使用 import 語句導入模組時 Python 會依次在 sys.path 中的路徑下尋找對應的模組文件。\n",
    "sys.path.append(\"../ecg-classification/\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\Chen_Lab01\\\\Documents\\\\GitHub/ecg-classification\")\n",
    "# from IPython.display import Video\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\") #  是 Matplotlib 庫中用於設置繪圖樣式的函數。它使用了一種名為 \"ggplot\" 的預定義樣式\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "                        #  該樣式模仿了 R 語言的 ggplot2 繪圖包的外觀。\n",
    "# print(sys.path)\n",
    "from ecg_tools.config import EcgConfig, Mode\n",
    "from ecg_tools.data_loader import DatasetConfig, get_data_loaders\n",
    "from ecg_tools.model import ECGformer\n",
    "from ecg_tools.train import ECGClassifierTrainer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load model",
   "id": "adbb91b9dbfa94e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:32:47.898250Z",
     "start_time": "2024-05-02T04:32:47.852149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "config = EcgConfig()    \n",
    "model_quantized = torch.load(\"..\\\\model_save\\\\model_quantized.pth\")\n",
    "model = torch.load(\"..\\\\model_save\\\\model.pth\")"
   ],
   "id": "29bb12472624e7d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xaio\\anaconda3\\envs\\pytorch-ecg\\lib\\site-packages\\torch\\_utils.py:382: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:32:49.787568Z",
     "start_time": "2024-05-02T04:32:47.899251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import einops\n",
    "loader = get_data_loaders(DatasetConfig())\n",
    "accuracy = 0\n",
    "for signal, label in loader[Mode.eval]:\n",
    "    p = model(einops.rearrange(signal, \"b c e -> b e c\"))\n",
    "    print(p)\n",
    "    print(label)\n",
    "    # print(signal.shape, label.shape)\n",
    "    print(p.argmax(1) == label)\n",
    "    accuracy += torch.sum(p.argmax(1) == label)\n",
    "    print(f\"accuracy: {accuracy / config.dataset.batch_size}\")\n",
    "    break\n",
    "\n"
   ],
   "id": "780d3550eb5bc030",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4664, -0.5813, -0.0759,  0.8808, -0.3671, -0.7415],\n",
      "        [-0.4398, -0.5792, -0.0414,  0.8643, -0.3161, -0.7562],\n",
      "        [-0.4712, -0.5695, -0.0611,  0.8864, -0.3544, -0.7355],\n",
      "        [-0.4462, -0.5696, -0.0674,  0.8759, -0.3429, -0.7418],\n",
      "        [-0.4285, -0.5792, -0.0772,  0.8672, -0.3274, -0.7411],\n",
      "        [-0.3981, -0.5828, -0.0495,  0.8423, -0.2698, -0.7635],\n",
      "        [-0.4494, -0.5558, -0.0697,  0.8976, -0.3636, -0.7337],\n",
      "        [-0.4550, -0.5648, -0.0774,  0.8840, -0.3715, -0.7420],\n",
      "        [-0.4529, -0.5736, -0.0935,  0.9085, -0.3562, -0.7340],\n",
      "        [-0.4061, -0.5896, -0.0596,  0.8443, -0.2862, -0.7518],\n",
      "        [-0.4213, -0.5731, -0.0697,  0.8633, -0.2930, -0.7251],\n",
      "        [-0.4356, -0.5898, -0.0624,  0.8786, -0.3294, -0.7417],\n",
      "        [-0.4546, -0.5911, -0.0715,  0.8920, -0.3542, -0.7540],\n",
      "        [-0.4694, -0.5625, -0.0958,  0.9038, -0.3837, -0.7250],\n",
      "        [-0.4100, -0.5911, -0.0479,  0.8370, -0.2743, -0.7606],\n",
      "        [-0.2910, -0.6222, -0.0295,  0.7496, -0.1196, -0.7513],\n",
      "        [-0.4820, -0.5581, -0.0752,  0.8925, -0.4051, -0.7365],\n",
      "        [-0.2663, -0.5931,  0.0420,  0.7043, -0.0603, -0.8032],\n",
      "        [-0.3995, -0.5749, -0.0595,  0.8480, -0.2797, -0.7476],\n",
      "        [-0.4576, -0.5659, -0.0747,  0.8975, -0.3559, -0.7545],\n",
      "        [-0.3492, -0.5956, -0.0221,  0.8026, -0.1985, -0.7605],\n",
      "        [-0.4870, -0.5777, -0.0811,  0.8901, -0.3728, -0.7334],\n",
      "        [-0.4749, -0.5722, -0.0791,  0.8978, -0.3890, -0.7340],\n",
      "        [-0.3430, -0.5927, -0.0281,  0.7948, -0.1979, -0.7868],\n",
      "        [-0.3616, -0.5759, -0.0268,  0.8029, -0.1884, -0.7645],\n",
      "        [-0.4561, -0.5674, -0.0815,  0.8958, -0.3667, -0.7284],\n",
      "        [-0.4250, -0.5886, -0.0616,  0.8601, -0.2905, -0.7421],\n",
      "        [-0.4785, -0.5795, -0.0749,  0.8899, -0.3712, -0.7284],\n",
      "        [-0.3520, -0.5895, -0.0348,  0.8008, -0.2143, -0.7645],\n",
      "        [-0.4220, -0.5765, -0.0688,  0.8661, -0.3045, -0.7526],\n",
      "        [-0.4536, -0.5774, -0.0738,  0.8731, -0.3420, -0.7210],\n",
      "        [-0.3862, -0.6060, -0.0598,  0.8159, -0.2818, -0.7293]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([5, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 4, 5, 0, 5, 1, 2, 0, 4, 0, 0, 0, 0, 5,\n",
      "        4, 0, 0, 0, 4, 0, 0, 0])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False])\n",
      "accuracy: 0.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parameter 提取",
   "id": "18593e383e1153c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T17:57:49.142100Z",
     "start_time": "2024-05-01T17:57:49.096071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name in model_quantized.state_dict():\n",
    "   print(name)\n",
    "\n",
    "print(model_quantized.state_dict()['encoder.0.0.block.1.queries_projection._packed_params._packed_params'])"
   ],
   "id": "1c3a2eb2b1a473e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positional_encoding\n",
      "encoder.0.0.block.0.weight\n",
      "encoder.0.0.block.0.bias\n",
      "encoder.0.0.block.1.queries_projection.scale\n",
      "encoder.0.0.block.1.queries_projection.zero_point\n",
      "encoder.0.0.block.1.queries_projection._packed_params.dtype\n",
      "encoder.0.0.block.1.queries_projection._packed_params._packed_params\n",
      "encoder.0.0.block.1.values_projection.scale\n",
      "encoder.0.0.block.1.values_projection.zero_point\n",
      "encoder.0.0.block.1.values_projection._packed_params.dtype\n",
      "encoder.0.0.block.1.values_projection._packed_params._packed_params\n",
      "encoder.0.0.block.1.keys_projection.scale\n",
      "encoder.0.0.block.1.keys_projection.zero_point\n",
      "encoder.0.0.block.1.keys_projection._packed_params.dtype\n",
      "encoder.0.0.block.1.keys_projection._packed_params._packed_params\n",
      "encoder.0.0.block.1.final_projection.scale\n",
      "encoder.0.0.block.1.final_projection.zero_point\n",
      "encoder.0.0.block.1.final_projection._packed_params.dtype\n",
      "encoder.0.0.block.1.final_projection._packed_params._packed_params\n",
      "encoder.0.1.block.0.weight\n",
      "encoder.0.1.block.0.bias\n",
      "encoder.0.1.block.1.0.scale\n",
      "encoder.0.1.block.1.0.zero_point\n",
      "encoder.0.1.block.1.0._packed_params.dtype\n",
      "encoder.0.1.block.1.0._packed_params._packed_params\n",
      "encoder.0.1.block.1.2.scale\n",
      "encoder.0.1.block.1.2.zero_point\n",
      "encoder.0.1.block.1.2._packed_params.dtype\n",
      "encoder.0.1.block.1.2._packed_params._packed_params\n",
      "encoder.1.0.block.0.weight\n",
      "encoder.1.0.block.0.bias\n",
      "encoder.1.0.block.1.queries_projection.scale\n",
      "encoder.1.0.block.1.queries_projection.zero_point\n",
      "encoder.1.0.block.1.queries_projection._packed_params.dtype\n",
      "encoder.1.0.block.1.queries_projection._packed_params._packed_params\n",
      "encoder.1.0.block.1.values_projection.scale\n",
      "encoder.1.0.block.1.values_projection.zero_point\n",
      "encoder.1.0.block.1.values_projection._packed_params.dtype\n",
      "encoder.1.0.block.1.values_projection._packed_params._packed_params\n",
      "encoder.1.0.block.1.keys_projection.scale\n",
      "encoder.1.0.block.1.keys_projection.zero_point\n",
      "encoder.1.0.block.1.keys_projection._packed_params.dtype\n",
      "encoder.1.0.block.1.keys_projection._packed_params._packed_params\n",
      "encoder.1.0.block.1.final_projection.scale\n",
      "encoder.1.0.block.1.final_projection.zero_point\n",
      "encoder.1.0.block.1.final_projection._packed_params.dtype\n",
      "encoder.1.0.block.1.final_projection._packed_params._packed_params\n",
      "encoder.1.1.block.0.weight\n",
      "encoder.1.1.block.0.bias\n",
      "encoder.1.1.block.1.0.scale\n",
      "encoder.1.1.block.1.0.zero_point\n",
      "encoder.1.1.block.1.0._packed_params.dtype\n",
      "encoder.1.1.block.1.0._packed_params._packed_params\n",
      "encoder.1.1.block.1.2.scale\n",
      "encoder.1.1.block.1.2.zero_point\n",
      "encoder.1.1.block.1.2._packed_params.dtype\n",
      "encoder.1.1.block.1.2._packed_params._packed_params\n",
      "encoder.2.0.block.0.weight\n",
      "encoder.2.0.block.0.bias\n",
      "encoder.2.0.block.1.queries_projection.scale\n",
      "encoder.2.0.block.1.queries_projection.zero_point\n",
      "encoder.2.0.block.1.queries_projection._packed_params.dtype\n",
      "encoder.2.0.block.1.queries_projection._packed_params._packed_params\n",
      "encoder.2.0.block.1.values_projection.scale\n",
      "encoder.2.0.block.1.values_projection.zero_point\n",
      "encoder.2.0.block.1.values_projection._packed_params.dtype\n",
      "encoder.2.0.block.1.values_projection._packed_params._packed_params\n",
      "encoder.2.0.block.1.keys_projection.scale\n",
      "encoder.2.0.block.1.keys_projection.zero_point\n",
      "encoder.2.0.block.1.keys_projection._packed_params.dtype\n",
      "encoder.2.0.block.1.keys_projection._packed_params._packed_params\n",
      "encoder.2.0.block.1.final_projection.scale\n",
      "encoder.2.0.block.1.final_projection.zero_point\n",
      "encoder.2.0.block.1.final_projection._packed_params.dtype\n",
      "encoder.2.0.block.1.final_projection._packed_params._packed_params\n",
      "encoder.2.1.block.0.weight\n",
      "encoder.2.1.block.0.bias\n",
      "encoder.2.1.block.1.0.scale\n",
      "encoder.2.1.block.1.0.zero_point\n",
      "encoder.2.1.block.1.0._packed_params.dtype\n",
      "encoder.2.1.block.1.0._packed_params._packed_params\n",
      "encoder.2.1.block.1.2.scale\n",
      "encoder.2.1.block.1.2.zero_point\n",
      "encoder.2.1.block.1.2._packed_params.dtype\n",
      "encoder.2.1.block.1.2._packed_params._packed_params\n",
      "encoder.3.0.block.0.weight\n",
      "encoder.3.0.block.0.bias\n",
      "encoder.3.0.block.1.queries_projection.scale\n",
      "encoder.3.0.block.1.queries_projection.zero_point\n",
      "encoder.3.0.block.1.queries_projection._packed_params.dtype\n",
      "encoder.3.0.block.1.queries_projection._packed_params._packed_params\n",
      "encoder.3.0.block.1.values_projection.scale\n",
      "encoder.3.0.block.1.values_projection.zero_point\n",
      "encoder.3.0.block.1.values_projection._packed_params.dtype\n",
      "encoder.3.0.block.1.values_projection._packed_params._packed_params\n",
      "encoder.3.0.block.1.keys_projection.scale\n",
      "encoder.3.0.block.1.keys_projection.zero_point\n",
      "encoder.3.0.block.1.keys_projection._packed_params.dtype\n",
      "encoder.3.0.block.1.keys_projection._packed_params._packed_params\n",
      "encoder.3.0.block.1.final_projection.scale\n",
      "encoder.3.0.block.1.final_projection.zero_point\n",
      "encoder.3.0.block.1.final_projection._packed_params.dtype\n",
      "encoder.3.0.block.1.final_projection._packed_params._packed_params\n",
      "encoder.3.1.block.0.weight\n",
      "encoder.3.1.block.0.bias\n",
      "encoder.3.1.block.1.0.scale\n",
      "encoder.3.1.block.1.0.zero_point\n",
      "encoder.3.1.block.1.0._packed_params.dtype\n",
      "encoder.3.1.block.1.0._packed_params._packed_params\n",
      "encoder.3.1.block.1.2.scale\n",
      "encoder.3.1.block.1.2.zero_point\n",
      "encoder.3.1.block.1.2._packed_params.dtype\n",
      "encoder.3.1.block.1.2._packed_params._packed_params\n",
      "classifier.1.scale\n",
      "classifier.1.zero_point\n",
      "classifier.1._packed_params.dtype\n",
      "classifier.1._packed_params._packed_params\n",
      "classifier.2.weight\n",
      "classifier.2.bias\n",
      "classifier.3.scale\n",
      "classifier.3.zero_point\n",
      "classifier.3._packed_params.dtype\n",
      "classifier.3._packed_params._packed_params\n",
      "embedding.cls_token\n",
      "embedding.0.scale\n",
      "embedding.0.zero_point\n",
      "embedding.0._packed_params.dtype\n",
      "embedding.0._packed_params._packed_params\n",
      "embedding.1.weight\n",
      "embedding.1.bias\n",
      "(tensor([[ 0.0096,  0.0170, -0.0696,  ..., -0.0277, -0.0617, -0.0345],\n",
      "        [-0.0441,  0.0623,  0.0685,  ..., -0.0192,  0.0662, -0.0634],\n",
      "        [-0.0560,  0.0062, -0.0679,  ..., -0.0606, -0.0566, -0.0628],\n",
      "        ...,\n",
      "        [ 0.0017,  0.0425, -0.0583,  ...,  0.0708,  0.0136,  0.0249],\n",
      "        [-0.0238, -0.0158,  0.0096,  ..., -0.0057,  0.0079,  0.0413],\n",
      "        [ 0.0057, -0.0385, -0.0006,  ..., -0.0062,  0.0668,  0.0260]],\n",
      "       size=(192, 192), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.0005660120514221489,\n",
      "       zero_point=0), Parameter containing:\n",
      "tensor([-0.0673,  0.0034, -0.0287, -0.0168, -0.0249, -0.0638,  0.0283,  0.0088,\n",
      "        -0.0718,  0.0122, -0.0233,  0.0410,  0.0240,  0.0637,  0.0276,  0.0434,\n",
      "         0.0241,  0.0293,  0.0544, -0.0007, -0.0522, -0.0072,  0.0199, -0.0077,\n",
      "         0.0692, -0.0602,  0.0658,  0.0484,  0.0675, -0.0628, -0.0023,  0.0650,\n",
      "         0.0594,  0.0254, -0.0165, -0.0665,  0.0174, -0.0709,  0.0680,  0.0377,\n",
      "        -0.0372, -0.0218,  0.0655,  0.0592,  0.0664, -0.0025, -0.0264, -0.0298,\n",
      "         0.0628,  0.0471, -0.0672, -0.0357,  0.0365, -0.0138, -0.0246,  0.0239,\n",
      "        -0.0304,  0.0364, -0.0200, -0.0021,  0.0211, -0.0644, -0.0202,  0.0337,\n",
      "         0.0533,  0.0272,  0.0526, -0.0172,  0.0228, -0.0068, -0.0020,  0.0385,\n",
      "         0.0640, -0.0280,  0.0006, -0.0299,  0.0375, -0.0605, -0.0265, -0.0242,\n",
      "        -0.0143, -0.0034, -0.0025,  0.0144,  0.0697, -0.0415, -0.0129, -0.0196,\n",
      "        -0.0394, -0.0667,  0.0231,  0.0718, -0.0140,  0.0568, -0.0702, -0.0269,\n",
      "        -0.0602, -0.0227, -0.0548,  0.0567,  0.0585,  0.0551, -0.0642, -0.0444,\n",
      "        -0.0009, -0.0062,  0.0670, -0.0690,  0.0598,  0.0562,  0.0246, -0.0117,\n",
      "        -0.0279,  0.0202, -0.0612, -0.0678,  0.0077, -0.0509,  0.0040, -0.0298,\n",
      "         0.0272,  0.0573, -0.0147,  0.0450,  0.0245,  0.0241, -0.0018,  0.0481,\n",
      "         0.0458,  0.0408, -0.0172,  0.0516, -0.0516, -0.0116,  0.0570, -0.0507,\n",
      "        -0.0085,  0.0098,  0.0161, -0.0097,  0.0480, -0.0662, -0.0530,  0.0038,\n",
      "         0.0610, -0.0707, -0.0721,  0.0094,  0.0497, -0.0622,  0.0536, -0.0437,\n",
      "         0.0583,  0.0308, -0.0154, -0.0204,  0.0093, -0.0491,  0.0319, -0.0028,\n",
      "         0.0214, -0.0264,  0.0482, -0.0680, -0.0240,  0.0147, -0.0199, -0.0456,\n",
      "         0.0623,  0.0679, -0.0419,  0.0581, -0.0158,  0.0483, -0.0464, -0.0171,\n",
      "         0.0627,  0.0445, -0.0617, -0.0262, -0.0632,  0.0097,  0.0149,  0.0395,\n",
      "        -0.0005, -0.0258, -0.0631, -0.0058, -0.0440,  0.0212, -0.0653,  0.0329],\n",
      "       requires_grad=True))\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
