digraph {
	graph [size="136.79999999999998,136.79999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2304859410720 [label="
 (1, 6)" fillcolor=darkolivegreen1]
	2304859338640 [label=CppFunction]
	2304859338256 -> 2304859338640
	2304859338256 -> 2304530826160 [dir=none]
	2304530826160 [label="bias
 (192)" fillcolor=orange]
	2304859338256 -> 2304859413920 [dir=none]
	2304859413920 [label="input
 (1, 192)" fillcolor=orange]
	2304859338256 -> 2304531175024 [dir=none]
	2304531175024 [label="result1
 (1, 1)" fillcolor=orange]
	2304859338256 -> 2304859417120 [dir=none]
	2304859417120 [label="result2
 (1, 1)" fillcolor=orange]
	2304859338256 -> 2304530825840 [dir=none]
	2304530825840 [label="weight
 (192)" fillcolor=orange]
	2304859338256 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859338400 -> 2304859338256
	2304859338400 [label=CppFunction]
	2304859338112 -> 2304859338400
	2304859338112 [label="MeanBackward1
-----------------------------
dim           :          (2,)
keepdim       :         False
self_sym_numel:         36096
self_sym_sizes: (1, 192, 188)"]
	2304859338016 -> 2304859338112
	2304859338016 [label="PermuteBackward0
----------------
dims: (0, 2, 1)"]
	2304859337920 -> 2304859338016
	2304859337920 [label="AddBackward0
------------
alpha: 1"]
	2304859337824 -> 2304859337920
	2304859337824 [label="AddBackward0
------------
alpha: 1"]
	2304859337536 -> 2304859337824
	2304859337536 [label="AddBackward0
------------
alpha: 1"]
	2304859337392 -> 2304859337536
	2304859337392 [label="AddBackward0
------------
alpha: 1"]
	2304859337248 -> 2304859337392
	2304859337248 [label="AddBackward0
------------
alpha: 1"]
	2304859337008 -> 2304859337248
	2304859337008 [label="AddBackward0
------------
alpha: 1"]
	2304859336816 -> 2304859337008
	2304859336816 [label="AddBackward0
------------
alpha: 1"]
	2304859336672 -> 2304859336816
	2304859336672 [label="AddBackward0
------------
alpha: 1"]
	2304859338832 -> 2304859336672
	2304859338832 [label="AddBackward0
------------
alpha: 1"]
	2304859338976 -> 2304859338832
	2304859338976 [label="AddBackward0
------------
alpha: 1"]
	2304859339072 -> 2304859338976
	2304859339072 [label="AddBackward0
------------
alpha: 1"]
	2304859339216 -> 2304859339072
	2304859339216 [label="AddBackward0
------------
alpha: 1"]
	2304859339360 -> 2304859339216
	2304859339360 [label="AddBackward0
------------
alpha: 1"]
	2304859339456 -> 2304859339360
	2304859339456 [label="AddBackward0
------------
alpha: 1"]
	2304859339600 -> 2304859339456
	2304859339600 [label="AddBackward0
------------
alpha: 1"]
	2304859339744 -> 2304859339600
	2304859339744 [label="AddBackward0
------------
alpha: 1"]
	2304859339840 -> 2304859339744
	2304859339840 [label="AddBackward0
------------
alpha: 1"]
	2304859339984 -> 2304859339840
	2304859339984 [label="AddBackward0
------------
alpha: 1"]
	2304859340128 -> 2304859339984
	2304859340128 [label="CatBackward0
------------
dim: 1"]
	2304859340224 -> 2304859340128
	2304859340224 [label="ExpandBackward0
---------------------------
self_sym_sizes: (1, 1, 192)"]
	2304859340368 -> 2304859340224
	2304859340368 [label="UnsqueezeBackward0
------------------
dim: 0"]
	2304859340464 -> 2304859340368
	2304530827120 [label="embedding.cls_token
 (1, 192)" fillcolor=lightblue]
	2304530827120 -> 2304859340464
	2304859340464 [label=AccumulateGrad]
	2304859340176 -> 2304859340128
	2304859340176 -> 2304823760176 [dir=none]
	2304823760176 [label="self
 (1, 187, 192)" fillcolor=orange]
	2304859340176 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859340560 -> 2304859340176
	2304859340560 -> 2304530828400 [dir=none]
	2304530828400 [label="bias
 (192)" fillcolor=orange]
	2304859340560 -> 2304823760736 [dir=none]
	2304823760736 [label="input
 (1, 187, 192)" fillcolor=orange]
	2304859340560 -> 2304784552304 [dir=none]
	2304784552304 [label="result1
 (1, 187, 1)" fillcolor=orange]
	2304859340560 -> 2304823713824 [dir=none]
	2304823713824 [label="result2
 (1, 187, 1)" fillcolor=orange]
	2304859340560 -> 2304530828080 [dir=none]
	2304530828080 [label="weight
 (192)" fillcolor=orange]
	2304859340560 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859340272 -> 2304859340560
	2304530828080 [label="embedding.1.weight
 (192)" fillcolor=lightblue]
	2304530828080 -> 2304859340272
	2304859340272 [label=AccumulateGrad]
	2304859340512 -> 2304859340560
	2304530828400 [label="embedding.1.bias
 (192)" fillcolor=lightblue]
	2304530828400 -> 2304859340512
	2304859340512 [label=AccumulateGrad]
	2304859337440 -> 2304859339984
	2304505002032 [label="positional_encoding
 (188, 192)" fillcolor=lightblue]
	2304505002032 -> 2304859337440
	2304859337440 [label=AccumulateGrad]
	2304859339936 -> 2304859339840
	2304859339936 [label=CppFunction]
	2304859340416 -> 2304859339936
	2304859340416 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859340608 -> 2304859340416
	2304859340608 [label=CloneBackward0]
	2304859340704 -> 2304859340608
	2304859340704 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859340752 -> 2304859340704
	2304859340752 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859504800 -> 2304859340752
	2304859504800 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859504896 -> 2304859504800
	2304859504896 -> 2304859417520 [dir=none]
	2304859417520 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859504896 -> 2304859417280 [dir=none]
	2304859417280 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859504896 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859504992 -> 2304859504896
	2304859504992 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859505136 -> 2304859504992
	2304859505136 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859505232 -> 2304859505136
	2304859505232 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859505328 -> 2304859505232
	2304859505328 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859505424 -> 2304859505328
	2304859505424 -> 2304859417760 [dir=none]
	2304859417760 [label="other
 ()" fillcolor=orange]
	2304859505424 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859505520 -> 2304859505424
	2304859505520 -> 2304859418000 [dir=none]
	2304859418000 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859505520 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859505616 -> 2304859505520
	2304859505616 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859505712 -> 2304859505616
	2304859505712 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859505808 -> 2304859505712
	2304859505808 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859505904 -> 2304859505808
	2304859505904 -> 2304859418320 [dir=none]
	2304859418320 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859505904 -> 2304859418240 [dir=none]
	2304859418240 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859505904 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859506048 -> 2304859505904
	2304859506048 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859506192 -> 2304859506048
	2304859506192 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859506288 -> 2304859506192
	2304859506288 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859506336 -> 2304859506288
	2304859506336 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859506480 -> 2304859506336
	2304859506480 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859506624 -> 2304859506480
	2304859506624 [label=CppFunction]
	2304859506816 -> 2304859506624
	2304859506816 -> 2304505105200 [dir=none]
	2304505105200 [label="bias
 (192)" fillcolor=orange]
	2304859506816 -> 2304823761376 [dir=none]
	2304823761376 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859506816 -> 2304859418720 [dir=none]
	2304859418720 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859506816 -> 2304859418480 [dir=none]
	2304859418480 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859506816 -> 2304505104320 [dir=none]
	2304505104320 [label="weight
 (192)" fillcolor=orange]
	2304859506816 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339984 -> 2304859506816
	2304859507056 -> 2304859506816
	2304505104320 [label="encoder.0.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304505104320 -> 2304859507056
	2304859507056 [label=AccumulateGrad]
	2304859506864 -> 2304859506816
	2304505105200 [label="encoder.0.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304505105200 -> 2304859506864
	2304859506864 [label=AccumulateGrad]
	2304859505952 -> 2304859505904
	2304859505952 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859506096 -> 2304859505952
	2304859506096 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859506576 -> 2304859506096
	2304859506576 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859506720 -> 2304859506576
	2304859506720 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859507152 -> 2304859506720
	2304859507152 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859507248 -> 2304859507152
	2304859507248 [label=CppFunction]
	2304859506816 -> 2304859507248
	2304859504944 -> 2304859504896
	2304859504944 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859505280 -> 2304859504944
	2304859505280 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859505472 -> 2304859505280
	2304859505472 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859505664 -> 2304859505472
	2304859505664 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859505856 -> 2304859505664
	2304859505856 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859506240 -> 2304859505856
	2304859506240 [label=CppFunction]
	2304859506816 -> 2304859506240
	2304859339792 -> 2304859339744
	2304859339792 [label=CppFunction]
	2304859340032 -> 2304859339792
	2304859340032 -> 2304859411520 [dir=none]
	2304859411520 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859340032 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859340080 -> 2304859340032
	2304859340080 [label=CppFunction]
	2304859339888 -> 2304859340080
	2304859339888 -> 2304530454608 [dir=none]
	2304530454608 [label="bias
 (192)" fillcolor=orange]
	2304859339888 -> 2304859410800 [dir=none]
	2304859410800 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859339888 -> 2304823721904 [dir=none]
	2304823721904 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859339888 -> 2304859418560 [dir=none]
	2304859418560 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859339888 -> 2304530454208 [dir=none]
	2304530454208 [label="weight
 (192)" fillcolor=orange]
	2304859339888 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339840 -> 2304859339888
	2304859505184 -> 2304859339888
	2304530454208 [label="encoder.0.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530454208 -> 2304859505184
	2304859505184 [label=AccumulateGrad]
	2304859504704 -> 2304859339888
	2304530454608 [label="encoder.0.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530454608 -> 2304859504704
	2304859504704 [label=AccumulateGrad]
	2304859337440 -> 2304859339600
	2304859339552 -> 2304859339456
	2304859339552 [label=CppFunction]
	2304859340320 -> 2304859339552
	2304859340320 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859340656 -> 2304859340320
	2304859340656 [label=CloneBackward0]
	2304859505376 -> 2304859340656
	2304859505376 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859505760 -> 2304859505376
	2304859505760 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859506768 -> 2304859505760
	2304859506768 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859505088 -> 2304859506768
	2304859505088 -> 2304859418880 [dir=none]
	2304859418880 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859505088 -> 2304859419040 [dir=none]
	2304859419040 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859505088 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859507200 -> 2304859505088
	2304859507200 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859506144 -> 2304859507200
	2304859506144 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859507440 -> 2304859506144
	2304859507440 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859507536 -> 2304859507440
	2304859507536 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859507632 -> 2304859507536
	2304859507632 -> 2304859419440 [dir=none]
	2304859419440 [label="other
 ()" fillcolor=orange]
	2304859507632 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859507728 -> 2304859507632
	2304859507728 -> 2304859419680 [dir=none]
	2304859419680 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859507728 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859507824 -> 2304859507728
	2304859507824 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859507920 -> 2304859507824
	2304859507920 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859508016 -> 2304859507920
	2304859508016 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859508112 -> 2304859508016
	2304859508112 -> 2304859420000 [dir=none]
	2304859420000 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859508112 -> 2304859419920 [dir=none]
	2304859419920 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859508112 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859508208 -> 2304859508112
	2304859508208 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859508352 -> 2304859508208
	2304859508352 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859508448 -> 2304859508352
	2304859508448 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859508544 -> 2304859508448
	2304859508544 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859508640 -> 2304859508544
	2304859508640 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859508736 -> 2304859508640
	2304859508736 [label=CppFunction]
	2304859508832 -> 2304859508736
	2304859508832 -> 2304530456528 [dir=none]
	2304530456528 [label="bias
 (192)" fillcolor=orange]
	2304859508832 -> 2304823766176 [dir=none]
	2304823766176 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859508832 -> 2304859420400 [dir=none]
	2304859420400 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859508832 -> 2304859420160 [dir=none]
	2304859420160 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859508832 -> 2304530456208 [dir=none]
	2304530456208 [label="weight
 (192)" fillcolor=orange]
	2304859508832 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339600 -> 2304859508832
	2304859508928 -> 2304859508832
	2304530456208 [label="encoder.1.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304530456208 -> 2304859508928
	2304859508928 [label=AccumulateGrad]
	2304859508880 -> 2304859508832
	2304530456528 [label="encoder.1.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304530456528 -> 2304859508880
	2304859508880 [label=AccumulateGrad]
	2304859508160 -> 2304859508112
	2304859508160 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859508496 -> 2304859508160
	2304859508496 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859508688 -> 2304859508496
	2304859508688 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859508256 -> 2304859508688
	2304859508256 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859509024 -> 2304859508256
	2304859509024 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859509120 -> 2304859509024
	2304859509120 [label=CppFunction]
	2304859508832 -> 2304859509120
	2304859507104 -> 2304859505088
	2304859507104 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859507488 -> 2304859507104
	2304859507488 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859507680 -> 2304859507488
	2304859507680 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859507872 -> 2304859507680
	2304859507872 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859508064 -> 2304859507872
	2304859508064 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859508400 -> 2304859508064
	2304859508400 [label=CppFunction]
	2304859508832 -> 2304859508400
	2304859339408 -> 2304859339360
	2304859339408 [label=CppFunction]
	2304859339696 -> 2304859339408
	2304859339696 -> 2304859412080 [dir=none]
	2304859412080 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859339696 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859339504 -> 2304859339696
	2304859339504 [label=CppFunction]
	2304859506432 -> 2304859339504
	2304859506432 -> 2304530459728 [dir=none]
	2304530459728 [label="bias
 (192)" fillcolor=orange]
	2304859506432 -> 2304859411360 [dir=none]
	2304859411360 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859506432 -> 2304859420480 [dir=none]
	2304859420480 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859506432 -> 2304859420560 [dir=none]
	2304859420560 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859506432 -> 2304530459408 [dir=none]
	2304530459408 [label="weight
 (192)" fillcolor=orange]
	2304859506432 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339456 -> 2304859506432
	2304859507392 -> 2304859506432
	2304530459408 [label="encoder.1.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530459408 -> 2304859507392
	2304859507392 [label=AccumulateGrad]
	2304859504848 -> 2304859506432
	2304530459728 [label="encoder.1.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530459728 -> 2304859504848
	2304859504848 [label=AccumulateGrad]
	2304859337440 -> 2304859339216
	2304859339168 -> 2304859339072
	2304859339168 [label=CppFunction]
	2304859339648 -> 2304859339168
	2304859339648 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859339312 -> 2304859339648
	2304859339312 [label=CloneBackward0]
	2304859507584 -> 2304859339312
	2304859507584 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859507968 -> 2304859507584
	2304859507968 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859508784 -> 2304859507968
	2304859508784 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859507296 -> 2304859508784
	2304859507296 -> 2304859420640 [dir=none]
	2304859420640 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859507296 -> 2304859420800 [dir=none]
	2304859420800 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859507296 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859509072 -> 2304859507296
	2304859509072 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859508304 -> 2304859509072
	2304859508304 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859509312 -> 2304859508304
	2304859509312 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859509408 -> 2304859509312
	2304859509408 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859509504 -> 2304859509408
	2304859509504 -> 2304859420320 [dir=none]
	2304859420320 [label="other
 ()" fillcolor=orange]
	2304859509504 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859509600 -> 2304859509504
	2304859509600 -> 2304859420880 [dir=none]
	2304859420880 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859509600 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859509696 -> 2304859509600
	2304859509696 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859509792 -> 2304859509696
	2304859509792 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859509936 -> 2304859509792
	2304859509936 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859510032 -> 2304859509936
	2304859510032 -> 2304859420960 [dir=none]
	2304859420960 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859510032 -> 2304859420240 [dir=none]
	2304859420240 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859510032 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859510128 -> 2304859510032
	2304859510128 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859510272 -> 2304859510128
	2304859510272 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859510368 -> 2304859510272
	2304859510368 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859510464 -> 2304859510368
	2304859510464 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859510560 -> 2304859510464
	2304859510560 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859510656 -> 2304859510560
	2304859510656 [label=CppFunction]
	2304859510752 -> 2304859510656
	2304859510752 -> 2304530461648 [dir=none]
	2304530461648 [label="bias
 (192)" fillcolor=orange]
	2304859510752 -> 2304859411680 [dir=none]
	2304859411680 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859510752 -> 2304859421040 [dir=none]
	2304859421040 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859510752 -> 2304859420720 [dir=none]
	2304859420720 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859510752 -> 2304530461328 [dir=none]
	2304530461328 [label="weight
 (192)" fillcolor=orange]
	2304859510752 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339216 -> 2304859510752
	2304859510848 -> 2304859510752
	2304530461328 [label="encoder.2.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304530461328 -> 2304859510848
	2304859510848 [label=AccumulateGrad]
	2304859510800 -> 2304859510752
	2304530461648 [label="encoder.2.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304530461648 -> 2304859510800
	2304859510800 [label=AccumulateGrad]
	2304859510080 -> 2304859510032
	2304859510080 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859510416 -> 2304859510080
	2304859510416 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859510608 -> 2304859510416
	2304859510608 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859510176 -> 2304859510608
	2304859510176 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859510944 -> 2304859510176
	2304859510944 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859511040 -> 2304859510944
	2304859511040 [label=CppFunction]
	2304859510752 -> 2304859511040
	2304859508976 -> 2304859507296
	2304859508976 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859509360 -> 2304859508976
	2304859509360 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859509552 -> 2304859509360
	2304859509552 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859509744 -> 2304859509552
	2304859509744 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859509984 -> 2304859509744
	2304859509984 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859510320 -> 2304859509984
	2304859510320 [label=CppFunction]
	2304859510752 -> 2304859510320
	2304859339024 -> 2304859338976
	2304859339024 [label=CppFunction]
	2304859339264 -> 2304859339024
	2304859339264 -> 2304859412640 [dir=none]
	2304859412640 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859339264 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859507776 -> 2304859339264
	2304859507776 [label=CppFunction]
	2304859508592 -> 2304859507776
	2304859508592 -> 2304530579520 [dir=none]
	2304530579520 [label="bias
 (192)" fillcolor=orange]
	2304859508592 -> 2304859411920 [dir=none]
	2304859411920 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859508592 -> 2304859421280 [dir=none]
	2304859421280 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859508592 -> 2304859421360 [dir=none]
	2304859421360 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859508592 -> 2304530464448 [dir=none]
	2304530464448 [label="weight
 (192)" fillcolor=orange]
	2304859508592 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859339072 -> 2304859508592
	2304859509264 -> 2304859508592
	2304530464448 [label="encoder.2.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530464448 -> 2304859509264
	2304859509264 [label=AccumulateGrad]
	2304859505568 -> 2304859508592
	2304530579520 [label="encoder.2.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530579520 -> 2304859505568
	2304859505568 [label=AccumulateGrad]
	2304859337440 -> 2304859338832
	2304859338784 -> 2304859336672
	2304859338784 [label=CppFunction]
	2304859339120 -> 2304859338784
	2304859339120 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859338928 -> 2304859339120
	2304859338928 [label=CloneBackward0]
	2304859509456 -> 2304859338928
	2304859509456 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859509888 -> 2304859509456
	2304859509888 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859510704 -> 2304859509888
	2304859510704 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859509168 -> 2304859510704
	2304859509168 -> 2304859421440 [dir=none]
	2304859421440 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859509168 -> 2304859421600 [dir=none]
	2304859421600 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859509168 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859510992 -> 2304859509168
	2304859510992 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859510224 -> 2304859510992
	2304859510224 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859511232 -> 2304859510224
	2304859511232 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859511328 -> 2304859511232
	2304859511328 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859511424 -> 2304859511328
	2304859511424 -> 2304859421200 [dir=none]
	2304859421200 [label="other
 ()" fillcolor=orange]
	2304859511424 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859511520 -> 2304859511424
	2304859511520 -> 2304859421680 [dir=none]
	2304859421680 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859511520 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859511616 -> 2304859511520
	2304859511616 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859511712 -> 2304859511616
	2304859511712 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859511808 -> 2304859511712
	2304859511808 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859511904 -> 2304859511808
	2304859511904 -> 2304859421760 [dir=none]
	2304859421760 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859511904 -> 2304859421120 [dir=none]
	2304859421120 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859511904 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859512000 -> 2304859511904
	2304859512000 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859512144 -> 2304859512000
	2304859512144 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859512240 -> 2304859512144
	2304859512240 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859512336 -> 2304859512240
	2304859512336 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859512432 -> 2304859512336
	2304859512432 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859512528 -> 2304859512432
	2304859512528 [label=CppFunction]
	2304859512624 -> 2304859512528
	2304859512624 -> 2304530581360 [dir=none]
	2304530581360 [label="bias
 (192)" fillcolor=orange]
	2304859512624 -> 2304859412240 [dir=none]
	2304859412240 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859512624 -> 2304859421840 [dir=none]
	2304859421840 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859512624 -> 2304859421520 [dir=none]
	2304859421520 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859512624 -> 2304530581040 [dir=none]
	2304530581040 [label="weight
 (192)" fillcolor=orange]
	2304859512624 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859338832 -> 2304859512624
	2304859512720 -> 2304859512624
	2304530581040 [label="encoder.3.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304530581040 -> 2304859512720
	2304859512720 [label=AccumulateGrad]
	2304859512672 -> 2304859512624
	2304530581360 [label="encoder.3.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304530581360 -> 2304859512672
	2304859512672 [label=AccumulateGrad]
	2304859511952 -> 2304859511904
	2304859511952 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859512288 -> 2304859511952
	2304859512288 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859512480 -> 2304859512288
	2304859512480 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859512048 -> 2304859512480
	2304859512048 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859512816 -> 2304859512048
	2304859512816 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859512912 -> 2304859512816
	2304859512912 [label=CppFunction]
	2304859512624 -> 2304859512912
	2304859510896 -> 2304859509168
	2304859510896 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859511280 -> 2304859510896
	2304859511280 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859511472 -> 2304859511280
	2304859511472 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859511664 -> 2304859511472
	2304859511664 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859511856 -> 2304859511664
	2304859511856 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859512192 -> 2304859511856
	2304859512192 [label=CppFunction]
	2304859512624 -> 2304859512192
	2304859336720 -> 2304859336816
	2304859336720 [label=CppFunction]
	2304859338880 -> 2304859336720
	2304859338880 -> 2304859413200 [dir=none]
	2304859413200 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859338880 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859509648 -> 2304859338880
	2304859509648 [label=CppFunction]
	2304859510512 -> 2304859509648
	2304859510512 -> 2304530584400 [dir=none]
	2304530584400 [label="bias
 (192)" fillcolor=orange]
	2304859510512 -> 2304859412480 [dir=none]
	2304859412480 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859510512 -> 2304859422080 [dir=none]
	2304859422080 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859510512 -> 2304859422160 [dir=none]
	2304859422160 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859510512 -> 2304530584080 [dir=none]
	2304530584080 [label="weight
 (192)" fillcolor=orange]
	2304859510512 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859336672 -> 2304859510512
	2304859511184 -> 2304859510512
	2304530584080 [label="encoder.3.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530584080 -> 2304859511184
	2304859511184 [label=AccumulateGrad]
	2304859504752 -> 2304859510512
	2304530584400 [label="encoder.3.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530584400 -> 2304859504752
	2304859504752 [label=AccumulateGrad]
	2304859337440 -> 2304859337008
	2304859337056 -> 2304859337248
	2304859337056 [label=CppFunction]
	2304859338736 -> 2304859337056
	2304859338736 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859336864 -> 2304859338736
	2304859336864 [label=CloneBackward0]
	2304859511376 -> 2304859336864
	2304859511376 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859511760 -> 2304859511376
	2304859511760 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859512576 -> 2304859511760
	2304859512576 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859511088 -> 2304859512576
	2304859511088 -> 2304859422240 [dir=none]
	2304859422240 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859511088 -> 2304859422400 [dir=none]
	2304859422400 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859511088 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859512864 -> 2304859511088
	2304859512864 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859512096 -> 2304859512864
	2304859512096 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859513104 -> 2304859512096
	2304859513104 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859513200 -> 2304859513104
	2304859513200 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859513296 -> 2304859513200
	2304859513296 -> 2304859422000 [dir=none]
	2304859422000 [label="other
 ()" fillcolor=orange]
	2304859513296 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859513392 -> 2304859513296
	2304859513392 -> 2304859422480 [dir=none]
	2304859422480 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859513392 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859513488 -> 2304859513392
	2304859513488 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859513584 -> 2304859513488
	2304859513584 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859513680 -> 2304859513584
	2304859513680 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859513776 -> 2304859513680
	2304859513776 -> 2304859422560 [dir=none]
	2304859422560 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859513776 -> 2304859421920 [dir=none]
	2304859421920 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859513776 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859513872 -> 2304859513776
	2304859513872 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859514016 -> 2304859513872
	2304859514016 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859514112 -> 2304859514016
	2304859514112 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859514208 -> 2304859514112
	2304859514208 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859514304 -> 2304859514208
	2304859514304 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859514400 -> 2304859514304
	2304859514400 [label=CppFunction]
	2304859514496 -> 2304859514400
	2304859514496 -> 2304530586240 [dir=none]
	2304530586240 [label="bias
 (192)" fillcolor=orange]
	2304859514496 -> 2304859412800 [dir=none]
	2304859412800 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859514496 -> 2304859422320 [dir=none]
	2304859422320 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859514496 -> 2304859422640 [dir=none]
	2304859422640 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859514496 -> 2304530585920 [dir=none]
	2304530585920 [label="weight
 (192)" fillcolor=orange]
	2304859514496 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859337008 -> 2304859514496
	2304859514592 -> 2304859514496
	2304530585920 [label="encoder.4.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304530585920 -> 2304859514592
	2304859514592 [label=AccumulateGrad]
	2304859514544 -> 2304859514496
	2304530586240 [label="encoder.4.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304530586240 -> 2304859514544
	2304859514544 [label=AccumulateGrad]
	2304859513824 -> 2304859513776
	2304859513824 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859514160 -> 2304859513824
	2304859514160 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859514352 -> 2304859514160
	2304859514352 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859513920 -> 2304859514352
	2304859513920 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859514688 -> 2304859513920
	2304859514688 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859514784 -> 2304859514688
	2304859514784 [label=CppFunction]
	2304859514496 -> 2304859514784
	2304859512768 -> 2304859511088
	2304859512768 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859513152 -> 2304859512768
	2304859513152 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859513344 -> 2304859513152
	2304859513344 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859513536 -> 2304859513344
	2304859513536 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859513728 -> 2304859513536
	2304859513728 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859514064 -> 2304859513728
	2304859514064 [label=CppFunction]
	2304859514496 -> 2304859514064
	2304859337296 -> 2304859337392
	2304859337296 [label=CppFunction]
	2304859336960 -> 2304859337296
	2304859336960 -> 2304859413760 [dir=none]
	2304859413760 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859336960 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859511568 -> 2304859336960
	2304859511568 [label=CppFunction]
	2304859512384 -> 2304859511568
	2304859512384 -> 2304530589360 [dir=none]
	2304530589360 [label="bias
 (192)" fillcolor=orange]
	2304859512384 -> 2304859413040 [dir=none]
	2304859413040 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859512384 -> 2304859619472 [dir=none]
	2304859619472 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859512384 -> 2304859619632 [dir=none]
	2304859619632 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859512384 -> 2304530589040 [dir=none]
	2304530589040 [label="weight
 (192)" fillcolor=orange]
	2304859512384 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859337248 -> 2304859512384
	2304859513056 -> 2304859512384
	2304530589040 [label="encoder.4.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530589040 -> 2304859513056
	2304859513056 [label=AccumulateGrad]
	2304859505040 -> 2304859512384
	2304530589360 [label="encoder.4.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530589360 -> 2304859505040
	2304859505040 [label=AccumulateGrad]
	2304859337440 -> 2304859337536
	2304859337584 -> 2304859337824
	2304859337584 [label=CppFunction]
	2304859337104 -> 2304859337584
	2304859337104 [label="UnsafeViewBackward0
-------------------------------
self_sym_sizes: (1, 188, 8, 24)"]
	2304859337488 -> 2304859337104
	2304859337488 [label=CloneBackward0]
	2304859513248 -> 2304859337488
	2304859513248 [label="ViewBackward0
----------------------------------
self_sym_sizes: (1, 188, 8, 24, 1)"]
	2304859513632 -> 2304859513248
	2304859513632 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859514448 -> 2304859513632
	2304859514448 [label="ViewBackward0
----------------------------
self_sym_sizes: (8, 188, 24)"]
	2304859512960 -> 2304859514448
	2304859512960 -> 2304859619712 [dir=none]
	2304859619712 [label="mat2
 (8, 188, 24)" fillcolor=orange]
	2304859512960 -> 2304859619872 [dir=none]
	2304859619872 [label="self
 (8, 188, 188)" fillcolor=orange]
	2304859512960 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859514736 -> 2304859512960
	2304859514736 [label="ReshapeAliasBackward0
-----------------------------------
self_sym_sizes: (8, 188, 188, 1, 1)"]
	2304859513968 -> 2304859514736
	2304859513968 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859514976 -> 2304859513968
	2304859514976 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859515072 -> 2304859514976
	2304859515072 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859515168 -> 2304859515072
	2304859515168 -> 2304859619392 [dir=none]
	2304859619392 [label="other
 ()" fillcolor=orange]
	2304859515168 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	2304859515264 -> 2304859515168
	2304859515264 -> 2304859619952 [dir=none]
	2304859619952 [label="result
 (1, 188, 8, 188)" fillcolor=orange]
	2304859515264 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2304859515360 -> 2304859515264
	2304859515360 [label="ViewBackward0
-----------------------------------
self_sym_sizes: (1, 188, 8, 188, 1)"]
	2304859515456 -> 2304859515360
	2304859515456 [label="PermuteBackward0
---------------------
dims: (3, 1, 0, 4, 2)"]
	2304859515552 -> 2304859515456
	2304859515552 [label="ViewBackward0
-----------------------------
self_sym_sizes: (8, 188, 188)"]
	2304859515648 -> 2304859515552
	2304859515648 -> 2304859620032 [dir=none]
	2304859620032 [label="mat2
 (8, 24, 188)" fillcolor=orange]
	2304859515648 -> 2304859619552 [dir=none]
	2304859619552 [label="self
 (8, 188, 24)" fillcolor=orange]
	2304859515648 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2304859515744 -> 2304859515648
	2304859515744 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 24, 1, 1)"]
	2304859515888 -> 2304859515744
	2304859515888 [label="PermuteBackward0
---------------------
dims: (2, 1, 4, 0, 3)"]
	2304859515984 -> 2304859515888
	2304859515984 [label="PermuteBackward0
---------------------
dims: (0, 1, 2, 4, 3)"]
	2304859516080 -> 2304859515984
	2304859516080 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859516176 -> 2304859516080
	2304859516176 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859516272 -> 2304859516176
	2304859516272 [label=CppFunction]
	2304859516368 -> 2304859516272
	2304859516368 -> 2304530591280 [dir=none]
	2304530591280 [label="bias
 (192)" fillcolor=orange]
	2304859516368 -> 2304859413360 [dir=none]
	2304859413360 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859516368 -> 2304859620112 [dir=none]
	2304859620112 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859516368 -> 2304859619792 [dir=none]
	2304859619792 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859516368 -> 2304530590960 [dir=none]
	2304530590960 [label="weight
 (192)" fillcolor=orange]
	2304859516368 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859337536 -> 2304859516368
	2304859516464 -> 2304859516368
	2304530590960 [label="encoder.5.0.block.0.weight
 (192)" fillcolor=lightblue]
	2304530590960 -> 2304859516464
	2304859516464 [label=AccumulateGrad]
	2304859516416 -> 2304859516368
	2304530591280 [label="encoder.5.0.block.0.bias
 (192)" fillcolor=lightblue]
	2304530591280 -> 2304859516416
	2304859516416 [label=AccumulateGrad]
	2304859515696 -> 2304859515648
	2304859515696 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 24, 1, 188, 1)"]
	2304859516032 -> 2304859515696
	2304859516032 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859516224 -> 2304859516032
	2304859516224 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 1, 3)"]
	2304859515792 -> 2304859516224
	2304859515792 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859516560 -> 2304859515792
	2304859516560 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859516656 -> 2304859516560
	2304859516656 [label=CppFunction]
	2304859516368 -> 2304859516656
	2304859514640 -> 2304859512960
	2304859514640 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (8, 188, 1, 24, 1)"]
	2304859515024 -> 2304859514640
	2304859515024 [label="PermuteBackward0
---------------------
dims: (2, 4, 0, 3, 1)"]
	2304859515216 -> 2304859515024
	2304859515216 [label="PermuteBackward0
---------------------
dims: (0, 4, 2, 3, 1)"]
	2304859515408 -> 2304859515216
	2304859515408 [label="UnsqueezeBackward0
------------------
dim: 4"]
	2304859515600 -> 2304859515408
	2304859515600 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 188, 192)"]
	2304859515936 -> 2304859515600
	2304859515936 [label=CppFunction]
	2304859516368 -> 2304859515936
	2304859337872 -> 2304859337920
	2304859337872 [label=CppFunction]
	2304859337344 -> 2304859337872
	2304859337344 -> 2304859414320 [dir=none]
	2304859414320 [label="self
 (1, 188, 768)" fillcolor=orange]
	2304859337344 [label="GeluBackward0
---------------------------
approximate:           none
self       : [saved tensor]"]
	2304859513440 -> 2304859337344
	2304859513440 [label=CppFunction]
	2304859514256 -> 2304859513440
	2304859514256 -> 2304530594400 [dir=none]
	2304530594400 [label="bias
 (192)" fillcolor=orange]
	2304859514256 -> 2304859413600 [dir=none]
	2304859413600 [label="input
 (1, 188, 192)" fillcolor=orange]
	2304859514256 -> 2304859620352 [dir=none]
	2304859620352 [label="result1
 (1, 188, 1)" fillcolor=orange]
	2304859514256 -> 2304859620432 [dir=none]
	2304859620432 [label="result2
 (1, 188, 1)" fillcolor=orange]
	2304859514256 -> 2304530594080 [dir=none]
	2304530594080 [label="weight
 (192)" fillcolor=orange]
	2304859514256 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (192,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2304859337824 -> 2304859514256
	2304859514928 -> 2304859514256
	2304530594080 [label="encoder.5.1.block.0.weight
 (192)" fillcolor=lightblue]
	2304530594080 -> 2304859514928
	2304859514928 [label=AccumulateGrad]
	2304859507344 -> 2304859514256
	2304530594400 [label="encoder.5.1.block.0.bias
 (192)" fillcolor=lightblue]
	2304530594400 -> 2304859507344
	2304859507344 [label=AccumulateGrad]
	2304859338208 -> 2304859338256
	2304530825840 [label="classifier.2.weight
 (192)" fillcolor=lightblue]
	2304530825840 -> 2304859338208
	2304859338208 [label=AccumulateGrad]
	2304859338304 -> 2304859338256
	2304530826160 [label="classifier.2.bias
 (192)" fillcolor=lightblue]
	2304530826160 -> 2304859338304
	2304859338304 [label=AccumulateGrad]
	2304859338640 -> 2304859410720
}
