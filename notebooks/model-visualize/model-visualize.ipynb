{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:07.307679Z",
     "start_time": "2024-05-06T06:27:02.565293Z"
    }
   },
   "source": [
    "import itertools # 是 Python 的內建模組，提供了一組用於處理迭代器的函數和工具。\n",
    "                 # 它包含了各種用於高效處理迭代器的函數，可以幫助我們編寫更簡潔、高效的代碼。\n",
    "import sys # 是 Python 的內建模組，提供了與 Python 解釋器和運行環境相關的功能。\n",
    "# sys.path 是一個列表，包含了 Python 解釋器在導入模組時會搜尋的路徑。\n",
    "# 當你使用 import 語句導入模組時 Python 會依次在 sys.path 中的路徑下尋找對應的模組文件。\n",
    "sys.path.append(\"../ecg-classification/\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\Chen_Lab01\\\\Documents\\\\GitHub/ecg-classification\")\n",
    "# from IPython.display import Video\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\") #  是 Matplotlib 庫中用於設置繪圖樣式的函數。它使用了一種名為 \"ggplot\" 的預定義樣式\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "                        #  該樣式模仿了 R 語言的 ggplot2 繪圖包的外觀。\n",
    "# print(sys.path)\n",
    "import torch\n",
    "from ecg_tools.config import EcgConfig, Mode\n",
    "from ecg_tools.data_loader import DatasetConfig, get_data_loaders\n",
    "from ecg_tools.model import ECGformer\n",
    "from ecg_tools.train import ECGClassifierTrainer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize the model",
   "id": "47dab4244e5f9743"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load",
   "id": "3a881f2b807408c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the model",
   "id": "ab9000cbc621d3da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:07.431802Z",
     "start_time": "2024-05-06T06:27:07.309680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.load(\"..\\\\..\\\\model_save\\\\model_epoch_598.pth\")\n",
    "model.eval()\n",
    "model.to('cpu')"
   ],
   "id": "65a7293516b0cca3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECGformer(\n",
       "  (encoder): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (0): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): MultiHeadAttention(\n",
       "            (queries_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (values_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (keys_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (final_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (embedding): LinearEmbedding(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load quantized model",
   "id": "a131bd3c8ecabac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:07.447307Z",
     "start_time": "2024-05-06T06:27:07.432803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = EcgConfig()    \n",
    "model_quantized = torch.load(\"..\\\\..\\\\model_save\\\\model_quantized_598.pth\")\n",
    "model_quantized.eval()\n",
    "model_quantized.to('cpu')"
   ],
   "id": "97ef5e082b44725f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xaio\\anaconda3\\envs\\pytorch-ecg\\lib\\site-packages\\torch\\_utils.py:382: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ECGformer(\n",
       "  (encoder): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (0): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): MultiHeadAttention(\n",
       "            (queries_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (values_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (keys_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "            (final_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "          )\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): DynamicQuantizedLinear(in_features=64, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       "  (embedding): LinearEmbedding(\n",
       "    (0): DynamicQuantizedLinear(in_features=1, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    (1): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "print model",
   "id": "d21832b978b1967c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TorchInfo summary",
   "id": "8844fda5bfe38d64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:07.463409Z",
     "start_time": "2024-05-06T06:27:07.448807Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_quantized)",
   "id": "c3ad1d2037868cd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGformer(\n",
      "  (encoder): ModuleList(\n",
      "    (0): TransformerEncoderLayer(\n",
      "      (0): ResidualAdd(\n",
      "        (block): Sequential(\n",
      "          (0): MultiHeadAttention(\n",
      "            (queries_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (values_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (keys_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (final_projection): DynamicQuantizedLinear(in_features=64, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          )\n",
      "          (1): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (0): Reduce('b n e -> b e', 'mean')\n",
      "    (1): DynamicQuantizedLinear(in_features=64, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (embedding): LinearEmbedding(\n",
      "    (0): DynamicQuantizedLinear(in_features=1, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model summary",
   "id": "bb2b5f7aa602013b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "import sys\n",
    "\n",
    "# Save reference to original stdout\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "# Redirect stdout to file and call summary()\n",
    "with open('model-summary.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    print(f\"Model Summary for {type(model_quantized).__name__}:\")\n",
    "    summary(model_quantized, \n",
    "            input_size=(1, config.model.signal_length, 1),\n",
    "            device='cpu', \n",
    "            col_names=(\"input_size\", \"output_size\"),\n",
    "            depth=6,\n",
    "            verbose=1)\n",
    "\n",
    "# Reset stdout back to original\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(\"Model summary saved to model-summary.txt\")\n"
   ],
   "id": "616e6e444a6c674d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Neutron 可視化",
   "id": "7c8315ac48f63a4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ONNX 檔案\n",
    "Neutron 可視化最齊全的是 ONNX 格式，但是不支援 quantized model，這裡使用原始 model"
   ],
   "id": "de93834caff6d353"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:14.087802Z",
     "start_time": "2024-05-06T06:27:13.885120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_names = [\"ECG Classification Input\"]\n",
    "output_names = [\"Prediction\"]\n",
    "X = torch.randn(1, 63, 1)\n",
    "torch.onnx.export(model, X, \"model.onnx\", input_names=input_names, output_names=output_names)"
   ],
   "id": "82433c541eabc31f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TorchScript 檔案",
   "id": "c01e28d852e6189"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T06:27:17.743137Z",
     "start_time": "2024-05-06T06:27:17.246731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.randn(1, 63, 1)\n",
    "traced_script_module = torch.jit.trace(model_quantized, inputs)\n",
    "traced_script_module.save(\"traced_resnet_model.pth\")\n",
    "\n",
    "import netron\n",
    "modelData = 'traced_resnet_model.pth'\n",
    "netron.start(modelData)"
   ],
   "id": "28936bdc1d18e69e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'traced_resnet_model.pth' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grapviz 可視化",
   "id": "b424843e36b94c23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchviz import make_dot\n",
    "vis_graph = make_dot(model_quantized(inputs), params=dict(model_quantized.named_parameters()), show_attrs=True, show_saved=True)\n",
    "vis_graph.view()  # 當前目錄保存為 pdf 文件"
   ],
   "id": "6541dab9a16979c8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
