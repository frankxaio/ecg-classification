{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:36.539419Z",
     "start_time": "2024-05-02T18:53:31.244300Z"
    }
   },
   "source": [
    "import itertools # 是 Python 的內建模組，提供了一組用於處理迭代器的函數和工具。\n",
    "                 # 它包含了各種用於高效處理迭代器的函數，可以幫助我們編寫更簡潔、高效的代碼。\n",
    "import sys # 是 Python 的內建模組，提供了與 Python 解釋器和運行環境相關的功能。\n",
    "# sys.path 是一個列表，包含了 Python 解釋器在導入模組時會搜尋的路徑。\n",
    "# 當你使用 import 語句導入模組時 Python 會依次在 sys.path 中的路徑下尋找對應的模組文件。\n",
    "sys.path.append(\"../ecg-classification/\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\Chen_Lab01\\\\Documents\\\\GitHub/ecg-classification\")\n",
    "# from IPython.display import Video\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\") #  是 Matplotlib 庫中用於設置繪圖樣式的函數。它使用了一種名為 \"ggplot\" 的預定義樣式\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "                        #  該樣式模仿了 R 語言的 ggplot2 繪圖包的外觀。\n",
    "# print(sys.path)\n",
    "import torch\n",
    "from ecg_tools.config import EcgConfig, Mode\n",
    "from ecg_tools.data_loader import DatasetConfig, get_data_loaders\n",
    "from ecg_tools.model import ECGformer\n",
    "from ecg_tools.train import ECGClassifierTrainer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "adbb91b9dbfa94e3",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "id": "29bb12472624e7d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:36.710855Z",
     "start_time": "2024-05-02T18:53:36.540772Z"
    }
   },
   "source": [
    "import torch\n",
    "config = EcgConfig()    \n",
    "model = torch.load(\"..\\\\..\\\\model_save\\\\model_epoch_98.pth\")\n",
    "model.eval()\n",
    "model.to('cpu')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECGformer(\n",
       "  (encoder): ModuleList(\n",
       "    (0-5): 6 x TransformerEncoderLayer(\n",
       "      (0): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): MultiHeadAttention(\n",
       "            (queries_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (values_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (keys_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (final_projection): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualAdd(\n",
       "        (block): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          )\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): Linear(in_features=192, out_features=192, bias=True)\n",
       "    (2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Linear(in_features=192, out_features=6, bias=True)\n",
       "  )\n",
       "  (embedding): LinearEmbedding(\n",
       "    (0): Linear(in_features=1, out_features=192, bias=True)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "fdc775d31a626cf5",
   "metadata": {},
   "source": [
    "量化模型"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe171c96df432930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:37.474412Z",
     "start_time": "2024-05-02T18:53:36.711361Z"
    }
   },
   "source": [
    "import quanto\n",
    "from quanto import Calibration, freeze, qfloat8, qint4, qint8, quantize\n",
    "\n",
    "quantize(model, weights=quanto.qint8, activations=quanto.qint8) # 量化線性層\n",
    "freeze(model)\n",
    "torch.save(model, \"..\\\\..\\\\model_save\\\\model_quantized_98_quanto.pth\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "48981fc857f746e3",
   "metadata": {},
   "source": [
    "準確度測試"
   ]
  },
  {
   "cell_type": "code",
   "id": "780d3550eb5bc030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:43.538654Z",
     "start_time": "2024-05-02T18:53:37.475915Z"
    }
   },
   "source": [
    "import einops\n",
    "loader = get_data_loaders(DatasetConfig())\n",
    "accuracy = 0\n",
    "model.eval()\n",
    "for signal, label in loader[Mode.eval]:\n",
    "    signal.to('cpu')\n",
    "    label.to('cpu')\n",
    "    signal = einops.rearrange(signal, \"b c e -> b e c\")\n",
    "    # print(signal)\n",
    "    p = model(signal)\n",
    "    print(p)\n",
    "    print(label)\n",
    "    print(signal.shape, label.shape)\n",
    "    print(p.argmax(1) == label)\n",
    "    accuracy += torch.sum(p.argmax(1) == label)\n",
    "    print(f\"accuracy: {accuracy / config.dataset.batch_size}\")\n",
    "    break\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTensor(tensor([[  5,   1,  -5,   1,  -9,  -1],\n",
      "        [  4,  -1,  -3,   1,  -5,  -2],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  7,  -6,  -3,   1,  -9,   3],\n",
      "        [  6,  -1,  -4,   1, -10,   0],\n",
      "        [  6,   1,  -5,   0,  -9,  -1],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  4,  -1,  -3,   1,  -6,  -2],\n",
      "        [  6,   0,  -5,   1, -11,   0],\n",
      "        [  4,  -1,  -2,   1,  -7,  -2],\n",
      "        [  6,   0,  -5,   1, -10,   0],\n",
      "        [  7,  -4,  -4,   1,  -8,   0],\n",
      "        [  4,  -1,  -3,   1,  -6,  -2],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  6,   1,  -5,   1, -10,  -1],\n",
      "        [  5,   0,  -5,   1, -10,   0],\n",
      "        [  5,   1,  -5,   1, -10,  -1],\n",
      "        [  6,   0,  -4,   1, -11,   0],\n",
      "        [  6,   1,  -5,   0,  -9,  -1],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  6,   0,  -5,   0, -10,  -1],\n",
      "        [  3,  -4,  -1,   2,  -5,   2],\n",
      "        [  6,  -2,  -5,   1,  -7,  -1],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  4,  -2,  -3,   1,  -5,  -2],\n",
      "        [  6,  -1,  -5,   1,  -8,   0],\n",
      "        [  5,   1,  -5,   1, -10,  -1],\n",
      "        [  6,   1,  -5,   0, -11,  -1],\n",
      "        [  5,   1,  -4,   1, -12,  -1],\n",
      "        [  5,  -3,  -3,   1,  -5,  -2],\n",
      "        [  4,  -1,  -3,   1,  -6,  -2],\n",
      "        [  6,   1,  -4,   0, -10,  -1],\n",
      "        [  5,  -5,  -3,   1,  -8,   3],\n",
      "        [  4,  -1,  -3,   0,  -5,  -2],\n",
      "        [  4,  -1,  -2,   1,  -6,  -2],\n",
      "        [  6,  -1,  -5,   1, -10,   0],\n",
      "        [  6,   0,  -5,   1, -10,   0],\n",
      "        [  6,  -5,  -3,   1,  -9,   3],\n",
      "        [  6,   1,  -5,   0, -11,  -1],\n",
      "        [  5,  -5,  -3,   2,  -6,   3],\n",
      "        [  6,   0,  -4,   1, -11,   0],\n",
      "        [  5,   0,  -4,   1, -11,   0],\n",
      "        [  5,  -3,  -3,   1,  -5,  -1],\n",
      "        [  6,   0,  -6,   0, -10,   1],\n",
      "        [  5,   1,  -5,   1, -10,   0],\n",
      "        [  4,  -1,  -3,   0,  -5,  -2],\n",
      "        [  7,  -5,  -5,   2,  -8,   0],\n",
      "        [  6,   0,  -5,   0, -11,   0],\n",
      "        [  6,   1,  -5,   1, -10,  -1],\n",
      "        [  5,  -2,  -4,   1,  -8,   0],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  5,  -1,  -5,   0,  -9,   0],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  5,   0,  -4,   1, -11,   0],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  5,  -1,  -4,   1, -10,   0],\n",
      "        [  5,  -3,  -4,   0,  -8,   1],\n",
      "        [  6,   1,  -6,   0,  -9,   0],\n",
      "        [  6,  -1,  -5,   0,  -9,   0],\n",
      "        [  6,  -5,  -3,   2,  -9,   2],\n",
      "        [  6,  -1,  -5,   1, -11,   0],\n",
      "        [  6,   1,  -5,   0, -11,  -1],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  5,  -1,  -3,   1, -10,   0],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  5,  -5,  -3,   2,  -6,   3],\n",
      "        [  6,   1,  -4,   0, -10,  -1],\n",
      "        [  5,   1,  -5,   1,  -9,  -1],\n",
      "        [  6,   0,  -5,   0, -10,   0],\n",
      "        [  6,   0,  -4,   0, -11,   0],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  6,   0,  -4,   0, -11,   0],\n",
      "        [  6,   0,  -5,   0, -11,   0],\n",
      "        [  6,  -2,  -3,   1,  -8,  -1],\n",
      "        [  7,  -5,  -4,   1,  -9,   1],\n",
      "        [  4,  -1,  -3,   0,  -6,  -2],\n",
      "        [  6,   1,  -6,   0,  -9,  -1],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  6,  -1,  -4,   0, -10,   0],\n",
      "        [  5,   1,  -5,   1, -10,  -1],\n",
      "        [  6,  -1,  -5,   0, -10,   0],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  4,  -1,  -3,   0,  -6,  -2],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  5,   1,  -5,  -1, -10,  -1],\n",
      "        [  6,   0,  -5,   1, -10,   0],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  5,  -1,  -3,   0,  -6,  -2],\n",
      "        [  6,   1,  -6,   1,  -9,  -1],\n",
      "        [  5,  -2,  -3,   1,  -6,  -1],\n",
      "        [  4,  -1,  -3,   1,  -6,  -2],\n",
      "        [  4,  -1,  -3,   1,  -6,  -2],\n",
      "        [  5,  -2,  -4,   1,  -8,   0],\n",
      "        [  5,  -2,  -3,   1,  -5,  -2],\n",
      "        [  6,   0,  -5,   0, -11,   1],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  6,   0,  -4,   0, -10,  -1],\n",
      "        [  6,   0,  -5,   0, -11,   0],\n",
      "        [  6,   1,  -5,   0, -10,  -1],\n",
      "        [  5,  -5,  -3,   2,  -8,   2],\n",
      "        [  6,   1,  -5,   0, -11,  -1],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  5,  -2,  -3,   1,  -6,  -2],\n",
      "        [  5,  -1,  -4,   1,  -9,   0],\n",
      "        [  5,  -2,  -3,   1,  -7,  -2],\n",
      "        [  5,  -1,  -4,   0,  -9,   0],\n",
      "        [  6,   1,  -4,   0, -11,   0],\n",
      "        [  6,   1,  -5,   0, -11,  -1],\n",
      "        [  5,  -1,  -4,   0, -11,   0],\n",
      "        [  6,   1,  -5,   1, -10,  -1],\n",
      "        [  5,  -2,  -3,   1,  -7,  -1],\n",
      "        [  7,  -4,  -3,   0,  -9,   0],\n",
      "        [  5,  -3,  -2,   1,  -6,  -2],\n",
      "        [  5,   1,  -5,   1, -10,  -1],\n",
      "        [  5,  -5,  -2,   2,  -7,   3],\n",
      "        [  4,  -2,  -2,   1,  -6,  -2],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  5,  -1,  -4,   1,  -9,   0],\n",
      "        [  6,  -4,  -2,   2,  -7,   1],\n",
      "        [  5,  -1,  -4,   0,  -9,   0],\n",
      "        [  4,  -2,  -3,   1,  -6,  -2],\n",
      "        [  4,  -1,  -2,   0,  -6,  -2],\n",
      "        [  6,   1,  -5,   0,  -9,  -1],\n",
      "        [  6,   0,  -5,   1, -11,   0]], dtype=torch.int8), scale=1.0, public_dtype=torch.float32, grad_fn=<torch.autograd.function.QuantizerBackward object at 0x0000027795E90E40>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1,\n",
      "        2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "        0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 4, 0, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0,\n",
      "        0, 0, 5, 4, 4, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 2, 0,\n",
      "        1, 2, 0, 2, 4, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 3,\n",
      "        0, 0, 0, 0, 0, 0, 5, 0])\n",
      "torch.Size([128, 187, 1]) torch.Size([128])\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True, False, False,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
      "        False,  True,  True, False,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True, False, False, False, False,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True,  True,  True,  True, False,  True])\n",
      "accuracy: 0.7578125\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize the model",
   "id": "379edaba6f750520"
  },
  {
   "cell_type": "markdown",
   "id": "bc9c7997add87778",
   "metadata": {},
   "source": [
    "Neutron 可視化"
   ]
  },
  {
   "cell_type": "code",
   "id": "198696373b0fcab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:44.306617Z",
     "start_time": "2024-05-02T18:53:43.660437Z"
    }
   },
   "source": [
    "inputs = torch.randn(1, 187, 1)\n",
    "traced_script_module = torch.jit.trace(model_quantized, inputs)\n",
    "traced_script_module.save(\"traced_resnet_model.pth\")\n",
    "\n",
    "import netron\n",
    "modelData = 'traced_resnet_model.pth'\n",
    "netron.start(modelData)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_quantized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m inputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m187\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m traced_script_module \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mtrace(\u001B[43mmodel_quantized\u001B[49m, inputs)\n\u001B[0;32m      3\u001B[0m traced_script_module\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraced_resnet_model.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnetron\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model_quantized' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "235629a16d18a7d3",
   "metadata": {},
   "source": [
    "Grapviz 可視化"
   ]
  },
  {
   "cell_type": "code",
   "id": "e36b52a2d77913ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:53:43.646417Z",
     "start_time": "2024-05-02T18:53:43.638415Z"
    }
   },
   "source": [
    "# from torchviz import make_dot\n",
    "# vis_graph = make_dot(model_quantized(inputs), params=dict(model_quantized.named_parameters()), show_attrs=True, show_saved=True)\n",
    "# vis_graph.view()  # 会在当前目录下保存一个“Digraph.gv.pdf”文件，并在默认浏览器中打开"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "18593e383e1153c3",
   "metadata": {},
   "source": "## Parameter Extraction"
  },
  {
   "cell_type": "markdown",
   "id": "9da43806140530cf",
   "metadata": {},
   "source": [
    "### 提取全部的參數(忽略量化的資訊)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7dff539acd7bfd93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T18:54:09.161238Z",
     "start_time": "2024-05-02T18:54:09.053185Z"
    }
   },
   "source": [
    "model_state_dict = model.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    'scale',\n",
    "    'zero_point',\n",
    "    '_packed_params.dtype'\n",
    "]\n",
    "\n",
    "with open('model_layers_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if not any(ignore_key in layer_name for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\") \n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "1b8d3a51dac9641d",
   "metadata": {},
   "source": [
    "### 提取六層 Encoder 參數"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c3a2eb2b1a473e5",
   "metadata": {},
   "source": [
    "model_state_dict = model_quantized.state_dict()\n",
    "\n",
    "ignore_keys = [\n",
    "    '.scale',\n",
    "    '.zero_point',\n",
    "    '._packed_params.dtype'\n",
    "]\n",
    "\n",
    "# Extract encoder.0 to encoder.5\n",
    "for i in range(6):\n",
    "    with open(f'encoder_{i}_params.txt', 'w') as f:\n",
    "        for layer_name, param_tensor in model_state_dict.items():\n",
    "            if layer_name.startswith(f'encoder.{i}') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "                f.write(f\"Layer: {layer_name}\\n\") \n",
    "                f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "# Extract classifier\n",
    "with open('classifier_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('classifier') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\") \n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract embedding.cls_token\n",
    "with open('cls_token_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name == 'embedding.cls_token':\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract embedding\n",
    "with open('embedding_params.txt', 'w') as f: \n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('embedding') and layer_name != 'embedding.cls_token' and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\")\n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Extract positional_encoding\n",
    "with open('pos_encoding_params.txt', 'w') as f:\n",
    "    for layer_name, param_tensor in model_state_dict.items():\n",
    "        if layer_name.startswith('positional_encoding') and not any(layer_name.endswith(ignore_key) for ignore_key in ignore_keys):\n",
    "            f.write(f\"Layer: {layer_name}\\n\") \n",
    "            f.write(f\"Parameters: {str(param_tensor)}\\n\")\n",
    "            f.write(\"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
